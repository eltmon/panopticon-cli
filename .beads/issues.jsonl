{"id":"panopticon-1dl","title":"Panopticon V1 Launch","description":"First public release of Panopticon CLI - multi-agent orchestration for Claude Code.\n\n## Goals\n- Working `npx panopticon-cli install` command\n- Dashboard for agent monitoring\n- Skills \u0026 commands that sync across AI tools\n- Traefik-based workspace routing\n- npm published package with provenance\n\n## Phases\n1. Core CLI (pan init, pan sync)\n2. Skills \u0026 Commands\n3. Dashboard extraction\n4. Beads integration\n5. Installation \u0026 distribution\n\n## Success Criteria\n- Can run `npx panopticon-cli install` on fresh machine\n- Dashboard shows running agents\n- Skills sync to ~/.claude/skills/\n- Workspaces get friendly URLs","status":"closed","priority":1,"issue_type":"epic","created_at":"2026-01-17T17:56:18.797835939-08:00","created_by":"eltmon","updated_at":"2026-01-17T17:57:44.814197594-08:00","closed_at":"2026-01-17T17:57:44.814197594-08:00","close_reason":"Duplicate"}
{"id":"panopticon-6ax","title":"Panopticon V1 Launch","description":"Panopticon V1: Multi-Agent Orchestration for Claude Code\n\nFirst public release of the open-source orchestration system.\n\n## Overview\n\nPanopticon is an opinionated multi-agent orchestration system for Claude Code. \nIt manages projects, agents, and provides a unified set of skills, commands, \nand integrations that sync to your Claude Code environment.\n\n## PRD Reference\n- PRD: /home/eltmon/projects/panopticon/docs/PRD.md\n- Linear: MIN-630 (origin)\n- GitHub: github.com/eltmon/panopticon-cli\n\n## Implementation Phases\n\n### Core (P1) - Required for V1 Launch\n\n| Phase | Description | PRD Parts |\n|-------|-------------|-----------|\n| 1 | Core CLI Foundation | Part 8, 9, 14 |\n| 2 | Skills System | Part 4 |\n| 3 | Commands Migration | Part 9 |\n| 4 | Dashboard | Part 11 |\n| 5 | Workspace Management | Part 9, 14 |\n| 6 | Installation System | Part 14 |\n| 7 | npm Publishing | Part 14 |\n| 10 | Beads Deep Integration | Part 3 |\n| 11 | Health Monitoring | Part 7 |\n\n### Extended (P2) - Post-Launch\n\n| Phase | Description | PRD Parts |\n|-------|-------------|-----------|\n| 8 | Issue Tracker Integration | Part 10 |\n| 9 | Testing \u0026 Documentation | Part 12, Appendix B |\n| 12 | Context Engineering | Part 2, 5 |\n| 13 | Multi-Runtime Architecture | Part 6 |\n| 14 | Project Hooks | Part 14 |\n\n## Key Deliverables\n\n- **CLI**: \\`pan\\` command with init, sync, workspace, health subcommands\n- **Skills**: 14+ high-value SKILL.md files\n- **Commands**: /work-* and /pan:* slash commands\n- **Dashboard**: React web app for agent monitoring\n- **Workspaces**: Docker-isolated environments per feature\n- **npm Package**: panopticon-cli with provenance\n\n## Success Metrics\n\n1. Single source of truth - All agent tooling in ~/.panopticon/\n2. Zero friction sync - \\`pan sync\\` updates Claude Code instantly\n3. Project isolation - Each project has its own workspaces/agents\n4. Crash recovery - Beads tracks state, agents can resume\n5. Multi-project - Switch between projects seamlessly\n6. Cross-platform skills - One SKILL.md works everywhere\n\n## Technology Stack\n\n- Language: TypeScript/Node.js\n- CLI: Commander.js\n- Dashboard: React + Vite + TailwindCSS\n- Backend: Express + Socket.io\n- Config: TOML\n- State: Beads (Git-backed)\n- Containers: Docker + Traefik","status":"open","priority":1,"issue_type":"epic","created_at":"2026-01-17T17:56:23.332832136-08:00","created_by":"eltmon","updated_at":"2026-01-17T18:09:25.689910113-08:00"}
{"id":"panopticon-6ax.1","title":"Phase 1: Core CLI Foundation","description":"Set up the basic CLI structure, core commands, and configuration system.\n\n## Prerequisites\n- Node.js 18+ installed\n- npm account (eltmon) logged in\n- Phase 0 (project scaffolding) already done: package.json, tsconfig.json exist\n\n## Acceptance Criteria (Testable)\n- [ ] \\`npm run build\\` succeeds with no errors\n- [ ] \\`node dist/cli/index.js --version\\` prints \"0.1.0\"\n- [ ] \\`node dist/cli/index.js init\\` creates ~/.panopticon/ with all subdirs\n- [ ] \\`cat ~/.panopticon/config.toml\\` shows valid TOML\n- [ ] \\`grep \"pan\" ~/.zshrc\\` (or ~/.bashrc) shows alias line\n- [ ] \\`node dist/cli/index.js sync --dry-run\\` lists target locations\n- [ ] Running \\`pan --version\\` works after sourcing shell rc\n\n---\n\n## Step 1: Install Dependencies\n\n\\`\\`\\`bash\ncd /home/eltmon/projects/panopticon\nnpm install commander@^12 chalk@^5 ora@^8 @iarna/toml execa@^8 inquirer@^9\nnpm install -D @types/inquirer\n\\`\\`\\`\n\n---\n\n## Step 2: Create Directory Structure\n\n\\`\\`\\`\nsrc/\n├── cli/\n│   ├── index.ts              # Entry point, Commander setup\n│   └── commands/\n│       ├── init.ts           # pan init\n│       ├── sync.ts           # pan sync\n│       └── restore.ts        # pan restore\n└── lib/\n    ├── config.ts             # TOML parsing\n    ├── paths.ts              # Path constants\n    ├── shell.ts              # Shell detection, alias\n    ├── backup.ts             # Backup/restore logic\n    └── sync.ts               # Safe sync logic\n\\`\\`\\`\n\n---\n\n## Step 3: CLI Entry Point (src/cli/index.ts)\n\n\\`\\`\\`typescript\n#!/usr/bin/env node\nimport { Command } from 'commander';\nimport chalk from 'chalk';\nimport { initCommand } from './commands/init.js';\nimport { syncCommand } from './commands/sync.js';\nimport { restoreCommand } from './commands/restore.js';\n\nconst program = new Command();\n\nprogram\n  .name('pan')\n  .description('Multi-agent orchestration for Claude Code')\n  .version('0.1.0');\n\nprogram\n  .command('init')\n  .description('Initialize Panopticon (~/.panopticon/)')\n  .action(initCommand);\n\nprogram\n  .command('sync')\n  .description('Sync skills/commands to AI tools')\n  .option('--dry-run', 'Show what would be synced')\n  .option('--force', 'Overwrite without prompts')\n  .option('--backup-only', 'Only create backup')\n  .option('--merge', 'Keep user content, add Panopticon alongside')\n  .action(syncCommand);\n\nprogram\n  .command('restore \u003ctimestamp\u003e')\n  .description('Restore from backup')\n  .action(restoreCommand);\n\nprogram.parse();\n\\`\\`\\`\n\n**IMPORTANT**: Add shebang and make sure package.json has:\n\\`\\`\\`json\n{\n  \"bin\": {\n    \"pan\": \"./dist/cli/index.js\",\n    \"panopticon\": \"./dist/cli/index.js\"\n  }\n}\n\\`\\`\\`\n\n---\n\n## Step 4: Path Constants (src/lib/paths.ts)\n\n\\`\\`\\`typescript\nimport { homedir } from 'os';\nimport { join } from 'path';\nimport { existsSync } from 'fs';\n\nexport const PANOPTICON_HOME = join(homedir(), '.panopticon');\nexport const CONFIG_FILE = join(PANOPTICON_HOME, 'config.toml');\nexport const PROJECTS_FILE = join(PANOPTICON_HOME, 'projects.toml');\nexport const SKILLS_DIR = join(PANOPTICON_HOME, 'skills');\nexport const COMMANDS_DIR = join(PANOPTICON_HOME, 'commands');\nexport const AGENTS_DIR = join(PANOPTICON_HOME, 'agents');\nexport const BACKUPS_DIR = join(PANOPTICON_HOME, 'backups');\n\n// Sync targets for different AI tools\nexport const SYNC_TARGETS = {\n  'claude-skills': join(homedir(), '.claude', 'skills'),\n  'claude-commands': join(homedir(), '.claude', 'commands'),\n  'codex-skills': join(homedir(), '.codex', 'skills'),\n  'gemini-skills': join(homedir(), '.gemini', 'skills'),\n  'antigravity-skills': join(homedir(), '.gemini', 'antigravity', 'skills'),\n};\n\nexport type Platform = 'macos' | 'linux' | 'wsl2' | 'windows';\n\nexport function detectPlatform(): Platform {\n  const platform = process.platform;\n  if (platform === 'darwin') return 'macos';\n  if (platform === 'win32') return 'windows';\n  \n  // Check for WSL2\n  if (platform === 'linux') {\n    const isWSL = existsSync('/proc/version') \u0026\u0026 \n      require('fs').readFileSync('/proc/version', 'utf8').toLowerCase().includes('microsoft');\n    return isWSL ? 'wsl2' : 'linux';\n  }\n  return 'linux';\n}\n\\`\\`\\`\n\n---\n\n## Step 5: Shell Alias (src/lib/shell.ts)\n\n\\`\\`\\`typescript\nimport { homedir } from 'os';\nimport { join } from 'path';\nimport { existsSync, appendFileSync, readFileSync } from 'fs';\n\ntype Shell = 'bash' | 'zsh' | 'fish' | 'unknown';\n\nexport function detectShell(): Shell {\n  const shell = process.env.SHELL || '';\n  if (shell.includes('zsh')) return 'zsh';\n  if (shell.includes('bash')) return 'bash';\n  if (shell.includes('fish')) return 'fish';\n  return 'unknown';\n}\n\nexport function getShellRcFile(shell: Shell): string | null {\n  const home = homedir();\n  switch (shell) {\n    case 'zsh': return join(home, '.zshrc');\n    case 'bash': return join(home, '.bashrc');\n    case 'fish': return join(home, '.config', 'fish', 'config.fish');\n    default: return null;\n  }\n}\n\nconst ALIAS_MARKER = '# Panopticon CLI';\nconst ALIAS_LINE = 'alias pan=\"node ~/.panopticon/cli/index.js\"';\n\nexport function addShellAlias(): { added: boolean; rcFile: string | null; shell: Shell } {\n  const shell = detectShell();\n  const rcFile = getShellRcFile(shell);\n  \n  if (!rcFile) {\n    return { added: false, rcFile: null, shell };\n  }\n  \n  // Check if already added\n  if (existsSync(rcFile)) {\n    const content = readFileSync(rcFile, 'utf8');\n    if (content.includes(ALIAS_MARKER)) {\n      return { added: false, rcFile, shell }; // Already exists\n    }\n  }\n  \n  // Add alias\n  const aliasBlock = \\`\\\\n\\${ALIAS_MARKER}\\\\n\\${ALIAS_LINE}\\\\n\\`;\n  appendFileSync(rcFile, aliasBlock);\n  \n  return { added: true, rcFile, shell };\n}\n\\`\\`\\`\n\n---\n\n## Step 6: Default Config Template (src/lib/config.ts)\n\n\\`\\`\\`typescript\nimport { readFileSync, writeFileSync, existsSync } from 'fs';\nimport * as TOML from '@iarna/toml';\nimport { CONFIG_FILE, PROJECTS_FILE } from './paths.js';\n\nexport interface PanopticonConfig {\n  panopticon: {\n    version: string;\n    default_runtime: string;\n  };\n  trackers: {\n    linear?: { api_key_env: string };\n    github?: { token_env: string };\n  };\n  dashboard: {\n    port: number;\n    api_port: number;\n  };\n  sync: {\n    auto_sync: boolean;\n    strategy: 'symlink' | 'copy';\n    backup_before_sync: boolean;\n    backup_retention_days: number;\n  };\n  health: {\n    ping_timeout: string;\n    consecutive_failures: number;\n    cooldown: string;\n  };\n}\n\nexport const DEFAULT_CONFIG: PanopticonConfig = {\n  panopticon: {\n    version: '1.0.0',\n    default_runtime: 'claude',\n  },\n  trackers: {\n    linear: { api_key_env: 'LINEAR_API_KEY' },\n    github: { token_env: 'GITHUB_TOKEN' },\n  },\n  dashboard: {\n    port: 3001,\n    api_port: 3002,\n  },\n  sync: {\n    auto_sync: true,\n    strategy: 'symlink',\n    backup_before_sync: true,\n    backup_retention_days: 30,\n  },\n  health: {\n    ping_timeout: '30s',\n    consecutive_failures: 3,\n    cooldown: '5m',\n  },\n};\n\nexport function writeDefaultConfig(): void {\n  const toml = TOML.stringify(DEFAULT_CONFIG as any);\n  writeFileSync(CONFIG_FILE, toml);\n}\n\nexport function loadConfig(): PanopticonConfig {\n  if (!existsSync(CONFIG_FILE)) {\n    throw new Error(\\`Config not found: \\${CONFIG_FILE}. Run 'pan init' first.\\`);\n  }\n  const content = readFileSync(CONFIG_FILE, 'utf8');\n  return TOML.parse(content) as unknown as PanopticonConfig;\n}\n\\`\\`\\`\n\n---\n\n## Step 7: Init Command (src/cli/commands/init.ts)\n\n\\`\\`\\`typescript\nimport { mkdirSync, existsSync } from 'fs';\nimport chalk from 'chalk';\nimport ora from 'ora';\nimport { \n  PANOPTICON_HOME, SKILLS_DIR, COMMANDS_DIR, AGENTS_DIR, BACKUPS_DIR \n} from '../../lib/paths.js';\nimport { writeDefaultConfig } from '../../lib/config.js';\nimport { addShellAlias } from '../../lib/shell.js';\n\nconst DIRS_TO_CREATE = [\n  PANOPTICON_HOME,\n  SKILLS_DIR,\n  COMMANDS_DIR,\n  AGENTS_DIR,\n  BACKUPS_DIR,\n  \\`\\${PANOPTICON_HOME}/context\\`,\n  \\`\\${PANOPTICON_HOME}/context/materialized\\`,\n  \\`\\${PANOPTICON_HOME}/context/history\\`,\n  \\`\\${PANOPTICON_HOME}/runtimes\\`,\n  \\`\\${PANOPTICON_HOME}/templates\\`,\n  \\`\\${PANOPTICON_HOME}/mcp\\`,\n];\n\nexport async function initCommand(): Promise\u003cvoid\u003e {\n  const spinner = ora('Initializing Panopticon...').start();\n  \n  try {\n    // Check if already initialized\n    if (existsSync(PANOPTICON_HOME)) {\n      spinner.warn('Panopticon already initialized at ' + PANOPTICON_HOME);\n      return;\n    }\n    \n    // Create directories\n    for (const dir of DIRS_TO_CREATE) {\n      mkdirSync(dir, { recursive: true });\n    }\n    spinner.text = 'Created directory structure';\n    \n    // Write default config\n    writeDefaultConfig();\n    spinner.text = 'Created config.toml';\n    \n    // Add shell alias\n    const { added, rcFile, shell } = addShellAlias();\n    \n    spinner.succeed('Panopticon initialized!');\n    \n    console.log('');\n    console.log(chalk.green('✓') + ' Created ' + chalk.cyan('~/.panopticon/'));\n    console.log(chalk.green('✓') + ' Created ' + chalk.cyan('config.toml'));\n    \n    if (added \u0026\u0026 rcFile) {\n      console.log(chalk.green('✓') + ' Added pan alias to ' + chalk.cyan(rcFile));\n      console.log('');\n      console.log(chalk.yellow('Run this to activate:'));\n      console.log(chalk.cyan(\\`  source \\${rcFile}\\`));\n    } else if (rcFile) {\n      console.log(chalk.dim('  pan alias already exists in ' + rcFile));\n    }\n    \n    console.log('');\n    console.log(chalk.bold('Next steps:'));\n    console.log('  pan sync     # Sync skills to Claude Code');\n    console.log('  pan install  # Set up Traefik + Docker');\n    \n  } catch (error) {\n    spinner.fail('Initialization failed');\n    console.error(error);\n    process.exit(1);\n  }\n}\n\\`\\`\\`\n\n---\n\n## Step 8: Safe Sync Logic (src/lib/sync.ts)\n\n\\`\\`\\`typescript\nimport { existsSync, readdirSync, lstatSync, readlinkSync, symlinkSync, mkdirSync } from 'fs';\nimport { join, basename } from 'path';\nimport { PANOPTICON_HOME } from './paths.js';\n\nexport type SyncTargetState = 'empty' | 'panopticon' | 'user-content' | 'mixed';\n\nexport function detectTargetState(targetPath: string): SyncTargetState {\n  if (!existsSync(targetPath)) return 'empty';\n  \n  const items = readdirSync(targetPath);\n  if (items.length === 0) return 'empty';\n  \n  let panopticonCount = 0;\n  let otherCount = 0;\n  \n  for (const item of items) {\n    const itemPath = join(targetPath, item);\n    const stat = lstatSync(itemPath);\n    \n    if (stat.isSymbolicLink()) {\n      const target = readlinkSync(itemPath);\n      if (target.includes('.panopticon')) {\n        panopticonCount++;\n      } else {\n        otherCount++;\n      }\n    } else {\n      otherCount++;\n    }\n  }\n  \n  if (panopticonCount === items.length) return 'panopticon';\n  if (otherCount === items.length) return 'user-content';\n  return 'mixed';\n}\n\nexport function createSymlinks(\n  sourceDir: string, \n  targetDir: string,\n  options: { dryRun?: boolean } = {}\n): string[] {\n  const created: string[] = [];\n  \n  if (!existsSync(sourceDir)) return created;\n  \n  // Ensure target dir exists\n  if (!options.dryRun) {\n    mkdirSync(targetDir, { recursive: true });\n  }\n  \n  const items = readdirSync(sourceDir);\n  \n  for (const item of items) {\n    const sourcePath = join(sourceDir, item);\n    const targetPath = join(targetDir, item);\n    \n    if (options.dryRun) {\n      created.push(\\`\\${targetPath} -\u003e \\${sourcePath}\\`);\n    } else {\n      // Remove existing if it's our symlink\n      if (existsSync(targetPath)) {\n        const stat = lstatSync(targetPath);\n        if (stat.isSymbolicLink()) {\n          const existing = readlinkSync(targetPath);\n          if (existing.includes('.panopticon')) {\n            require('fs').unlinkSync(targetPath);\n          } else {\n            continue; // Skip user content\n          }\n        } else {\n          continue; // Skip user directories/files\n        }\n      }\n      \n      symlinkSync(sourcePath, targetPath);\n      created.push(targetPath);\n    }\n  }\n  \n  return created;\n}\n\\`\\`\\`\n\n---\n\n## Step 9: Sync Command (src/cli/commands/sync.ts)\n\n\\`\\`\\`typescript\nimport chalk from 'chalk';\nimport ora from 'ora';\nimport { SKILLS_DIR, COMMANDS_DIR, SYNC_TARGETS } from '../../lib/paths.js';\nimport { detectTargetState, createSymlinks } from '../../lib/sync.js';\n\ninterface SyncOptions {\n  dryRun?: boolean;\n  force?: boolean;\n  backupOnly?: boolean;\n  merge?: boolean;\n}\n\nexport async function syncCommand(options: SyncOptions): Promise\u003cvoid\u003e {\n  const spinner = ora('Syncing Panopticon...').start();\n  \n  if (options.dryRun) {\n    spinner.info('Dry run mode - no changes will be made');\n  }\n  \n  // Sync skills to all AI tool locations\n  const skillTargets = [\n    SYNC_TARGETS['claude-skills'],\n    SYNC_TARGETS['codex-skills'],\n    SYNC_TARGETS['gemini-skills'],\n    SYNC_TARGETS['antigravity-skills'],\n  ];\n  \n  for (const target of skillTargets) {\n    const state = detectTargetState(target);\n    \n    if (state === 'user-content' \u0026\u0026 !options.force \u0026\u0026 !options.merge) {\n      spinner.warn(\\`Skipping \\${target} - contains user content (use --force or --merge)\\`);\n      continue;\n    }\n    \n    spinner.text = \\`Syncing skills to \\${target}...\\`;\n    const created = createSymlinks(SKILLS_DIR, target, { dryRun: options.dryRun });\n    \n    if (options.dryRun) {\n      console.log(chalk.dim(\\`  Would create \\${created.length} symlinks in \\${target}\\`));\n    }\n  }\n  \n  // Sync commands to Claude Code only (commands aren't universal)\n  spinner.text = 'Syncing commands to ~/.claude/commands/...';\n  const commandsCreated = createSymlinks(\n    COMMANDS_DIR, \n    SYNC_TARGETS['claude-commands'],\n    { dryRun: options.dryRun }\n  );\n  \n  spinner.succeed('Sync complete!');\n  \n  console.log('');\n  console.log(chalk.bold('Synced to:'));\n  for (const [name, path] of Object.entries(SYNC_TARGETS)) {\n    const state = detectTargetState(path);\n    const icon = state === 'panopticon' ? chalk.green('✓') : chalk.yellow('○');\n    console.log(\\`  \\${icon} \\${path}\\`);\n  }\n}\n\\`\\`\\`\n\n---\n\n## Verification Checklist\n\nAfter implementation, run these commands to verify:\n\n\\`\\`\\`bash\n# 1. Build\nnpm run build\n# Expected: No errors, dist/ created\n\n# 2. Version check\nnode dist/cli/index.js --version\n# Expected: 0.1.0\n\n# 3. Help check\nnode dist/cli/index.js --help\n# Expected: Shows init, sync, restore commands\n\n# 4. Init (first time)\nrm -rf ~/.panopticon  # Clean slate\nnode dist/cli/index.js init\n# Expected: \"Panopticon initialized!\"\n\n# 5. Verify directory structure\nls -la ~/.panopticon/\n# Expected: skills/, commands/, agents/, config.toml, etc.\n\n# 6. Verify config\ncat ~/.panopticon/config.toml\n# Expected: Valid TOML with all sections\n\n# 7. Verify alias added\ngrep -n \"panopticon\" ~/.zshrc || grep -n \"panopticon\" ~/.bashrc\n# Expected: Shows alias line\n\n# 8. Sync dry-run\nnode dist/cli/index.js sync --dry-run\n# Expected: Lists targets without changing anything\n\n# 9. Test alias (after sourcing)\nsource ~/.zshrc  # or ~/.bashrc\npan --version\n# Expected: 0.1.0\n\\`\\`\\`\n\n---\n\n## Common Gotchas\n\n1. **Shebang**: Ensure \\`#!/usr/bin/env node\\` is first line of index.ts\n2. **ESM imports**: Use \\`.js\\` extension in imports (TypeScript ESM quirk)\n3. **Symlink permissions**: May need sudo on some systems for /etc/hosts\n4. **Fish shell**: Config location is different (\\`~/.config/fish/config.fish\\`)\n5. **WSL2**: Shell rc file might be in Windows home, not WSL home\n\n---\n\n## Dependencies on Other Phases\n\n- **Depends on**: None (this is Phase 1)\n- **Blocks**: Phase 2 (needs SKILLS_DIR), Phase 3 (needs COMMANDS_DIR)","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-17T17:56:31.579314546-08:00","created_by":"eltmon","updated_at":"2026-01-17T18:20:56.21063565-08:00","labels":["cli","core"],"dependencies":[{"issue_id":"panopticon-6ax.1","depends_on_id":"panopticon-6ax","type":"parent-child","created_at":"2026-01-17T17:56:31.59066985-08:00","created_by":"eltmon"}]}
{"id":"panopticon-6ax.10","title":"Phase 10: Beads Deep Integration","description":"Implement deep Beads integration for persistent state and agent tracking.\n\n## Prerequisites\n- Phase 1 complete (paths, config)\n- Phase 3 complete (agents library)\n- Beads CLI installed (`which bd` succeeds)\n\n## Acceptance Criteria (Testable)\n- [ ] `bd hook check agent-min-123` returns current work item (or null)\n- [ ] `bd hook assign agent-min-123 beads-xyz` assigns work to agent\n- [ ] Agent state persisted to ~/.panopticon/agents/\u003cid\u003e/state.json\n- [ ] Agent CV shows completion stats: `bd stats --actor=panopticon/agent-min-123`\n- [ ] Crash recovery: Restarted agent resumes from checkpoint\n\n---\n\n## Step 1: Create Hook Interface (src/lib/beads/hooks.ts)\n\n```typescript\nimport { execSync } from 'child_process';\nimport { existsSync, readFileSync, writeFileSync, mkdirSync } from 'fs';\nimport { join } from 'path';\nimport { AGENTS_DIR } from '../paths.js';\n\nexport interface HookItem {\n  beadId: string;\n  title: string;\n  assignedAt: Date;\n}\n\nexport interface Hook {\n  agentId: string;\n  currentWork: HookItem | null;\n  queue: HookItem[];\n}\n\nfunction getHookPath(agentId: string): string {\n  return join(AGENTS_DIR, agentId, 'hook.json');\n}\n\nexport function getHook(agentId: string): Hook {\n  const hookPath = getHookPath(agentId);\n\n  if (!existsSync(hookPath)) {\n    return { agentId, currentWork: null, queue: [] };\n  }\n\n  const content = readFileSync(hookPath, 'utf8');\n  return JSON.parse(content);\n}\n\nexport function saveHook(hook: Hook): void {\n  const hookPath = getHookPath(hook.agentId);\n  const dir = join(AGENTS_DIR, hook.agentId);\n\n  mkdirSync(dir, { recursive: true });\n  writeFileSync(hookPath, JSON.stringify(hook, null, 2));\n}\n\nexport function hookCheck(agentId: string): HookItem | null {\n  const hook = getHook(agentId);\n  return hook.currentWork;\n}\n\nexport function hookAssign(agentId: string, beadId: string): HookItem {\n  // Get bead details from beads CLI\n  let title = beadId;\n  try {\n    const output = execSync(`bd show ${beadId} --format json`, { encoding: 'utf8' });\n    const bead = JSON.parse(output);\n    title = bead.title || beadId;\n  } catch {\n    // Use beadId as title if bd fails\n  }\n\n  const item: HookItem = {\n    beadId,\n    title,\n    assignedAt: new Date(),\n  };\n\n  const hook = getHook(agentId);\n  hook.currentWork = item;\n  saveHook(hook);\n\n  return item;\n}\n\nexport function hookComplete(agentId: string): HookItem | null {\n  const hook = getHook(agentId);\n\n  if (!hook.currentWork) {\n    return null;\n  }\n\n  // Close the bead\n  try {\n    execSync(`bd close ${hook.currentWork.beadId} --reason \"Completed by ${agentId}\"`);\n  } catch (error) {\n    console.error('Failed to close bead:', error);\n  }\n\n  // Get next work from queue\n  hook.currentWork = hook.queue.shift() || null;\n  saveHook(hook);\n\n  return hook.currentWork;\n}\n\nexport function hookEnqueue(agentId: string, beadId: string): void {\n  let title = beadId;\n  try {\n    const output = execSync(`bd show ${beadId} --format json`, { encoding: 'utf8' });\n    const bead = JSON.parse(output);\n    title = bead.title || beadId;\n  } catch {\n    // Use beadId as title\n  }\n\n  const hook = getHook(agentId);\n  hook.queue.push({\n    beadId,\n    title,\n    assignedAt: new Date(),\n  });\n  saveHook(hook);\n}\n```\n\n---\n\n## Step 2: Create Attribution Module (src/lib/beads/attribution.ts)\n\n```typescript\nimport { execSync } from 'child_process';\n\nexport interface BeadEvent {\n  type: 'created' | 'assigned' | 'status_change' | 'note_added' | 'closed';\n  actor: string;\n  timestamp: Date;\n  details?: Record\u003cstring, string\u003e;\n}\n\nconst ACTOR_PREFIX = 'panopticon';\n\nexport function getActorId(agentId: string): string {\n  return `${ACTOR_PREFIX}/${agentId}`;\n}\n\nexport function createBeadWithAttribution(\n  title: string,\n  agentId: string,\n  options?: {\n    type?: string;\n    labels?: string[];\n    dependsOn?: string;\n  }\n): string {\n  const actor = getActorId(agentId);\n\n  let cmd = `bd create \"${title}\" --actor \"${actor}\"`;\n\n  if (options?.type) {\n    cmd += ` --type ${options.type}`;\n  }\n  if (options?.labels) {\n    cmd += ` --labels \"${options.labels.join(',')}\"`;\n  }\n  if (options?.dependsOn) {\n    cmd += ` --depends-on ${options.dependsOn}`;\n  }\n\n  const output = execSync(cmd, { encoding: 'utf8' });\n\n  // Extract bead ID from output\n  const match = output.match(/Created: (\\S+)/);\n  return match ? match[1] : '';\n}\n\nexport function addNoteWithAttribution(\n  beadId: string,\n  note: string,\n  agentId: string\n): void {\n  const actor = getActorId(agentId);\n  execSync(`bd notes add ${beadId} \"${note}\" --actor \"${actor}\"`);\n}\n\nexport function updateStatusWithAttribution(\n  beadId: string,\n  status: string,\n  agentId: string\n): void {\n  const actor = getActorId(agentId);\n  execSync(`bd update ${beadId} --status ${status} --actor \"${actor}\"`);\n}\n\nexport function closeBeadWithAttribution(\n  beadId: string,\n  reason: string,\n  agentId: string\n): void {\n  const actor = getActorId(agentId);\n  execSync(`bd close ${beadId} --reason \"${reason}\" --actor \"${actor}\"`);\n}\n```\n\n---\n\n## Step 3: Create Agent CV Module (src/lib/beads/cv.ts)\n\n```typescript\nimport { execSync } from 'child_process';\nimport { existsSync, readFileSync, writeFileSync, mkdirSync } from 'fs';\nimport { join } from 'path';\nimport { AGENTS_DIR } from '../paths.js';\nimport { getActorId } from './attribution.js';\n\nexport interface AgentCV {\n  agentId: string;\n  issuesCompleted: number;\n  issuesFailed: number;\n  totalTimeMinutes: number;\n  capabilities: Record\u003cstring, number\u003e;  // label -\u003e count\n  recentWork: Array\u003c{\n    beadId: string;\n    title: string;\n    success: boolean;\n    durationMinutes: number;\n    completedAt: Date;\n  }\u003e;\n}\n\nfunction getCVPath(agentId: string): string {\n  return join(AGENTS_DIR, agentId, 'cv.json');\n}\n\nexport function getAgentCV(agentId: string): AgentCV {\n  const cvPath = getCVPath(agentId);\n\n  if (!existsSync(cvPath)) {\n    return {\n      agentId,\n      issuesCompleted: 0,\n      issuesFailed: 0,\n      totalTimeMinutes: 0,\n      capabilities: {},\n      recentWork: [],\n    };\n  }\n\n  const content = readFileSync(cvPath, 'utf8');\n  return JSON.parse(content);\n}\n\nexport function saveAgentCV(cv: AgentCV): void {\n  const cvPath = getCVPath(cv.agentId);\n  const dir = join(AGENTS_DIR, cv.agentId);\n\n  mkdirSync(dir, { recursive: true });\n  writeFileSync(cvPath, JSON.stringify(cv, null, 2));\n}\n\nexport function recordCompletion(\n  agentId: string,\n  beadId: string,\n  success: boolean,\n  durationMinutes: number,\n  labels: string[] = []\n): void {\n  const cv = getAgentCV(agentId);\n\n  // Update stats\n  if (success) {\n    cv.issuesCompleted++;\n  } else {\n    cv.issuesFailed++;\n  }\n\n  cv.totalTimeMinutes += durationMinutes;\n\n  // Update capabilities\n  for (const label of labels) {\n    cv.capabilities[label] = (cv.capabilities[label] || 0) + 1;\n  }\n\n  // Get bead title\n  let title = beadId;\n  try {\n    const output = execSync(`bd show ${beadId} --format json`, { encoding: 'utf8' });\n    const bead = JSON.parse(output);\n    title = bead.title || beadId;\n  } catch {\n    // Use beadId\n  }\n\n  // Add to recent work\n  cv.recentWork.unshift({\n    beadId,\n    title,\n    success,\n    durationMinutes,\n    completedAt: new Date(),\n  });\n\n  // Keep last 20 items\n  cv.recentWork = cv.recentWork.slice(0, 20);\n\n  saveAgentCV(cv);\n}\n\nexport function printAgentStats(agentId: string): void {\n  const cv = getAgentCV(agentId);\n  const actor = getActorId(agentId);\n\n  console.log(`\\nAgent: ${actor}`);\n  console.log('-'.repeat(40));\n  console.log(`Issues completed: ${cv.issuesCompleted}`);\n  console.log(`Issues failed:    ${cv.issuesFailed}`);\n\n  const successRate = cv.issuesCompleted + cv.issuesFailed \u003e 0\n    ? Math.round((cv.issuesCompleted / (cv.issuesCompleted + cv.issuesFailed)) * 100)\n    : 0;\n  console.log(`Success rate:     ${successRate}%`);\n\n  const avgTime = cv.issuesCompleted \u003e 0\n    ? Math.round(cv.totalTimeMinutes / cv.issuesCompleted)\n    : 0;\n  console.log(`Avg time/issue:   ${avgTime} min`);\n\n  // Top capabilities\n  const topCaps = Object.entries(cv.capabilities)\n    .sort((a, b) =\u003e b[1] - a[1])\n    .slice(0, 5);\n\n  if (topCaps.length \u003e 0) {\n    console.log(`\\nTop capabilities:`);\n    for (const [cap, count] of topCaps) {\n      console.log(`  ${cap}: ${count}`);\n    }\n  }\n\n  // Recent work\n  if (cv.recentWork.length \u003e 0) {\n    console.log(`\\nRecent work:`);\n    for (const work of cv.recentWork.slice(0, 5)) {\n      const icon = work.success ? 'V' : 'X';\n      console.log(`  ${icon} ${work.beadId}  \"${work.title}\"  ${work.durationMinutes} min`);\n    }\n  }\n}\n```\n\n---\n\n## Step 4: Create Crash Recovery Module (src/lib/beads/recovery.ts)\n\n```typescript\nimport { existsSync, readFileSync, writeFileSync, mkdirSync } from 'fs';\nimport { join } from 'path';\nimport { AGENTS_DIR } from '../paths.js';\nimport { hookCheck } from './hooks.js';\n\nexport interface Checkpoint {\n  step: string;\n  progress: number;  // 0.0 to 1.0\n  filesModified: string[];\n  uncommittedChanges: boolean;\n  timestamp: Date;\n}\n\nexport interface AgentState {\n  id: string;\n  issueId: string;\n  workspace: string;\n  runtime: string;\n  model: string;\n  status: 'starting' | 'running' | 'stopped' | 'error';\n  startedAt: Date;\n  lastActivity?: Date;\n  checkpoint?: Checkpoint;\n  currentWork?: string;  // Bead ID\n}\n\nfunction getStatePath(agentId: string): string {\n  return join(AGENTS_DIR, agentId, 'state.json');\n}\n\nexport function getAgentState(agentId: string): AgentState | null {\n  const statePath = getStatePath(agentId);\n\n  if (!existsSync(statePath)) {\n    return null;\n  }\n\n  const content = readFileSync(statePath, 'utf8');\n  return JSON.parse(content);\n}\n\nexport function saveAgentState(state: AgentState): void {\n  const statePath = getStatePath(state.id);\n  const dir = join(AGENTS_DIR, state.id);\n\n  mkdirSync(dir, { recursive: true });\n  writeFileSync(statePath, JSON.stringify(state, null, 2));\n}\n\nexport function saveCheckpoint(\n  agentId: string,\n  checkpoint: Omit\u003cCheckpoint, 'timestamp'\u003e\n): void {\n  const state = getAgentState(agentId);\n  if (!state) return;\n\n  state.checkpoint = {\n    ...checkpoint,\n    timestamp: new Date(),\n  };\n  state.lastActivity = new Date();\n\n  saveAgentState(state);\n}\n\nexport function clearCheckpoint(agentId: string): void {\n  const state = getAgentState(agentId);\n  if (!state) return;\n\n  delete state.checkpoint;\n  saveAgentState(state);\n}\n\nexport interface RecoveryInfo {\n  hasWork: boolean;\n  currentWork?: string;\n  checkpoint?: Checkpoint;\n  warningMessage?: string;\n}\n\nexport function getRecoveryInfo(agentId: string): RecoveryInfo {\n  const state = getAgentState(agentId);\n  const hookWork = hookCheck(agentId);\n\n  if (!state \u0026\u0026 !hookWork) {\n    return { hasWork: false };\n  }\n\n  const info: RecoveryInfo = {\n    hasWork: !!hookWork,\n    currentWork: hookWork?.beadId,\n    checkpoint: state?.checkpoint,\n  };\n\n  if (state?.checkpoint?.uncommittedChanges) {\n    info.warningMessage = 'Warning: Agent has uncommitted changes from previous session';\n  }\n\n  return info;\n}\n\nexport function printRecoveryInfo(agentId: string): void {\n  const info = getRecoveryInfo(agentId);\n\n  console.log(`\\nRecovery Info: ${agentId}`);\n  console.log('-'.repeat(40));\n\n  if (!info.hasWork) {\n    console.log('No pending work.');\n    return;\n  }\n\n  console.log(`Current work: ${info.currentWork}`);\n\n  if (info.checkpoint) {\n    console.log(`\\nCheckpoint:`);\n    console.log(`  Step: ${info.checkpoint.step}`);\n    console.log(`  Progress: ${Math.round(info.checkpoint.progress * 100)}%`);\n    console.log(`  Files modified: ${info.checkpoint.filesModified.length}`);\n    console.log(`  Uncommitted changes: ${info.checkpoint.uncommittedChanges}`);\n  }\n\n  if (info.warningMessage) {\n    console.log(`\\n${info.warningMessage}`);\n  }\n}\n```\n\n---\n\n## Step 5: Create GUPP Enforcement (src/lib/beads/gupp.ts)\n\n```typescript\nimport { hookCheck, hookComplete } from './hooks.js';\nimport { getRecoveryInfo, saveCheckpoint } from './recovery.js';\nimport { addNoteWithAttribution, updateStatusWithAttribution, closeBeadWithAttribution } from './attribution.js';\n\n/**\n * GUPP Principle: \"If there is work on your Hook, YOU MUST RUN IT.\"\n *\n * This function implements the GUPP check that agents must run at startup.\n * Returns the work item to execute, or null if no work.\n */\nexport interface GuppResult {\n  hasWork: boolean;\n  workItem?: {\n    beadId: string;\n    title: string;\n    resumeFrom?: string;  // Checkpoint step to resume from\n    warnings?: string[];\n  };\n}\n\nexport function guppCheck(agentId: string): GuppResult {\n  const hookWork = hookCheck(agentId);\n\n  if (!hookWork) {\n    return { hasWork: false };\n  }\n\n  const recovery = getRecoveryInfo(agentId);\n  const warnings: string[] = [];\n\n  if (recovery.checkpoint?.uncommittedChanges) {\n    warnings.push('Uncommitted changes detected from previous session');\n  }\n\n  return {\n    hasWork: true,\n    workItem: {\n      beadId: hookWork.beadId,\n      title: hookWork.title,\n      resumeFrom: recovery.checkpoint?.step,\n      warnings,\n    },\n  };\n}\n\n/**\n * Execute GUPP work item.\n * This should be called when an agent starts and has work on its hook.\n */\nexport async function guppExecute(\n  agentId: string,\n  options: {\n    onStart: (beadId: string, title: string) =\u003e Promise\u003cvoid\u003e;\n    onProgress: (step: string, progress: number) =\u003e Promise\u003cvoid\u003e;\n    onComplete: (beadId: string, success: boolean, reason: string) =\u003e Promise\u003cvoid\u003e;\n  }\n): Promise\u003cvoid\u003e {\n  const result = guppCheck(agentId);\n\n  if (!result.hasWork || !result.workItem) {\n    return;\n  }\n\n  const { beadId, title, resumeFrom } = result.workItem;\n\n  // Update bead status to in_progress\n  updateStatusWithAttribution(beadId, 'in_progress', agentId);\n\n  // Log resume if applicable\n  if (resumeFrom) {\n    addNoteWithAttribution(beadId, `Resuming from checkpoint: ${resumeFrom}`, agentId);\n  }\n\n  try {\n    // Start work\n    await options.onStart(beadId, title);\n\n    // Work happens here...\n    // Agent calls onProgress periodically\n\n    // Complete work\n    await options.onComplete(beadId, true, 'Completed successfully');\n\n    // Close bead and get next work\n    closeBeadWithAttribution(beadId, 'Completed by agent', agentId);\n    hookComplete(agentId);\n\n    // Check for more work (recursive GUPP)\n    const moreWork = guppCheck(agentId);\n    if (moreWork.hasWork) {\n      await guppExecute(agentId, options);\n    }\n\n  } catch (error: any) {\n    // Save checkpoint on failure\n    saveCheckpoint(agentId, {\n      step: 'error',\n      progress: 0,\n      filesModified: [],\n      uncommittedChanges: false,\n    });\n\n    await options.onComplete(beadId, false, error.message);\n    addNoteWithAttribution(beadId, `Error: ${error.message}`, agentId);\n  }\n}\n```\n\n---\n\n## Step 6: Create CLI Commands for Hooks\n\nAdd to src/cli/commands/work/index.ts:\n\n```typescript\nwork\n  .command('hook \u003csubcommand\u003e [agentId] [beadId]')\n  .description('Manage agent hooks')\n  .action(hookCommand);\n```\n\nCreate src/cli/commands/work/hook.ts:\n\n```typescript\nimport chalk from 'chalk';\nimport { hookCheck, hookAssign, hookComplete, hookEnqueue, getHook } from '../../lib/beads/hooks.js';\nimport { printAgentStats } from '../../lib/beads/cv.js';\nimport { printRecoveryInfo } from '../../lib/beads/recovery.js';\n\nexport async function hookCommand(\n  subcommand: string,\n  agentId?: string,\n  beadId?: string\n): Promise\u003cvoid\u003e {\n  if (!agentId) {\n    console.error(chalk.red('Agent ID required'));\n    process.exit(1);\n  }\n\n  switch (subcommand) {\n    case 'check': {\n      const work = hookCheck(agentId);\n      if (work) {\n        console.log(chalk.green(`Current work: ${work.beadId}`));\n        console.log(`  Title: ${work.title}`);\n      } else {\n        console.log(chalk.dim('No work assigned.'));\n      }\n      break;\n    }\n\n    case 'assign': {\n      if (!beadId) {\n        console.error(chalk.red('Bead ID required'));\n        process.exit(1);\n      }\n      const item = hookAssign(agentId, beadId);\n      console.log(chalk.green(`Assigned: ${item.beadId}`));\n      break;\n    }\n\n    case 'complete': {\n      const next = hookComplete(agentId);\n      if (next) {\n        console.log(chalk.green(`Completed. Next: ${next.beadId}`));\n      } else {\n        console.log(chalk.green('Completed. No more work in queue.'));\n      }\n      break;\n    }\n\n    case 'queue': {\n      if (!beadId) {\n        console.error(chalk.red('Bead ID required'));\n        process.exit(1);\n      }\n      hookEnqueue(agentId, beadId);\n      console.log(chalk.green(`Queued: ${beadId}`));\n      break;\n    }\n\n    case 'show': {\n      const hook = getHook(agentId);\n      console.log(JSON.stringify(hook, null, 2));\n      break;\n    }\n\n    case 'stats': {\n      printAgentStats(agentId);\n      break;\n    }\n\n    case 'recovery': {\n      printRecoveryInfo(agentId);\n      break;\n    }\n\n    default:\n      console.error(chalk.red(`Unknown subcommand: ${subcommand}`));\n      console.log('Available: check, assign, complete, queue, show, stats, recovery');\n  }\n}\n```\n\n---\n\n## Verification Checklist\n\n```bash\n# 1. Build\nnpm run build\n# Expected: No errors\n\n# 2. Test hook check (empty)\nnode dist/cli/index.js work hook check agent-test-1\n# Expected: \"No work assigned.\"\n\n# 3. Test hook assign\nnode dist/cli/index.js work hook assign agent-test-1 test-bead-id\n# Expected: \"Assigned: test-bead-id\"\n\n# 4. Test hook check (with work)\nnode dist/cli/index.js work hook check agent-test-1\n# Expected: \"Current work: test-bead-id\"\n\n# 5. Test hook complete\nnode dist/cli/index.js work hook complete agent-test-1\n# Expected: \"Completed. No more work in queue.\"\n\n# 6. Test stats\nnode dist/cli/index.js work hook stats agent-test-1\n# Expected: Shows agent statistics\n\n# 7. Check state file\ncat ~/.panopticon/agents/agent-test-1/hook.json\n# Expected: JSON with hook data\n\n# 8. Check CV file\ncat ~/.panopticon/agents/agent-test-1/cv.json\n# Expected: JSON with CV data\n```\n\n---\n\n## Common Gotchas\n\n1. **bd not installed** - Install beads CLI first\n2. **bd command fails** - Check beads is initialized in repo\n3. **Actor format** - Must be \"panopticon/agent-xxx\"\n4. **JSON parse errors** - Check hook.json is valid JSON\n5. **Permissions** - Ensure write access to ~/.panopticon/\n\n---\n\n## Dependencies on Other Phases\n\n- **Depends on**: Phase 1 (paths), Phase 3 (agents)\n- **Blocks**: Phase 11 (health uses agent state)","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-17T18:06:51.141034166-08:00","created_by":"eltmon","updated_at":"2026-01-17T18:35:57.808122536-08:00","labels":["beads","persistence"],"dependencies":[{"issue_id":"panopticon-6ax.10","depends_on_id":"panopticon-6ax","type":"parent-child","created_at":"2026-01-17T18:06:51.154821461-08:00","created_by":"eltmon"}]}
{"id":"panopticon-6ax.11","title":"Phase 11: Health Monitoring \u0026 Stuck Detection","description":"Implement stuck detection and health monitoring using the Deacon pattern from Gastown.\n\n## Prerequisites\n- Phase 3 complete (agents library, tmux)\n- Phase 4 complete (dashboard API)\n- Phase 10 complete (agent state persistence)\n\n## Acceptance Criteria (Testable)\n- [ ] `pan health` shows status of all agents\n- [ ] Health check runs every 30 seconds (configurable)\n- [ ] Agent marked \"stuck\" after 3 consecutive failures\n- [ ] Stuck agent auto-recovered (killed + respawned)\n- [ ] 5-minute cooldown prevents recovery loops\n- [ ] Dashboard shows health status with color badges\n\n---\n\n## Step 1: Define Health Constants (src/lib/health/constants.ts)\n\n```typescript\n// Deacon pattern constants from Gastown\nexport const DEFAULT_PING_TIMEOUT = 30 * 1000;        // 30 seconds\nexport const DEFAULT_CONSECUTIVE_FAILURES = 3;         // failures before stuck\nexport const DEFAULT_COOLDOWN = 5 * 60 * 1000;        // 5 minutes\nexport const DEFAULT_CHECK_INTERVAL = 30 * 1000;       // 30 seconds\n\nexport type HealthStatus = 'healthy' | 'warning' | 'stuck' | 'dead';\n\nexport interface HealthConfig {\n  pingTimeout: number;\n  consecutiveFailures: number;\n  cooldown: number;\n  checkInterval: number;\n  enabled: boolean;\n}\n\nexport function loadHealthConfig(): HealthConfig {\n  // TODO: Load from config.toml\n  return {\n    pingTimeout: DEFAULT_PING_TIMEOUT,\n    consecutiveFailures: DEFAULT_CONSECUTIVE_FAILURES,\n    cooldown: DEFAULT_COOLDOWN,\n    checkInterval: DEFAULT_CHECK_INTERVAL,\n    enabled: true,\n  };\n}\n```\n\n---\n\n## Step 2: Create Health State Module (src/lib/health/state.ts)\n\n```typescript\nimport { existsSync, readFileSync, writeFileSync, mkdirSync } from 'fs';\nimport { join } from 'path';\nimport { AGENTS_DIR } from '../paths.js';\nimport { HealthStatus } from './constants.js';\n\nexport interface AgentHealth {\n  agentId: string;\n  status: HealthStatus;\n  consecutiveFailures: number;\n  lastPing?: Date;\n  lastResponse?: Date;\n  lastForceKill?: Date;\n  forceKillCount: number;\n  inCooldown: boolean;\n}\n\nfunction getHealthPath(agentId: string): string {\n  return join(AGENTS_DIR, agentId, 'health.json');\n}\n\nexport function getAgentHealth(agentId: string): AgentHealth {\n  const healthPath = getHealthPath(agentId);\n\n  if (!existsSync(healthPath)) {\n    return {\n      agentId,\n      status: 'healthy',\n      consecutiveFailures: 0,\n      forceKillCount: 0,\n      inCooldown: false,\n    };\n  }\n\n  const content = readFileSync(healthPath, 'utf8');\n  const data = JSON.parse(content);\n\n  // Convert date strings back to Date objects\n  return {\n    ...data,\n    lastPing: data.lastPing ? new Date(data.lastPing) : undefined,\n    lastResponse: data.lastResponse ? new Date(data.lastResponse) : undefined,\n    lastForceKill: data.lastForceKill ? new Date(data.lastForceKill) : undefined,\n  };\n}\n\nexport function saveAgentHealth(health: AgentHealth): void {\n  const healthPath = getHealthPath(health.agentId);\n  const dir = join(AGENTS_DIR, health.agentId);\n\n  mkdirSync(dir, { recursive: true });\n  writeFileSync(healthPath, JSON.stringify(health, null, 2));\n}\n\nexport function updateHealthStatus(agentId: string, status: HealthStatus): void {\n  const health = getAgentHealth(agentId);\n  health.status = status;\n  saveAgentHealth(health);\n}\n\nexport function recordPing(agentId: string): void {\n  const health = getAgentHealth(agentId);\n  health.lastPing = new Date();\n  saveAgentHealth(health);\n}\n\nexport function recordResponse(agentId: string): void {\n  const health = getAgentHealth(agentId);\n  health.lastResponse = new Date();\n  health.consecutiveFailures = 0;\n  health.status = 'healthy';\n  saveAgentHealth(health);\n}\n\nexport function recordFailure(agentId: string): number {\n  const health = getAgentHealth(agentId);\n  health.consecutiveFailures++;\n\n  if (health.consecutiveFailures \u003e= 3) {\n    health.status = 'stuck';\n  } else if (health.consecutiveFailures \u003e= 1) {\n    health.status = 'warning';\n  }\n\n  saveAgentHealth(health);\n  return health.consecutiveFailures;\n}\n\nexport function recordForceKill(agentId: string): void {\n  const health = getAgentHealth(agentId);\n  health.lastForceKill = new Date();\n  health.forceKillCount++;\n  health.inCooldown = true;\n  health.consecutiveFailures = 0;\n  health.status = 'dead';\n  saveAgentHealth(health);\n}\n\nexport function checkCooldown(agentId: string, cooldownMs: number): boolean {\n  const health = getAgentHealth(agentId);\n\n  if (!health.lastForceKill) {\n    health.inCooldown = false;\n    saveAgentHealth(health);\n    return false;\n  }\n\n  const timeSinceKill = Date.now() - new Date(health.lastForceKill).getTime();\n  health.inCooldown = timeSinceKill \u003c cooldownMs;\n  saveAgentHealth(health);\n\n  return health.inCooldown;\n}\n```\n\n---\n\n## Step 3: Create Health Monitor (src/lib/health/monitor.ts)\n\n```typescript\nimport { execSync } from 'child_process';\nimport { readdirSync, existsSync } from 'fs';\nimport { AGENTS_DIR } from '../paths.js';\nimport { sessionExists, sendKeys, capturePane } from '../tmux.js';\nimport { getAgentState } from '../beads/recovery.js';\nimport {\n  getAgentHealth,\n  recordPing,\n  recordResponse,\n  recordFailure,\n  recordForceKill,\n  checkCooldown,\n  AgentHealth,\n} from './state.js';\nimport { loadHealthConfig, HealthConfig } from './constants.js';\n\nconst HEALTH_CHECK_MARKER = '___PANOPTICON_HEALTH_CHECK___';\n\nexport class HealthMonitor {\n  private config: HealthConfig;\n  private intervalId?: NodeJS.Timeout;\n\n  constructor(config?: Partial\u003cHealthConfig\u003e) {\n    this.config = { ...loadHealthConfig(), ...config };\n  }\n\n  start(): void {\n    if (!this.config.enabled) {\n      console.log('Health monitoring disabled');\n      return;\n    }\n\n    console.log(`Starting health monitor (interval: ${this.config.checkInterval}ms)`);\n\n    // Initial check\n    this.checkAll();\n\n    // Schedule periodic checks\n    this.intervalId = setInterval(() =\u003e {\n      this.checkAll();\n    }, this.config.checkInterval);\n  }\n\n  stop(): void {\n    if (this.intervalId) {\n      clearInterval(this.intervalId);\n      this.intervalId = undefined;\n    }\n  }\n\n  async checkAll(): Promise\u003cAgentHealth[]\u003e {\n    const agents = this.getRunningAgents();\n    const results: AgentHealth[] = [];\n\n    for (const agentId of agents) {\n      const health = await this.checkAgent(agentId);\n      results.push(health);\n    }\n\n    return results;\n  }\n\n  async checkAgent(agentId: string): Promise\u003cAgentHealth\u003e {\n    // Check if in cooldown\n    if (checkCooldown(agentId, this.config.cooldown)) {\n      console.log(`Agent ${agentId} in cooldown, skipping check`);\n      return getAgentHealth(agentId);\n    }\n\n    // Record ping attempt\n    recordPing(agentId);\n\n    // Check if tmux session exists\n    if (!sessionExists(agentId)) {\n      recordFailure(agentId);\n      return getAgentHealth(agentId);\n    }\n\n    // Send health check nudge\n    try {\n      sendKeys(agentId, HEALTH_CHECK_MARKER);\n    } catch (error) {\n      recordFailure(agentId);\n      return getAgentHealth(agentId);\n    }\n\n    // Wait for response (check terminal output)\n    const responded = await this.waitForResponse(agentId);\n\n    if (responded) {\n      recordResponse(agentId);\n    } else {\n      const failures = recordFailure(agentId);\n\n      // Check if stuck (3 consecutive failures)\n      if (failures \u003e= this.config.consecutiveFailures) {\n        console.log(`Agent ${agentId} is stuck (${failures} failures)`);\n        await this.handleStuckAgent(agentId);\n      }\n    }\n\n    return getAgentHealth(agentId);\n  }\n\n  private async waitForResponse(agentId: string): Promise\u003cboolean\u003e {\n    const startTime = Date.now();\n\n    while (Date.now() - startTime \u003c this.config.pingTimeout) {\n      await this.sleep(1000);\n\n      // Check if agent is still active (producing output)\n      const output = capturePane(agentId, 10);\n\n      // Look for recent activity (not just our health check marker)\n      if (output \u0026\u0026 !output.includes(HEALTH_CHECK_MARKER)) {\n        return true;\n      }\n    }\n\n    return false;\n  }\n\n  private async handleStuckAgent(agentId: string): Promise\u003cvoid\u003e {\n    console.log(`Handling stuck agent: ${agentId}`);\n\n    // Record force kill\n    recordForceKill(agentId);\n\n    // Kill the tmux session\n    try {\n      execSync(`tmux kill-session -t ${agentId}`);\n    } catch (error) {\n      console.error(`Failed to kill session ${agentId}:`, error);\n    }\n\n    // Get agent state for respawn\n    const state = getAgentState(agentId);\n    if (!state) {\n      console.log(`No state found for ${agentId}, cannot respawn`);\n      return;\n    }\n\n    // Respawn (implement in agent module)\n    console.log(`Would respawn agent ${agentId} for issue ${state.issueId}`);\n    // TODO: Call agent respawn with crash recovery\n  }\n\n  private getRunningAgents(): string[] {\n    if (!existsSync(AGENTS_DIR)) {\n      return [];\n    }\n\n    return readdirSync(AGENTS_DIR, { withFileTypes: true })\n      .filter((d) =\u003e d.isDirectory() \u0026\u0026 d.name.startsWith('agent-'))\n      .map((d) =\u003e d.name);\n  }\n\n  private sleep(ms: number): Promise\u003cvoid\u003e {\n    return new Promise((resolve) =\u003e setTimeout(resolve, ms));\n  }\n}\n```\n\n---\n\n## Step 4: Create Health CLI Command (src/cli/commands/health.ts)\n\n```typescript\nimport chalk from 'chalk';\nimport { readdirSync, existsSync } from 'fs';\nimport { AGENTS_DIR } from '../lib/paths.js';\nimport { getAgentHealth, AgentHealth } from '../lib/health/state.js';\nimport { sessionExists } from '../lib/tmux.js';\n\ninterface HealthOptions {\n  json?: boolean;\n  watch?: boolean;\n}\n\nexport async function healthCommand(options: HealthOptions): Promise\u003cvoid\u003e {\n  const agents = getAgentIds();\n\n  if (agents.length === 0) {\n    console.log(chalk.dim('No agents found.'));\n    return;\n  }\n\n  const healths = agents.map((id) =\u003e ({\n    ...getAgentHealth(id),\n    tmuxActive: sessionExists(id),\n  }));\n\n  if (options.json) {\n    console.log(JSON.stringify(healths, null, 2));\n    return;\n  }\n\n  if (options.watch) {\n    await watchHealth(agents);\n    return;\n  }\n\n  printHealthTable(healths);\n}\n\nfunction getAgentIds(): string[] {\n  if (!existsSync(AGENTS_DIR)) {\n    return [];\n  }\n\n  return readdirSync(AGENTS_DIR, { withFileTypes: true })\n    .filter((d) =\u003e d.isDirectory() \u0026\u0026 d.name.startsWith('agent-'))\n    .map((d) =\u003e d.name);\n}\n\nfunction printHealthTable(healths: (AgentHealth \u0026 { tmuxActive: boolean })[]): void {\n  console.log(chalk.bold('\\nAgent Health\\n'));\n\n  const statusColors = {\n    healthy: chalk.green,\n    warning: chalk.yellow,\n    stuck: chalk.hex('#FFA500'),  // Orange\n    dead: chalk.red,\n  };\n\n  console.log(\n    chalk.dim(\n      'Agent'.padEnd(25) +\n      'Status'.padEnd(10) +\n      'Failures'.padEnd(10) +\n      'tmux'.padEnd(8) +\n      'Cooldown'\n    )\n  );\n  console.log(chalk.dim('-'.repeat(60)));\n\n  for (const health of healths) {\n    const statusColor = statusColors[health.status] || chalk.white;\n    const tmuxStatus = health.tmuxActive ? chalk.green('yes') : chalk.red('no');\n    const cooldown = health.inCooldown ? chalk.yellow('yes') : chalk.dim('no');\n\n    console.log(\n      health.agentId.padEnd(25) +\n      statusColor(health.status.padEnd(10)) +\n      String(health.consecutiveFailures).padEnd(10) +\n      tmuxStatus.padEnd(8) +\n      cooldown\n    );\n  }\n\n  console.log('');\n}\n\nasync function watchHealth(agents: string[]): Promise\u003cvoid\u003e {\n  console.log(chalk.dim('Watching health (Ctrl+C to stop)...\\n'));\n\n  const interval = setInterval(() =\u003e {\n    console.clear();\n    const healths = agents.map((id) =\u003e ({\n      ...getAgentHealth(id),\n      tmuxActive: sessionExists(id),\n    }));\n    printHealthTable(healths);\n    console.log(chalk.dim(`Last updated: ${new Date().toLocaleTimeString()}`));\n  }, 2000);\n\n  process.on('SIGINT', () =\u003e {\n    clearInterval(interval);\n    process.exit(0);\n  });\n\n  // Keep running\n  await new Promise(() =\u003e {});\n}\n```\n\n---\n\n## Step 5: Register Health Command\n\nUpdate src/cli/index.ts:\n\n```typescript\nimport { healthCommand } from './commands/health.js';\n\nprogram\n  .command('health')\n  .description('Show agent health status')\n  .option('--json', 'Output as JSON')\n  .option('--watch', 'Watch mode with live updates')\n  .action(healthCommand);\n```\n\n---\n\n## Step 6: Add Health Monitor to Dashboard API\n\nUpdate src/dashboard/server/index.ts:\n\n```typescript\nimport { HealthMonitor } from '../../lib/health/monitor.js';\nimport { getAgentHealth } from '../../lib/health/state.js';\n\n// Start health monitor\nconst healthMonitor = new HealthMonitor();\nhealthMonitor.start();\n\n// Health endpoint\napp.get('/api/health/agents', (req, res) =\u003e {\n  const agents = getAgentIds();\n  const healths = agents.map((id) =\u003e getAgentHealth(id));\n  res.json(healths);\n});\n\n// Graceful shutdown\nprocess.on('SIGTERM', () =\u003e {\n  healthMonitor.stop();\n  process.exit(0);\n});\n```\n\n---\n\n## Step 7: Add Health Badge to Dashboard\n\nCreate src/dashboard/frontend/src/components/HealthBadge.tsx:\n\n```typescript\nimport React from 'react';\n\ninterface Props {\n  status: 'healthy' | 'warning' | 'stuck' | 'dead';\n  failures?: number;\n}\n\nexport function HealthBadge({ status, failures }: Props) {\n  const colors = {\n    healthy: 'bg-green-500',\n    warning: 'bg-yellow-500',\n    stuck: 'bg-orange-500',\n    dead: 'bg-red-500',\n  };\n\n  return (\n    \u003cspan className={`inline-flex items-center px-2 py-1 rounded text-xs font-medium text-white ${colors[status]}`}\u003e\n      {status}\n      {failures !== undefined \u0026\u0026 failures \u003e 0 \u0026\u0026 (\n        \u003cspan className=\"ml-1 opacity-75\"\u003e({failures})\u003c/span\u003e\n      )}\n    \u003c/span\u003e\n  );\n}\n```\n\n---\n\n## Step 8: Create Health Grid Component\n\nCreate src/dashboard/frontend/src/components/HealthGrid.tsx:\n\n```typescript\nimport React from 'react';\nimport { useQuery } from '@tanstack/react-query';\nimport { HealthBadge } from './HealthBadge';\n\ninterface AgentHealth {\n  agentId: string;\n  status: 'healthy' | 'warning' | 'stuck' | 'dead';\n  consecutiveFailures: number;\n  inCooldown: boolean;\n  forceKillCount: number;\n}\n\nexport function HealthGrid() {\n  const { data: healths, isLoading } = useQuery\u003cAgentHealth[]\u003e({\n    queryKey: ['agent-health'],\n    queryFn: async () =\u003e {\n      const res = await fetch('/api/health/agents');\n      return res.json();\n    },\n    refetchInterval: 5000,\n  });\n\n  if (isLoading) {\n    return \u003cdiv className=\"text-gray-400\"\u003eLoading health data...\u003c/div\u003e;\n  }\n\n  if (!healths || healths.length === 0) {\n    return \u003cdiv className=\"text-gray-400\"\u003eNo agents to monitor.\u003c/div\u003e;\n  }\n\n  return (\n    \u003cdiv className=\"grid grid-cols-4 gap-4\"\u003e\n      {healths.map((health) =\u003e (\n        \u003cdiv\n          key={health.agentId}\n          className=\"bg-gray-700 rounded-lg p-4 text-center\"\n        \u003e\n          \u003cdiv className=\"mb-2\"\u003e\n            \u003cHealthBadge status={health.status} failures={health.consecutiveFailures} /\u003e\n          \u003c/div\u003e\n          \u003cdiv className=\"font-medium text-sm truncate\"\u003e{health.agentId}\u003c/div\u003e\n          {health.inCooldown \u0026\u0026 (\n            \u003cdiv className=\"text-xs text-yellow-400 mt-1\"\u003eIn cooldown\u003c/div\u003e\n          )}\n          {health.forceKillCount \u003e 0 \u0026\u0026 (\n            \u003cdiv className=\"text-xs text-red-400 mt-1\"\u003e\n              Kills: {health.forceKillCount}\n            \u003c/div\u003e\n          )}\n        \u003c/div\u003e\n      ))}\n    \u003c/div\u003e\n  );\n}\n```\n\n---\n\n## Verification Checklist\n\n```bash\n# 1. Build\nnpm run build\n# Expected: No errors\n\n# 2. Test health command (empty)\nnode dist/cli/index.js health\n# Expected: \"No agents found\" or health table\n\n# 3. Create test agent\nmkdir -p ~/.panopticon/agents/agent-test-health\necho '{}' \u003e ~/.panopticon/agents/agent-test-health/state.json\n\n# 4. Test health again\nnode dist/cli/index.js health\n# Expected: Shows agent-test-health with status\n\n# 5. Test JSON output\nnode dist/cli/index.js health --json\n# Expected: JSON array of health objects\n\n# 6. Check health file created\ncat ~/.panopticon/agents/agent-test-health/health.json\n# Expected: JSON with health data\n\n# 7. Test dashboard endpoint\ncurl http://localhost:3002/api/health/agents\n# Expected: JSON array of health objects\n\n# 8. Cleanup test agent\nrm -rf ~/.panopticon/agents/agent-test-health\n```\n\n---\n\n## Common Gotchas\n\n1. **tmux not running** - Health check will mark agent as failed\n2. **No agents directory** - Create with `pan init`\n3. **Cooldown blocking recovery** - Wait 5 minutes or clear health.json\n4. **Dashboard not updated** - Restart server after code changes\n5. **Health check marker visible** - Agent may echo it back\n\n---\n\n## Dependencies on Other Phases\n\n- **Depends on**: Phase 3 (tmux), Phase 4 (dashboard), Phase 10 (agent state)\n- **Blocks**: None (this is the monitoring layer)\n\n---\n\n## Configuration\n\nAdd to ~/.panopticon/config.toml:\n\n```toml\n[health]\nenabled = true\nping_timeout = \"30s\"       # How long to wait for response\nconsecutive_failures = 3   # Failures before marking stuck\ncooldown = \"5m\"            # Time after force-kill before retrying\ncheck_interval = \"30s\"     # How often to check\n```","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-17T18:07:13.227210714-08:00","created_by":"eltmon","updated_at":"2026-01-17T18:37:24.520434484-08:00","labels":["deacon","health"],"dependencies":[{"issue_id":"panopticon-6ax.11","depends_on_id":"panopticon-6ax","type":"parent-child","created_at":"2026-01-17T18:07:13.24210776-08:00","created_by":"eltmon"}]}
{"id":"panopticon-6ax.12","title":"Phase 12: Context Engineering","description":"Implement dynamic context discovery and structured context files from Cursor and GSD-Plus patterns.\n\n## Prerequisites\n- Phase 1 complete (paths, config)\n- Phase 5 complete (workspace creation)\n- Phase 10 complete (agent state)\n\n## Acceptance Criteria (Testable)\n- [ ] Tool outputs written to ~/.panopticon/context/materialized/\n- [ ] Session history saved to ~/.panopticon/context/history/\n- [ ] Skills index generated at ~/.panopticon/skills/index.json\n- [ ] STATE.md created in workspace with agent position\n- [ ] WORKSPACE.md created with project context\n- [ ] SUMMARY.md created after work completion\n\n---\n\n## Step 1: Create Directory Structure\n\n```bash\nmkdir -p ~/.panopticon/context/{materialized,history,cache}\nmkdir -p ~/.panopticon/templates/context\n```\n\n---\n\n## Step 2: Create Materialization Module (src/lib/context/materialization.ts)\n\n```typescript\nimport { writeFileSync, mkdirSync, existsSync } from 'fs';\nimport { join } from 'path';\nimport { execSync } from 'child_process';\nimport { PANOPTICON_HOME } from '../paths.js';\n\nconst MATERIALIZED_DIR = join(PANOPTICON_HOME, 'context', 'materialized');\n\nexport interface MaterializeOptions {\n  agentId?: string;\n  command: string;\n  maxSize?: number;  // Max bytes to store\n}\n\nexport interface MaterializedOutput {\n  path: string;\n  size: number;\n  lines: number;\n  timestamp: Date;\n}\n\nexport function materializeOutput(output: string, options: MaterializeOptions): MaterializedOutput {\n  // Create directory structure\n  const subDir = options.agentId || 'shared';\n  const dir = join(MATERIALIZED_DIR, subDir);\n  mkdirSync(dir, { recursive: true });\n\n  // Generate filename from command\n  const timestamp = new Date().toISOString().replace(/[:.]/g, '-');\n  const cmdSlug = options.command.slice(0, 30).replace(/[^a-zA-Z0-9]/g, '_');\n  const filename = `${timestamp}_${cmdSlug}.log`;\n  const path = join(dir, filename);\n\n  // Truncate if too large\n  let content = output;\n  const maxSize = options.maxSize || 1024 * 1024; // 1MB default\n  if (content.length \u003e maxSize) {\n    content = content.slice(0, maxSize) + '\\n\\n[OUTPUT TRUNCATED]\\n';\n  }\n\n  // Write file\n  writeFileSync(path, content);\n\n  return {\n    path,\n    size: content.length,\n    lines: content.split('\\n').length,\n    timestamp: new Date(),\n  };\n}\n\nexport function runAndMaterialize(command: string, options?: Partial\u003cMaterializeOptions\u003e): MaterializedOutput {\n  try {\n    const output = execSync(command, { encoding: 'utf8', maxBuffer: 10 * 1024 * 1024 });\n    return materializeOutput(output, { command, ...options });\n  } catch (error: any) {\n    const output = error.stdout || error.stderr || error.message;\n    return materializeOutput(output, { command, ...options });\n  }\n}\n\nexport function getDiscoveryHint(materialized: MaterializedOutput): string {\n  return `Output written to ${materialized.path} (${materialized.lines} lines). Use grep/tail to inspect.`;\n}\n```\n\n---\n\n## Step 3: Create History Module (src/lib/context/history.ts)\n\n```typescript\nimport { writeFileSync, readFileSync, mkdirSync, existsSync, appendFileSync } from 'fs';\nimport { join } from 'path';\nimport { PANOPTICON_HOME } from '../paths.js';\n\nconst HISTORY_DIR = join(PANOPTICON_HOME, 'context', 'history', 'sessions');\n\nexport interface HistoryEntry {\n  timestamp: Date;\n  role: 'user' | 'assistant' | 'system';\n  content: string;\n}\n\nexport interface Decision {\n  timestamp: Date;\n  decision: string;\n  context?: string;\n}\n\nexport interface Artifact {\n  timestamp: Date;\n  type: 'file' | 'commit' | 'command';\n  path: string;\n  description?: string;\n}\n\nfunction getSessionDir(agentId: string, date?: Date): string {\n  const d = date || new Date();\n  const dateStr = d.toISOString().split('T')[0];\n  return join(HISTORY_DIR, `${dateStr}-${agentId}`);\n}\n\nexport function recordMessage(agentId: string, entry: HistoryEntry): void {\n  const dir = getSessionDir(agentId);\n  mkdirSync(dir, { recursive: true });\n\n  const transcriptPath = join(dir, 'transcript.md');\n  const rolePrefix = entry.role === 'user' ? 'User' : entry.role === 'assistant' ? 'Assistant' : 'System';\n  const line = `\\n## ${rolePrefix} (${entry.timestamp.toISOString()})\\n\\n${entry.content}\\n`;\n\n  appendFileSync(transcriptPath, line);\n}\n\nexport function recordDecision(agentId: string, decision: Decision): void {\n  const dir = getSessionDir(agentId);\n  mkdirSync(dir, { recursive: true });\n\n  const path = join(dir, 'decisions.md');\n  const line = `\\n- **${decision.timestamp.toISOString()}**: ${decision.decision}${\n    decision.context ? ` (${decision.context})` : ''\n  }\\n`;\n\n  appendFileSync(path, line);\n}\n\nexport function recordArtifact(agentId: string, artifact: Artifact): void {\n  const dir = getSessionDir(agentId);\n  mkdirSync(dir, { recursive: true });\n\n  const path = join(dir, 'artifacts.md');\n  const line = `\\n- **${artifact.type}**: ${artifact.path}${\n    artifact.description ? ` - ${artifact.description}` : ''\n  }\\n`;\n\n  appendFileSync(path, line);\n}\n\nexport function getSessionHistory(agentId: string, date?: Date): string | null {\n  const dir = getSessionDir(agentId, date);\n  const transcriptPath = join(dir, 'transcript.md');\n\n  if (!existsSync(transcriptPath)) {\n    return null;\n  }\n\n  return readFileSync(transcriptPath, 'utf8');\n}\n\nexport function searchHistory(agentId: string, query: string): string[] {\n  // Use grep to search history files\n  const baseDir = join(HISTORY_DIR);\n  const results: string[] = [];\n\n  try {\n    const { execSync } = require('child_process');\n    const output = execSync(\n      `grep -r \"${query}\" \"${baseDir}\" --include=\"*.md\" -l 2\u003e/dev/null || true`,\n      { encoding: 'utf8' }\n    );\n    return output.trim().split('\\n').filter(Boolean);\n  } catch {\n    return [];\n  }\n}\n```\n\n---\n\n## Step 4: Create Skills Index (src/lib/context/skills-index.ts)\n\n```typescript\nimport { writeFileSync, readFileSync, readdirSync, existsSync } from 'fs';\nimport { join } from 'path';\nimport { SKILLS_DIR, PANOPTICON_HOME } from '../paths.js';\n\nexport interface SkillIndexEntry {\n  name: string;\n  description: string;\n  path: string;\n}\n\nexport interface SkillIndex {\n  version: string;\n  generatedAt: Date;\n  skills: SkillIndexEntry[];\n}\n\nfunction parseSkillFrontmatter(content: string): { name?: string; description?: string } {\n  const match = content.match(/^---\\n([\\s\\S]*?)\\n---/);\n  if (!match) return {};\n\n  const frontmatter = match[1];\n  const name = frontmatter.match(/name:\\s*(.+)/)?.[1]?.trim();\n  const description = frontmatter.match(/description:\\s*(.+)/)?.[1]?.trim();\n\n  return { name, description };\n}\n\nexport function generateSkillsIndex(): SkillIndex {\n  const skills: SkillIndexEntry[] = [];\n\n  if (!existsSync(SKILLS_DIR)) {\n    return { version: '1.0', generatedAt: new Date(), skills };\n  }\n\n  const dirs = readdirSync(SKILLS_DIR, { withFileTypes: true })\n    .filter((d) =\u003e d.isDirectory());\n\n  for (const dir of dirs) {\n    const skillPath = join(SKILLS_DIR, dir.name, 'SKILL.md');\n    if (!existsSync(skillPath)) continue;\n\n    const content = readFileSync(skillPath, 'utf8');\n    const { name, description } = parseSkillFrontmatter(content);\n\n    skills.push({\n      name: name || dir.name,\n      description: description || '(no description)',\n      path: skillPath,\n    });\n  }\n\n  const index: SkillIndex = {\n    version: '1.0',\n    generatedAt: new Date(),\n    skills: skills.sort((a, b) =\u003e a.name.localeCompare(b.name)),\n  };\n\n  // Write index file\n  const indexPath = join(SKILLS_DIR, 'index.json');\n  writeFileSync(indexPath, JSON.stringify(index, null, 2));\n\n  return index;\n}\n\nexport function loadSkillsIndex(): SkillIndex | null {\n  const indexPath = join(SKILLS_DIR, 'index.json');\n  if (!existsSync(indexPath)) {\n    return null;\n  }\n\n  const content = readFileSync(indexPath, 'utf8');\n  return JSON.parse(content);\n}\n\nexport function getSkillDefinition(skillName: string): string | null {\n  const skillPath = join(SKILLS_DIR, skillName, 'SKILL.md');\n  if (!existsSync(skillPath)) {\n    return null;\n  }\n\n  return readFileSync(skillPath, 'utf8');\n}\n```\n\n---\n\n## Step 5: Create Context State Files (src/lib/context/state.ts)\n\n```typescript\nimport { writeFileSync, readFileSync, existsSync } from 'fs';\nimport { join } from 'path';\n\nexport interface StateContext {\n  issueId: string;\n  status: string;\n  lastActivity: Date;\n  workspacePath: string;\n  prdPath?: string;\n  beadsReference?: string;\n  checkpoint?: string;\n  resumePoint?: string;\n}\n\nexport function generateStateMd(workspacePath: string, context: StateContext): string {\n  return `# Agent State: ${context.issueId}\n\n## Current Position\n\nIssue: ${context.issueId}\nStatus: ${context.status}\nLast activity: ${context.lastActivity.toISOString()}\n\n## Context References\n\n- Workspace: ${context.workspacePath}\n${context.prdPath ? `- PRD: ${context.prdPath}` : ''}\n${context.beadsReference ? `- Beads: ${context.beadsReference}` : ''}\n\n## Session Continuity\n\n${context.checkpoint ? `Last checkpoint: \"${context.checkpoint}\"` : 'No checkpoint saved.'}\n${context.resumePoint ? `Resume point: \"${context.resumePoint}\"` : ''}\n`;\n}\n\nexport function writeStateMd(workspacePath: string, context: StateContext): void {\n  const content = generateStateMd(workspacePath, context);\n  const path = join(workspacePath, 'STATE.md');\n  writeFileSync(path, content);\n}\n\nexport function readStateMd(workspacePath: string): StateContext | null {\n  const path = join(workspacePath, 'STATE.md');\n  if (!existsSync(path)) return null;\n\n  // Parse STATE.md back into context (simplified)\n  const content = readFileSync(path, 'utf8');\n  const issueMatch = content.match(/Issue: (\\S+)/);\n  const statusMatch = content.match(/Status: (\\S+)/);\n\n  if (!issueMatch) return null;\n\n  return {\n    issueId: issueMatch[1],\n    status: statusMatch?.[1] || 'unknown',\n    lastActivity: new Date(),\n    workspacePath,\n  };\n}\n```\n\n---\n\n## Step 6: Create Workspace Context (src/lib/context/workspace.ts)\n\n```typescript\nimport { writeFileSync, readFileSync, existsSync } from 'fs';\nimport { join } from 'path';\n\nexport interface WorkspaceContext {\n  issueId: string;\n  description: string;\n  coreValue?: string;\n  activeWork: string[];\n  constraints: string[];\n}\n\nexport function generateWorkspaceMd(context: WorkspaceContext): string {\n  const activeWorkList = context.activeWork\n    .map((item) =\u003e `- [ ] ${item}`)\n    .join('\\n');\n\n  const constraintsList = context.constraints\n    .map((c) =\u003e `- **${c.split(':')[0]}**: ${c.split(':').slice(1).join(':')}`)\n    .join('\\n');\n\n  return `# Workspace Context: ${context.issueId}\n\n## What This Is\n\n${context.description}\n\n${context.coreValue ? `## Core Value\\n\\n${context.coreValue}\\n` : ''}\n\n## Active Work\n\n${activeWorkList || '(No active work items)'}\n\n## Constraints\n\n${constraintsList || '(No constraints defined)'}\n`;\n}\n\nexport function writeWorkspaceMd(workspacePath: string, context: WorkspaceContext): void {\n  const content = generateWorkspaceMd(context);\n  const path = join(workspacePath, 'WORKSPACE.md');\n  writeFileSync(path, content);\n}\n\nexport function readWorkspaceMd(workspacePath: string): WorkspaceContext | null {\n  const path = join(workspacePath, 'WORKSPACE.md');\n  if (!existsSync(path)) return null;\n\n  const content = readFileSync(path, 'utf8');\n  const issueMatch = content.match(/# Workspace Context: (\\S+)/);\n\n  if (!issueMatch) return null;\n\n  return {\n    issueId: issueMatch[1],\n    description: '',\n    activeWork: [],\n    constraints: [],\n  };\n}\n```\n\n---\n\n## Step 7: Create Summary Generator (src/lib/context/summary.ts)\n\n```typescript\nimport { writeFileSync } from 'fs';\nimport { join } from 'path';\n\nexport interface WorkSummary {\n  title: string;\n  completedAt: Date;\n  durationMinutes: number;\n  beadsClosed: number;\n  whatWasDone: string[];\n  keyInsights: string[];\n  filesCreatedModified: string[];\n}\n\nexport function generateSummaryMd(summary: WorkSummary): string {\n  const whatWasDoneList = summary.whatWasDone\n    .map((item, i) =\u003e `${i + 1}. ${item}`)\n    .join('\\n');\n\n  const insightsList = summary.keyInsights\n    .map((item, i) =\u003e `${i + 1}. ${item}`)\n    .join('\\n');\n\n  const filesList = summary.filesCreatedModified\n    .map((f) =\u003e `- ${f}`)\n    .join('\\n');\n\n  return `# Work Summary: ${summary.title}\n\n**Completed:** ${summary.completedAt.toISOString().split('T')[0]}\n**Duration:** ${summary.durationMinutes} minutes\n**Beads closed:** ${summary.beadsClosed}\n\n## What Was Done\n\n${whatWasDoneList || '(No items recorded)'}\n\n## Key Insights\n\n${insightsList || '(No insights recorded)'}\n\n## Files Created/Modified\n\n${filesList || '(No files recorded)'}\n`;\n}\n\nexport function writeSummaryMd(workspacePath: string, summary: WorkSummary): void {\n  const content = generateSummaryMd(summary);\n  const path = join(workspacePath, 'SUMMARY.md');\n  writeFileSync(path, content);\n}\n```\n\n---\n\n## Step 8: Create Context Budget Manager (src/lib/context/budget.ts)\n\n```typescript\nexport interface ContextBudget {\n  total: number;\n  used: number;\n  reserved: {\n    systemPrompt: number;\n    skills: number;\n    history: number;\n    workState: number;\n  };\n  available: number;\n}\n\nexport function estimateTokens(text: string): number {\n  // Rough estimate: 1 token ~= 4 characters\n  return Math.ceil(text.length / 4);\n}\n\nexport function createBudget(totalTokens: number = 200000): ContextBudget {\n  return {\n    total: totalTokens,\n    used: 0,\n    reserved: {\n      systemPrompt: 10000,\n      skills: 5000,\n      history: 20000,\n      workState: 5000,\n    },\n    available: totalTokens - 40000, // Reserved amount\n  };\n}\n\nexport function updateBudget(budget: ContextBudget, used: number): ContextBudget {\n  return {\n    ...budget,\n    used: budget.used + used,\n    available: budget.total - budget.used - used - Object.values(budget.reserved).reduce((a, b) =\u003e a + b, 0),\n  };\n}\n\nexport function shouldSummarize(budget: ContextBudget): boolean {\n  return budget.available \u003c 50000;\n}\n\nexport function getDiscoveryHints(budget: ContextBudget): string[] {\n  const hints: string[] = [];\n\n  if (shouldSummarize(budget)) {\n    hints.push('Context budget low. Using summarized history.');\n    hints.push('Full history at ~/.panopticon/context/history/');\n  }\n\n  return hints;\n}\n```\n\n---\n\n## Step 9: Update Workspace Creation to Generate Context Files\n\nUpdate src/cli/commands/workspace.ts to include:\n\n```typescript\nimport { writeStateMd, StateContext } from '../lib/context/state.js';\nimport { writeWorkspaceMd, WorkspaceContext } from '../lib/context/workspace.js';\n\n// After creating worktree, add:\nconst stateContext: StateContext = {\n  issueId: id.toUpperCase(),\n  status: 'In Progress',\n  lastActivity: new Date(),\n  workspacePath,\n};\nwriteStateMd(workspacePath, stateContext);\n\nconst workspaceContext: WorkspaceContext = {\n  issueId: id.toUpperCase(),\n  description: 'Workspace for issue ' + id,\n  activeWork: ['Review requirements', 'Implement solution', 'Write tests'],\n  constraints: [],\n};\nwriteWorkspaceMd(workspacePath, workspaceContext);\n```\n\n---\n\n## Verification Checklist\n\n```bash\n# 1. Build\nnpm run build\n# Expected: No errors\n\n# 2. Test materialization\nnode -e \"\nconst { materializeOutput } = require('./dist/lib/context/materialization.js');\nconst result = materializeOutput('test output', { command: 'test' });\nconsole.log(result);\n\"\n# Expected: Path to materialized file\n\n# 3. Check materialized file\nls ~/.panopticon/context/materialized/shared/\n# Expected: Timestamped .log file\n\n# 4. Test skills index generation\nnode -e \"\nconst { generateSkillsIndex } = require('./dist/lib/context/skills-index.js');\nconst index = generateSkillsIndex();\nconsole.log(index.skills.length, 'skills indexed');\n\"\n# Expected: Number of skills\n\n# 5. Check index file\ncat ~/.panopticon/skills/index.json\n# Expected: JSON with skills array\n\n# 6. Create workspace and check context files\nnode dist/cli/index.js workspace create TEST-123\ncat workspaces/feature-test-123/STATE.md\ncat workspaces/feature-test-123/WORKSPACE.md\n# Expected: Generated markdown files\n\n# 7. Cleanup\nnode dist/cli/index.js workspace destroy TEST-123\n```\n\n---\n\n## Common Gotchas\n\n1. **Directory not created** - Run `pan init` first\n2. **Skills not indexed** - Ensure skills exist in ~/.panopticon/skills/\n3. **Token estimation rough** - Real tokenization varies by model\n4. **History files grow large** - Implement rotation/cleanup\n5. **JSON parse errors** - Check file format before parsing\n\n---\n\n## Dependencies on Other Phases\n\n- **Depends on**: Phase 1 (paths), Phase 5 (workspace)\n- **Blocks**: None (this is context layer)","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-17T18:07:50.71993622-08:00","created_by":"eltmon","updated_at":"2026-01-17T18:38:42.76742901-08:00","labels":["context","gsd-plus"],"dependencies":[{"issue_id":"panopticon-6ax.12","depends_on_id":"panopticon-6ax","type":"parent-child","created_at":"2026-01-17T18:07:50.734282035-08:00","created_by":"eltmon"}]}
{"id":"panopticon-6ax.13","title":"Phase 13: Multi-Runtime Architecture","description":"Implement multi-runtime support for Claude, Codex, Gemini CLI, and Cursor.\n\n## Prerequisites\n- Phase 1 complete (config system)\n- Phase 3 complete (agents library)\n- At least one AI runtime installed (claude, codex, etc.)\n\n## Acceptance Criteria (Testable)\n- [ ] `pan work issue MIN-123 --runtime codex` spawns Codex agent\n- [ ] `pan work issue MIN-123 --runtime gemini` spawns Gemini CLI agent\n- [ ] Runtime config files exist in ~/.panopticon/runtimes/\n- [ ] A/B testing: Same issue with different runtimes using --alias\n- [ ] Runtime metrics collected and viewable\n- [ ] Dashboard shows runtime comparison table\n\n---\n\n## Step 1: Create Runtime Interface (src/lib/runtime/interface.ts)\n\n```typescript\nexport type PromptMode = 'file' | 'argument' | 'stdin' | 'none';\n\nexport interface RuntimeConfig {\n  name: string;\n  command: string;\n  args: string[];\n  promptMode: PromptMode;\n  contextFile?: string;  // e.g., \"CLAUDE.md\" for file-based prompting\n  healthCheckCmd?: string;\n  modelFlag?: string;  // e.g., \"--model\" for claude\n}\n\nexport interface Runtime {\n  readonly name: string;\n  readonly config: RuntimeConfig;\n\n  // Lifecycle\n  spawn(workspace: string, options: SpawnOptions): Promise\u003cstring\u003e;  // Returns session ID\n  stop(sessionId: string): Promise\u003cvoid\u003e;\n\n  // Context injection\n  injectContext(workspace: string, context: string): Promise\u003cvoid\u003e;\n\n  // Health\n  isAvailable(): Promise\u003cboolean\u003e;\n  isHealthy(sessionId: string): Promise\u003cboolean\u003e;\n}\n\nexport interface SpawnOptions {\n  model?: string;\n  prompt?: string;\n  alias?: string;  // For A/B testing\n}\n```\n\n---\n\n## Step 2: Create Runtime Presets (src/lib/runtime/presets.ts)\n\n```typescript\nimport { RuntimeConfig } from './interface.js';\n\nexport const RUNTIME_PRESETS: Record\u003cstring, RuntimeConfig\u003e = {\n  claude: {\n    name: 'claude',\n    command: 'claude',\n    args: [],\n    promptMode: 'none',  // Uses hooks and CLAUDE.md\n    contextFile: 'CLAUDE.md',\n    modelFlag: '--model',\n  },\n\n  codex: {\n    name: 'codex',\n    command: 'codex',\n    args: [],\n    promptMode: 'file',  // Reads context from file\n    contextFile: 'CLAUDE.md',  // Codex also reads CLAUDE.md\n    modelFlag: '--model',\n  },\n\n  gemini: {\n    name: 'gemini',\n    command: 'gemini',\n    args: [],\n    promptMode: 'file',\n    contextFile: 'GEMINI.md',\n    modelFlag: '--model',\n  },\n\n  cursor: {\n    name: 'cursor',\n    command: 'cursor',\n    args: ['--new-window'],\n    promptMode: 'none',  // IDE-based, no CLI prompting\n    contextFile: 'CLAUDE.md',  // Cursor reads from .claude/\n  },\n};\n\nexport function getPreset(name: string): RuntimeConfig | undefined {\n  return RUNTIME_PRESETS[name];\n}\n```\n\n---\n\n## Step 3: Create Base Runtime Implementation (src/lib/runtime/base.ts)\n\n```typescript\nimport { execSync } from 'child_process';\nimport { writeFileSync, existsSync } from 'fs';\nimport { join } from 'path';\nimport { Runtime, RuntimeConfig, SpawnOptions, PromptMode } from './interface.js';\nimport { createSession, killSession, sessionExists } from '../tmux.js';\n\nexport class BaseRuntime implements Runtime {\n  readonly name: string;\n  readonly config: RuntimeConfig;\n\n  constructor(config: RuntimeConfig) {\n    this.name = config.name;\n    this.config = config;\n  }\n\n  async spawn(workspace: string, options: SpawnOptions): Promise\u003cstring\u003e {\n    // Generate session ID\n    const alias = options.alias || this.name;\n    const sessionId = `agent-${alias}-${Date.now()}`;\n\n    // Build command\n    let cmd = this.config.command;\n\n    // Add model flag if specified\n    if (options.model \u0026\u0026 this.config.modelFlag) {\n      cmd += ` ${this.config.modelFlag} ${options.model}`;\n    }\n\n    // Add preset args\n    if (this.config.args.length \u003e 0) {\n      cmd += ' ' + this.config.args.join(' ');\n    }\n\n    // Handle prompt injection based on mode\n    if (options.prompt) {\n      await this.injectContext(workspace, options.prompt);\n\n      if (this.config.promptMode === 'argument') {\n        cmd += ` \"${options.prompt}\"`;\n      } else if (this.config.promptMode === 'stdin') {\n        cmd = `echo \"${options.prompt}\" | ${cmd}`;\n      }\n    }\n\n    // Create tmux session\n    createSession(sessionId, workspace, cmd);\n\n    return sessionId;\n  }\n\n  async stop(sessionId: string): Promise\u003cvoid\u003e {\n    if (sessionExists(sessionId)) {\n      killSession(sessionId);\n    }\n  }\n\n  async injectContext(workspace: string, context: string): Promise\u003cvoid\u003e {\n    if (this.config.contextFile) {\n      const contextPath = join(workspace, this.config.contextFile);\n      writeFileSync(contextPath, context);\n    }\n  }\n\n  async isAvailable(): Promise\u003cboolean\u003e {\n    try {\n      execSync(`which ${this.config.command}`, { stdio: 'pipe' });\n      return true;\n    } catch {\n      return false;\n    }\n  }\n\n  async isHealthy(sessionId: string): Promise\u003cboolean\u003e {\n    return sessionExists(sessionId);\n  }\n}\n```\n\n---\n\n## Step 4: Create Runtime Factory (src/lib/runtime/factory.ts)\n\n```typescript\nimport { existsSync, readFileSync } from 'fs';\nimport { join } from 'path';\nimport { PANOPTICON_HOME } from '../paths.js';\nimport { Runtime, RuntimeConfig } from './interface.js';\nimport { BaseRuntime } from './base.js';\nimport { getPreset } from './presets.js';\nimport * as TOML from '@iarna/toml';\n\nconst RUNTIMES_DIR = join(PANOPTICON_HOME, 'runtimes');\n\nexport function loadRuntimeConfig(name: string): RuntimeConfig | null {\n  // Check for custom config file\n  const configPath = join(RUNTIMES_DIR, `${name}.toml`);\n  if (existsSync(configPath)) {\n    const content = readFileSync(configPath, 'utf8');\n    const parsed = TOML.parse(content) as any;\n    return {\n      name,\n      command: parsed.runtime?.command || name,\n      args: parsed.runtime?.args || [],\n      promptMode: parsed.runtime?.prompt_mode || 'none',\n      contextFile: parsed.runtime?.context_file,\n      modelFlag: parsed.runtime?.model_flag,\n    };\n  }\n\n  // Fall back to preset\n  return getPreset(name) || null;\n}\n\nexport function createRuntime(name: string): Runtime {\n  const config = loadRuntimeConfig(name);\n  if (!config) {\n    throw new Error(`Unknown runtime: ${name}. Available: claude, codex, gemini, cursor`);\n  }\n\n  return new BaseRuntime(config);\n}\n\nexport function listAvailableRuntimes(): string[] {\n  const available: string[] = [];\n\n  // Check presets\n  for (const name of ['claude', 'codex', 'gemini', 'cursor']) {\n    const runtime = createRuntime(name);\n    runtime.isAvailable().then((ok) =\u003e {\n      if (ok) available.push(name);\n    });\n  }\n\n  return available;\n}\n```\n\n---\n\n## Step 5: Create Runtime Metrics (src/lib/runtime/metrics.ts)\n\n```typescript\nimport { existsSync, readFileSync, writeFileSync, mkdirSync } from 'fs';\nimport { join } from 'path';\nimport { PANOPTICON_HOME } from '../paths.js';\n\nconst METRICS_FILE = join(PANOPTICON_HOME, 'metrics', 'runtimes.json');\n\nexport interface TaskMetric {\n  runtime: string;\n  taskId: string;\n  success: boolean;\n  durationMinutes: number;\n  capability?: string;\n  timestamp: Date;\n}\n\nexport interface RuntimeMetrics {\n  runtime: string;\n  totalTasks: number;\n  successCount: number;\n  failureCount: number;\n  totalDurationMinutes: number;\n  byCapability: Record\u003cstring, {\n    tasks: number;\n    successCount: number;\n    totalDuration: number;\n  }\u003e;\n}\n\nfunction loadMetricsData(): TaskMetric[] {\n  if (!existsSync(METRICS_FILE)) {\n    return [];\n  }\n  const content = readFileSync(METRICS_FILE, 'utf8');\n  return JSON.parse(content);\n}\n\nfunction saveMetricsData(metrics: TaskMetric[]): void {\n  const dir = join(PANOPTICON_HOME, 'metrics');\n  mkdirSync(dir, { recursive: true });\n  writeFileSync(METRICS_FILE, JSON.stringify(metrics, null, 2));\n}\n\nexport function recordTaskCompletion(metric: TaskMetric): void {\n  const metrics = loadMetricsData();\n  metrics.push(metric);\n  saveMetricsData(metrics);\n}\n\nexport function getRuntimeMetrics(runtime: string): RuntimeMetrics {\n  const allMetrics = loadMetricsData();\n  const runtimeMetrics = allMetrics.filter((m) =\u003e m.runtime === runtime);\n\n  const result: RuntimeMetrics = {\n    runtime,\n    totalTasks: runtimeMetrics.length,\n    successCount: runtimeMetrics.filter((m) =\u003e m.success).length,\n    failureCount: runtimeMetrics.filter((m) =\u003e !m.success).length,\n    totalDurationMinutes: runtimeMetrics.reduce((sum, m) =\u003e sum + m.durationMinutes, 0),\n    byCapability: {},\n  };\n\n  // Aggregate by capability\n  for (const metric of runtimeMetrics) {\n    if (!metric.capability) continue;\n\n    if (!result.byCapability[metric.capability]) {\n      result.byCapability[metric.capability] = {\n        tasks: 0,\n        successCount: 0,\n        totalDuration: 0,\n      };\n    }\n\n    const cap = result.byCapability[metric.capability];\n    cap.tasks++;\n    if (metric.success) cap.successCount++;\n    cap.totalDuration += metric.durationMinutes;\n  }\n\n  return result;\n}\n\nexport function getAllRuntimeMetrics(): RuntimeMetrics[] {\n  const allMetrics = loadMetricsData();\n  const runtimes = [...new Set(allMetrics.map((m) =\u003e m.runtime))];\n  return runtimes.map((r) =\u003e getRuntimeMetrics(r));\n}\n```\n\n---\n\n## Step 6: Update Work Issue Command for Runtime Selection\n\nUpdate src/cli/commands/work/issue.ts:\n\n```typescript\nimport { createRuntime } from '../../lib/runtime/factory.js';\n\n// In issueCommand function:\nconst runtime = createRuntime(options.runtime || 'claude');\n\n// Check availability\nif (!await runtime.isAvailable()) {\n  spinner.fail(`Runtime '${options.runtime}' not available. Is it installed?`);\n  process.exit(1);\n}\n\n// Spawn using runtime\nconst sessionId = await runtime.spawn(workspace, {\n  model: options.model,\n  prompt: `Working on issue ${id}`,\n  alias: options.alias,\n});\n\n// Update agent state with runtime info\nconst state: AgentState = {\n  id: sessionId,\n  issueId: id,\n  workspace,\n  runtime: runtime.name,\n  model: options.model || 'default',\n  // ...\n};\n```\n\n---\n\n## Step 7: Add Runtime to CLI Options\n\nUpdate src/cli/commands/work/index.ts:\n\n```typescript\nwork\n  .command('issue \u003cid\u003e')\n  .description('Spawn agent for Linear issue')\n  .option('--model \u003cmodel\u003e', 'Model to use (sonnet/opus/haiku)', 'sonnet')\n  .option('--runtime \u003cruntime\u003e', 'AI runtime (claude/codex/gemini/cursor)', 'claude')\n  .option('--alias \u003calias\u003e', 'Alias for A/B testing')\n  .option('--dry-run', 'Show what would be created')\n  .action(issueCommand);\n```\n\n---\n\n## Step 8: Create Default Runtime Config Files\n\nCreate ~/.panopticon/runtimes/claude.toml:\n\n```toml\n[runtime]\nname = \"claude\"\ncommand = \"claude\"\nargs = []\nprompt_mode = \"none\"\ncontext_file = \"CLAUDE.md\"\nmodel_flag = \"--model\"\n```\n\nCreate ~/.panopticon/runtimes/codex.toml:\n\n```toml\n[runtime]\nname = \"codex\"\ncommand = \"codex\"\nargs = []\nprompt_mode = \"file\"\ncontext_file = \"CLAUDE.md\"\nmodel_flag = \"--model\"\n```\n\nCreate ~/.panopticon/runtimes/gemini.toml:\n\n```toml\n[runtime]\nname = \"gemini\"\ncommand = \"gemini\"\nargs = []\nprompt_mode = \"file\"\ncontext_file = \"GEMINI.md\"\nmodel_flag = \"--model\"\n```\n\n---\n\n## Step 9: Add Runtime Comparison to Dashboard\n\nCreate src/dashboard/frontend/src/components/RuntimeComparison.tsx:\n\n```typescript\nimport React from 'react';\nimport { useQuery } from '@tanstack/react-query';\n\ninterface RuntimeMetrics {\n  runtime: string;\n  totalTasks: number;\n  successCount: number;\n  totalDurationMinutes: number;\n}\n\nexport function RuntimeComparison() {\n  const { data: metrics, isLoading } = useQuery\u003cRuntimeMetrics[]\u003e({\n    queryKey: ['runtime-metrics'],\n    queryFn: async () =\u003e {\n      const res = await fetch('/api/metrics/runtimes');\n      return res.json();\n    },\n  });\n\n  if (isLoading) {\n    return \u003cdiv className=\"text-gray-400\"\u003eLoading metrics...\u003c/div\u003e;\n  }\n\n  if (!metrics || metrics.length === 0) {\n    return \u003cdiv className=\"text-gray-400\"\u003eNo runtime metrics yet.\u003c/div\u003e;\n  }\n\n  return (\n    \u003cdiv className=\"bg-gray-800 rounded-lg p-4\"\u003e\n      \u003ch2 className=\"text-lg font-semibold mb-4\"\u003eRuntime Comparison\u003c/h2\u003e\n      \u003ctable className=\"w-full text-sm\"\u003e\n        \u003cthead\u003e\n          \u003ctr className=\"text-gray-400 border-b border-gray-700\"\u003e\n            \u003cth className=\"text-left py-2\"\u003eRuntime\u003c/th\u003e\n            \u003cth className=\"text-right py-2\"\u003eTasks\u003c/th\u003e\n            \u003cth className=\"text-right py-2\"\u003eSuccess Rate\u003c/th\u003e\n            \u003cth className=\"text-right py-2\"\u003eAvg Time\u003c/th\u003e\n          \u003c/tr\u003e\n        \u003c/thead\u003e\n        \u003ctbody\u003e\n          {metrics.map((m) =\u003e {\n            const successRate = m.totalTasks \u003e 0\n              ? Math.round((m.successCount / m.totalTasks) * 100)\n              : 0;\n            const avgTime = m.totalTasks \u003e 0\n              ? Math.round(m.totalDurationMinutes / m.totalTasks)\n              : 0;\n\n            return (\n              \u003ctr key={m.runtime} className=\"border-b border-gray-700\"\u003e\n                \u003ctd className=\"py-2 font-medium\"\u003e{m.runtime}\u003c/td\u003e\n                \u003ctd className=\"py-2 text-right\"\u003e{m.totalTasks}\u003c/td\u003e\n                \u003ctd className=\"py-2 text-right\"\u003e{successRate}%\u003c/td\u003e\n                \u003ctd className=\"py-2 text-right\"\u003e{avgTime}m\u003c/td\u003e\n              \u003c/tr\u003e\n            );\n          })}\n        \u003c/tbody\u003e\n      \u003c/table\u003e\n    \u003c/div\u003e\n  );\n}\n```\n\n---\n\n## Step 10: Add Dashboard API Endpoint\n\nUpdate src/dashboard/server/index.ts:\n\n```typescript\nimport { getAllRuntimeMetrics } from '../../lib/runtime/metrics.js';\n\napp.get('/api/metrics/runtimes', (req, res) =\u003e {\n  const metrics = getAllRuntimeMetrics();\n  res.json(metrics);\n});\n```\n\n---\n\n## Verification Checklist\n\n```bash\n# 1. Build\nnpm run build\n# Expected: No errors\n\n# 2. Check which runtimes are available\nnode -e \"\nconst { createRuntime } = require('./dist/lib/runtime/factory.js');\nfor (const name of ['claude', 'codex', 'gemini', 'cursor']) {\n  const rt = createRuntime(name);\n  rt.isAvailable().then(ok =\u003e console.log(name + ':', ok ? 'available' : 'not found'));\n}\n\"\n\n# 3. Test runtime spawn with claude (if available)\nnode dist/cli/index.js work issue TEST-RT-1 --runtime claude --dry-run\n# Expected: Shows spawn details\n\n# 4. Test runtime spawn with codex (if available)\nnode dist/cli/index.js work issue TEST-RT-2 --runtime codex --dry-run\n# Expected: Shows spawn details with codex command\n\n# 5. Check runtime config files\nls ~/.panopticon/runtimes/\n# Expected: claude.toml, codex.toml, gemini.toml\n\n# 6. Test A/B spawn\nnode dist/cli/index.js work issue MIN-123 --runtime claude --alias min123-claude --dry-run\nnode dist/cli/index.js work issue MIN-123 --runtime codex --alias min123-codex --dry-run\n# Expected: Different session IDs for same issue\n\n# 7. Check metrics endpoint\ncurl http://localhost:3002/api/metrics/runtimes\n# Expected: JSON array of runtime metrics\n```\n\n---\n\n## Common Gotchas\n\n1. **Runtime not found** - Install the CLI tool (claude, codex, etc.)\n2. **Command not in PATH** - Add to shell PATH\n3. **Config file syntax** - Ensure valid TOML\n4. **Alias collision** - Use unique aliases for A/B tests\n5. **tmux session limit** - Clean up old sessions\n\n---\n\n## Dependencies on Other Phases\n\n- **Depends on**: Phase 1 (config), Phase 3 (tmux/agents)\n- **Blocks**: None (optional enhancement)\n\n---\n\n## A/B Testing Workflow\n\n```bash\n# Spawn same issue with different runtimes\npan work issue MIN-648 --runtime claude --alias min648-claude\npan work issue MIN-648 --runtime codex --alias min648-codex\n\n# Monitor both\npan work status\n\n# Compare in dashboard\n# View Runtime Comparison table\n\n# When done, kill both\npan work kill min648-claude\npan work kill min648-codex\n```","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-17T18:08:19.718089452-08:00","created_by":"eltmon","updated_at":"2026-01-17T18:39:54.802866071-08:00","labels":["multi-model","runtime"],"dependencies":[{"issue_id":"panopticon-6ax.13","depends_on_id":"panopticon-6ax","type":"parent-child","created_at":"2026-01-17T18:08:19.734828102-08:00","created_by":"eltmon"}]}
{"id":"panopticon-6ax.14","title":"Phase 14: Project Hooks","description":"Implement project-level hooks for customizable lifecycle events during workspace creation, agent completion, and releases.\n\n## Prerequisites\n- Phase 1 complete (config system with TOML parsing)\n- Phase 3 complete (agents library)\n- Phase 5 complete (workspace management)\n- All project config files in place (.panopticon/project.toml)\n\n## Acceptance Criteria (Testable)\n- [ ] `pre_workspace_create` hook runs before workspace creation\n- [ ] `post_workspace_create` hook runs after workspace is ready\n- [ ] `post_agent_complete` hook runs when agent finishes work\n- [ ] `pre_release` hook runs before npm publish/deploy\n- [ ] Hooks support variable substitution (PROJECT_ROOT, WORKSPACE, ISSUE_ID, etc.)\n- [ ] Hook failures with `required: true` abort the operation\n- [ ] Hook timeout and retry logic works as configured\n- [ ] `pan hooks list` shows all configured hooks\n- [ ] `pan hooks run \u003chook-name\u003e` manually triggers a hook\n\n---\n\n## Step 1: Create Hook Types (src/lib/hooks/types.ts)\n\n```typescript\nexport type HookEvent =\n  | 'pre_workspace_create'\n  | 'post_workspace_create'\n  | 'pre_agent_spawn'\n  | 'post_agent_spawn'\n  | 'post_agent_complete'\n  | 'pre_release'\n  | 'post_release'\n  | 'on_agent_error'\n  | 'on_health_failure';\n\nexport interface HookConfig {\n  name: string;\n  event: HookEvent;\n  command: string;\n  workingDirectory?: string;  // Defaults to PROJECT_ROOT\n  required?: boolean;         // If true, failure aborts operation\n  timeout?: number;           // Milliseconds, default 60000\n  retries?: number;           // Default 0\n  retryDelay?: number;        // Milliseconds between retries\n  env?: Record\u003cstring, string\u003e;\n  condition?: string;         // Shell condition to check before running\n}\n\nexport interface HookResult {\n  hook: string;\n  event: HookEvent;\n  success: boolean;\n  exitCode: number;\n  stdout: string;\n  stderr: string;\n  durationMs: number;\n  attempts: number;\n}\n\nexport interface HookContext {\n  PROJECT_ROOT: string;\n  PANOPTICON_HOME: string;\n  WORKSPACE?: string;\n  ISSUE_ID?: string;\n  BRANCH_NAME?: string;\n  AGENT_ID?: string;\n  VERSION?: string;\n  RUNTIME?: string;\n  MODEL?: string;\n  EXIT_CODE?: string;\n  ERROR_MESSAGE?: string;\n}\n```\n\n---\n\n## Step 2: Create Hook Configuration Loader (src/lib/hooks/config.ts)\n\n```typescript\nimport { existsSync, readFileSync } from 'fs';\nimport { join } from 'path';\nimport * as TOML from '@iarna/toml';\nimport { HookConfig, HookEvent } from './types.js';\nimport { PANOPTICON_HOME } from '../paths.js';\n\nexport function loadProjectHooks(projectRoot: string): HookConfig[] {\n  const configPath = join(projectRoot, '.panopticon', 'project.toml');\n\n  if (!existsSync(configPath)) {\n    return [];\n  }\n\n  const content = readFileSync(configPath, 'utf8');\n  const parsed = TOML.parse(content) as any;\n\n  if (!parsed.hooks) {\n    return [];\n  }\n\n  const hooks: HookConfig[] = [];\n\n  // Hooks can be defined as [[hooks]] array or [hooks.event_name]\n  if (Array.isArray(parsed.hooks)) {\n    for (const hook of parsed.hooks) {\n      hooks.push(parseHookEntry(hook));\n    }\n  } else {\n    // Object format: [hooks.pre_workspace_create]\n    for (const [event, config] of Object.entries(parsed.hooks)) {\n      if (typeof config === 'object' \u0026\u0026 config !== null) {\n        hooks.push(parseHookEntry({ event, ...(config as object) }));\n      }\n    }\n  }\n\n  return hooks;\n}\n\nfunction parseHookEntry(entry: any): HookConfig {\n  return {\n    name: entry.name || entry.event || 'unnamed',\n    event: entry.event as HookEvent,\n    command: entry.command,\n    workingDirectory: entry.working_directory || entry.workingDirectory,\n    required: entry.required ?? false,\n    timeout: parseTimeout(entry.timeout) || 60000,\n    retries: entry.retries ?? 0,\n    retryDelay: parseTimeout(entry.retry_delay) || 1000,\n    env: entry.env,\n    condition: entry.condition,\n  };\n}\n\nfunction parseTimeout(value: string | number | undefined): number | undefined {\n  if (value === undefined) return undefined;\n  if (typeof value === 'number') return value;\n\n  // Parse duration strings like \"30s\", \"5m\"\n  const match = value.match(/^(\\d+)(s|m|ms)$/);\n  if (!match) return parseInt(value, 10) || undefined;\n\n  const num = parseInt(match[1], 10);\n  switch (match[2]) {\n    case 'ms': return num;\n    case 's': return num * 1000;\n    case 'm': return num * 60 * 1000;\n    default: return num;\n  }\n}\n\nexport function loadGlobalHooks(): HookConfig[] {\n  const configPath = join(PANOPTICON_HOME, 'config.toml');\n\n  if (!existsSync(configPath)) {\n    return [];\n  }\n\n  const content = readFileSync(configPath, 'utf8');\n  const parsed = TOML.parse(content) as any;\n\n  if (!parsed.hooks) {\n    return [];\n  }\n\n  return loadProjectHooks(PANOPTICON_HOME);\n}\n\nexport function getHooksForEvent(\n  projectRoot: string,\n  event: HookEvent\n): HookConfig[] {\n  const projectHooks = loadProjectHooks(projectRoot);\n  const globalHooks = loadGlobalHooks();\n\n  // Project hooks take precedence, then global hooks\n  const allHooks = [...projectHooks, ...globalHooks];\n\n  return allHooks.filter((h) =\u003e h.event === event);\n}\n```\n\n---\n\n## Step 3: Create Hook Variable Substitution (src/lib/hooks/variables.ts)\n\n```typescript\nimport { HookContext } from './types.js';\n\nexport function substituteVariables(\n  template: string,\n  context: HookContext\n): string {\n  let result = template;\n\n  // Replace ${VAR} and $VAR patterns\n  for (const [key, value] of Object.entries(context)) {\n    if (value === undefined) continue;\n\n    // ${VAR} format\n    result = result.replace(new RegExp(`\\\\$\\\\{${key}\\\\}`, 'g'), value);\n    // $VAR format (word boundary)\n    result = result.replace(new RegExp(`\\\\$${key}(?=\\\\W|$)`, 'g'), value);\n  }\n\n  return result;\n}\n\nexport function buildContext(\n  projectRoot: string,\n  options?: Partial\u003cHookContext\u003e\n): HookContext {\n  const { PANOPTICON_HOME } = require('../paths.js');\n\n  return {\n    PROJECT_ROOT: projectRoot,\n    PANOPTICON_HOME,\n    ...options,\n  };\n}\n\nexport function substituteEnv(\n  env: Record\u003cstring, string\u003e | undefined,\n  context: HookContext\n): Record\u003cstring, string\u003e {\n  if (!env) return {};\n\n  const result: Record\u003cstring, string\u003e = {};\n\n  for (const [key, value] of Object.entries(env)) {\n    result[key] = substituteVariables(value, context);\n  }\n\n  return result;\n}\n```\n\n---\n\n## Step 4: Create Hook Runner (src/lib/hooks/runner.ts)\n\n```typescript\nimport { execSync, spawn } from 'child_process';\nimport { HookConfig, HookResult, HookContext } from './types.js';\nimport { substituteVariables, substituteEnv } from './variables.js';\n\nexport async function runHook(\n  hook: HookConfig,\n  context: HookContext\n): Promise\u003cHookResult\u003e {\n  const startTime = Date.now();\n  let attempts = 0;\n  let lastResult: HookResult | null = null;\n\n  // Check condition first\n  if (hook.condition) {\n    const conditionMet = checkCondition(hook.condition, context);\n    if (!conditionMet) {\n      return {\n        hook: hook.name,\n        event: hook.event,\n        success: true,\n        exitCode: 0,\n        stdout: 'Skipped: condition not met',\n        stderr: '',\n        durationMs: 0,\n        attempts: 0,\n      };\n    }\n  }\n\n  // Substitute variables in command\n  const command = substituteVariables(hook.command, context);\n  const workingDirectory = hook.workingDirectory\n    ? substituteVariables(hook.workingDirectory, context)\n    : context.PROJECT_ROOT;\n\n  // Build environment\n  const env = {\n    ...process.env,\n    ...context,\n    ...substituteEnv(hook.env, context),\n  };\n\n  const maxAttempts = (hook.retries || 0) + 1;\n\n  while (attempts \u003c maxAttempts) {\n    attempts++;\n\n    try {\n      const result = await executeWithTimeout(command, {\n        cwd: workingDirectory,\n        env,\n        timeout: hook.timeout || 60000,\n      });\n\n      lastResult = {\n        hook: hook.name,\n        event: hook.event,\n        success: result.exitCode === 0,\n        exitCode: result.exitCode,\n        stdout: result.stdout,\n        stderr: result.stderr,\n        durationMs: Date.now() - startTime,\n        attempts,\n      };\n\n      if (lastResult.success) {\n        return lastResult;\n      }\n\n      // Retry if configured\n      if (attempts \u003c maxAttempts) {\n        console.log(`Hook ${hook.name} failed, retrying in ${hook.retryDelay}ms...`);\n        await sleep(hook.retryDelay || 1000);\n      }\n\n    } catch (error: any) {\n      lastResult = {\n        hook: hook.name,\n        event: hook.event,\n        success: false,\n        exitCode: error.status || 1,\n        stdout: error.stdout || '',\n        stderr: error.stderr || error.message,\n        durationMs: Date.now() - startTime,\n        attempts,\n      };\n\n      if (attempts \u003c maxAttempts) {\n        await sleep(hook.retryDelay || 1000);\n      }\n    }\n  }\n\n  return lastResult!;\n}\n\ninterface ExecResult {\n  exitCode: number;\n  stdout: string;\n  stderr: string;\n}\n\nasync function executeWithTimeout(\n  command: string,\n  options: { cwd: string; env: Record\u003cstring, string\u003e; timeout: number }\n): Promise\u003cExecResult\u003e {\n  return new Promise((resolve, reject) =\u003e {\n    const child = spawn('sh', ['-c', command], {\n      cwd: options.cwd,\n      env: options.env as NodeJS.ProcessEnv,\n      stdio: ['pipe', 'pipe', 'pipe'],\n    });\n\n    let stdout = '';\n    let stderr = '';\n    let timedOut = false;\n\n    const timer = setTimeout(() =\u003e {\n      timedOut = true;\n      child.kill('SIGTERM');\n    }, options.timeout);\n\n    child.stdout?.on('data', (data) =\u003e {\n      stdout += data.toString();\n    });\n\n    child.stderr?.on('data', (data) =\u003e {\n      stderr += data.toString();\n    });\n\n    child.on('close', (code) =\u003e {\n      clearTimeout(timer);\n\n      if (timedOut) {\n        reject(new Error(`Hook timed out after ${options.timeout}ms`));\n        return;\n      }\n\n      resolve({\n        exitCode: code || 0,\n        stdout,\n        stderr,\n      });\n    });\n\n    child.on('error', (error) =\u003e {\n      clearTimeout(timer);\n      reject(error);\n    });\n  });\n}\n\nfunction checkCondition(condition: string, context: HookContext): boolean {\n  const cmd = substituteVariables(condition, context);\n\n  try {\n    execSync(cmd, { stdio: 'pipe' });\n    return true;\n  } catch {\n    return false;\n  }\n}\n\nfunction sleep(ms: number): Promise\u003cvoid\u003e {\n  return new Promise((resolve) =\u003e setTimeout(resolve, ms));\n}\n```\n\n---\n\n## Step 5: Create Hook Orchestrator (src/lib/hooks/orchestrator.ts)\n\n```typescript\nimport chalk from 'chalk';\nimport { HookConfig, HookResult, HookContext, HookEvent } from './types.js';\nimport { getHooksForEvent } from './config.js';\nimport { buildContext } from './variables.js';\nimport { runHook } from './runner.js';\n\nexport interface OrchestratorOptions {\n  projectRoot: string;\n  context?: Partial\u003cHookContext\u003e;\n  verbose?: boolean;\n  dryRun?: boolean;\n}\n\nexport interface OrchestratorResult {\n  event: HookEvent;\n  success: boolean;\n  results: HookResult[];\n  abortedBy?: string;  // Hook name that caused abort\n}\n\nexport async function runHooksForEvent(\n  event: HookEvent,\n  options: OrchestratorOptions\n): Promise\u003cOrchestratorResult\u003e {\n  const hooks = getHooksForEvent(options.projectRoot, event);\n\n  if (hooks.length === 0) {\n    return { event, success: true, results: [] };\n  }\n\n  if (options.verbose) {\n    console.log(chalk.dim(`Running ${hooks.length} hook(s) for ${event}...`));\n  }\n\n  const context = buildContext(options.projectRoot, options.context);\n  const results: HookResult[] = [];\n\n  for (const hook of hooks) {\n    if (options.verbose) {\n      console.log(chalk.dim(`  - ${hook.name}: ${hook.command}`));\n    }\n\n    if (options.dryRun) {\n      results.push({\n        hook: hook.name,\n        event: hook.event,\n        success: true,\n        exitCode: 0,\n        stdout: '[DRY RUN]',\n        stderr: '',\n        durationMs: 0,\n        attempts: 0,\n      });\n      continue;\n    }\n\n    const result = await runHook(hook, context);\n    results.push(result);\n\n    if (!result.success) {\n      if (options.verbose) {\n        console.log(chalk.red(`    FAILED (exit ${result.exitCode})`));\n        if (result.stderr) {\n          console.log(chalk.dim(`    ${result.stderr}`));\n        }\n      }\n\n      // If required hook fails, abort the entire operation\n      if (hook.required) {\n        console.error(chalk.red(`Required hook \"${hook.name}\" failed. Aborting.`));\n        return {\n          event,\n          success: false,\n          results,\n          abortedBy: hook.name,\n        };\n      }\n    } else if (options.verbose) {\n      console.log(chalk.green(`    OK (${result.durationMs}ms)`));\n    }\n  }\n\n  return {\n    event,\n    success: true,\n    results,\n  };\n}\n\n// Convenience functions for specific events\nexport async function runPreWorkspaceCreate(\n  projectRoot: string,\n  issueId: string,\n  workspace: string\n): Promise\u003cOrchestratorResult\u003e {\n  return runHooksForEvent('pre_workspace_create', {\n    projectRoot,\n    context: { ISSUE_ID: issueId, WORKSPACE: workspace },\n    verbose: true,\n  });\n}\n\nexport async function runPostWorkspaceCreate(\n  projectRoot: string,\n  issueId: string,\n  workspace: string,\n  branchName: string\n): Promise\u003cOrchestratorResult\u003e {\n  return runHooksForEvent('post_workspace_create', {\n    projectRoot,\n    context: { ISSUE_ID: issueId, WORKSPACE: workspace, BRANCH_NAME: branchName },\n    verbose: true,\n  });\n}\n\nexport async function runPostAgentComplete(\n  projectRoot: string,\n  agentId: string,\n  issueId: string,\n  exitCode: number\n): Promise\u003cOrchestratorResult\u003e {\n  return runHooksForEvent('post_agent_complete', {\n    projectRoot,\n    context: {\n      AGENT_ID: agentId,\n      ISSUE_ID: issueId,\n      EXIT_CODE: String(exitCode),\n    },\n    verbose: true,\n  });\n}\n\nexport async function runPreRelease(\n  projectRoot: string,\n  version: string\n): Promise\u003cOrchestratorResult\u003e {\n  return runHooksForEvent('pre_release', {\n    projectRoot,\n    context: { VERSION: version },\n    verbose: true,\n  });\n}\n\nexport async function runOnAgentError(\n  projectRoot: string,\n  agentId: string,\n  errorMessage: string\n): Promise\u003cOrchestratorResult\u003e {\n  return runHooksForEvent('on_agent_error', {\n    projectRoot,\n    context: { AGENT_ID: agentId, ERROR_MESSAGE: errorMessage },\n    verbose: true,\n  });\n}\n```\n\n---\n\n## Step 6: Create Hook CLI Commands (src/cli/commands/hooks.ts)\n\n```typescript\nimport chalk from 'chalk';\nimport { loadProjectHooks, loadGlobalHooks, getHooksForEvent } from '../lib/hooks/config.js';\nimport { runHook } from '../lib/hooks/runner.js';\nimport { buildContext } from '../lib/hooks/variables.js';\nimport { HookEvent } from '../lib/hooks/types.js';\n\ninterface HooksOptions {\n  global?: boolean;\n  event?: HookEvent;\n  json?: boolean;\n}\n\nexport async function hooksListCommand(options: HooksOptions): Promise\u003cvoid\u003e {\n  const projectRoot = process.cwd();\n  const projectHooks = options.global ? [] : loadProjectHooks(projectRoot);\n  const globalHooks = loadGlobalHooks();\n\n  const hooks = options.global ? globalHooks : [...projectHooks, ...globalHooks];\n\n  // Filter by event if specified\n  const filtered = options.event\n    ? hooks.filter((h) =\u003e h.event === options.event)\n    : hooks;\n\n  if (options.json) {\n    console.log(JSON.stringify(filtered, null, 2));\n    return;\n  }\n\n  if (filtered.length === 0) {\n    console.log(chalk.dim('No hooks configured.'));\n    return;\n  }\n\n  console.log(chalk.bold('\\nConfigured Hooks\\n'));\n  console.log(\n    chalk.dim(\n      'Name'.padEnd(20) +\n      'Event'.padEnd(25) +\n      'Required'.padEnd(10) +\n      'Command'\n    )\n  );\n  console.log(chalk.dim('-'.repeat(80)));\n\n  for (const hook of filtered) {\n    const required = hook.required ? chalk.yellow('yes') : chalk.dim('no');\n    const commandPreview = hook.command.length \u003e 30\n      ? hook.command.slice(0, 27) + '...'\n      : hook.command;\n\n    console.log(\n      hook.name.padEnd(20) +\n      hook.event.padEnd(25) +\n      required.padEnd(10) +\n      chalk.cyan(commandPreview)\n    );\n  }\n\n  console.log('');\n}\n\nexport async function hooksRunCommand(\n  hookName: string,\n  options: { dryRun?: boolean }\n): Promise\u003cvoid\u003e {\n  const projectRoot = process.cwd();\n  const projectHooks = loadProjectHooks(projectRoot);\n  const globalHooks = loadGlobalHooks();\n  const allHooks = [...projectHooks, ...globalHooks];\n\n  const hook = allHooks.find((h) =\u003e h.name === hookName);\n\n  if (!hook) {\n    console.error(chalk.red(`Hook not found: ${hookName}`));\n    console.log(chalk.dim('Available hooks:'));\n    for (const h of allHooks) {\n      console.log(chalk.dim(`  - ${h.name}`));\n    }\n    process.exit(1);\n  }\n\n  if (options.dryRun) {\n    console.log(chalk.dim('Dry run - would execute:'));\n    console.log(chalk.cyan(`  ${hook.command}`));\n    console.log(chalk.dim(`  Working directory: ${hook.workingDirectory || projectRoot}`));\n    return;\n  }\n\n  console.log(chalk.dim(`Running hook: ${hookName}...`));\n\n  const context = buildContext(projectRoot);\n  const result = await runHook(hook, context);\n\n  if (result.success) {\n    console.log(chalk.green(`Hook completed successfully (${result.durationMs}ms)`));\n    if (result.stdout) {\n      console.log(chalk.dim('\\nOutput:'));\n      console.log(result.stdout);\n    }\n  } else {\n    console.log(chalk.red(`Hook failed (exit code: ${result.exitCode})`));\n    if (result.stderr) {\n      console.log(chalk.red('\\nError:'));\n      console.log(result.stderr);\n    }\n    process.exit(1);\n  }\n}\n\nexport async function hooksTestCommand(event: HookEvent): Promise\u003cvoid\u003e {\n  const projectRoot = process.cwd();\n  const hooks = getHooksForEvent(projectRoot, event);\n\n  if (hooks.length === 0) {\n    console.log(chalk.dim(`No hooks configured for event: ${event}`));\n    return;\n  }\n\n  console.log(chalk.bold(`\\nTesting ${hooks.length} hook(s) for ${event}\\n`));\n\n  const context = buildContext(projectRoot, {\n    ISSUE_ID: 'TEST-123',\n    WORKSPACE: '/tmp/test-workspace',\n    BRANCH_NAME: 'feature/test-123',\n    AGENT_ID: 'agent-test-123',\n    VERSION: '1.0.0-test',\n  });\n\n  for (const hook of hooks) {\n    console.log(chalk.dim(`Running: ${hook.name}...`));\n    const result = await runHook(hook, context);\n\n    if (result.success) {\n      console.log(chalk.green(`  OK (${result.durationMs}ms, ${result.attempts} attempt(s))`));\n    } else {\n      console.log(chalk.red(`  FAILED (exit ${result.exitCode})`));\n      if (result.stderr) {\n        console.log(chalk.dim(`  ${result.stderr.split('\\n')[0]}`));\n      }\n    }\n  }\n}\n```\n\n---\n\n## Step 7: Register Hook Commands (src/cli/index.ts)\n\n```typescript\nimport { hooksListCommand, hooksRunCommand, hooksTestCommand } from './commands/hooks.js';\n\nconst hooks = program\n  .command('hooks')\n  .description('Manage project hooks');\n\nhooks\n  .command('list')\n  .description('List configured hooks')\n  .option('--global', 'Show only global hooks')\n  .option('--event \u003cevent\u003e', 'Filter by event type')\n  .option('--json', 'Output as JSON')\n  .action(hooksListCommand);\n\nhooks\n  .command('run \u003cname\u003e')\n  .description('Manually run a hook')\n  .option('--dry-run', 'Show what would be executed')\n  .action(hooksRunCommand);\n\nhooks\n  .command('test \u003cevent\u003e')\n  .description('Test all hooks for an event with mock context')\n  .action(hooksTestCommand);\n```\n\n---\n\n## Step 8: Integrate Hooks into Workspace Creation\n\nUpdate src/cli/commands/workspace.ts:\n\n```typescript\nimport { runPreWorkspaceCreate, runPostWorkspaceCreate } from '../lib/hooks/orchestrator.js';\n\nexport async function workspaceCreateCommand(id: string, options: CreateOptions): Promise\u003cvoid\u003e {\n  const projectRoot = process.cwd();\n  const workspace = join(projectRoot, 'workspaces', `feature-${id.toLowerCase()}`);\n\n  // Run pre-create hooks\n  const preResult = await runPreWorkspaceCreate(projectRoot, id, workspace);\n  if (!preResult.success) {\n    spinner.fail('Pre-workspace hooks failed');\n    process.exit(1);\n  }\n\n  // ... existing workspace creation logic ...\n\n  // Run post-create hooks\n  const postResult = await runPostWorkspaceCreate(projectRoot, id, workspace, branchName);\n  if (!postResult.success) {\n    spinner.warn('Post-workspace hooks failed (workspace was created)');\n  }\n\n  spinner.succeed(`Workspace created: ${workspace}`);\n}\n```\n\n---\n\n## Step 9: Integrate Hooks into Agent Completion\n\nUpdate src/cli/commands/work/issue.ts:\n\n```typescript\nimport { runPostAgentComplete, runOnAgentError } from '../lib/hooks/orchestrator.js';\n\n// After agent completes work:\nconst projectRoot = process.cwd();\nconst exitCode = 0; // or from agent exit\n\nconst result = await runPostAgentComplete(projectRoot, agentId, issueId, exitCode);\n\n// On agent error:\nif (agentFailed) {\n  await runOnAgentError(projectRoot, agentId, errorMessage);\n}\n```\n\n---\n\n## Step 10: Create Example Hook Configurations\n\n### Example 1: Project-level hooks (.panopticon/project.toml)\n\n```toml\n[project]\nname = \"my-project\"\n\n# Hook using table format\n[hooks.pre_workspace_create]\nname = \"validate-issue\"\ncommand = \"curl -s https://api.linear.app/v1/issues/${ISSUE_ID} | jq -e '.id'\"\nrequired = true\ntimeout = \"10s\"\n\n[hooks.post_workspace_create]\nname = \"setup-env\"\ncommand = \"./scripts/setup-workspace.sh\"\nworking_directory = \"${WORKSPACE}\"\ntimeout = \"2m\"\n\n[hooks.post_agent_complete]\nname = \"run-tests\"\ncommand = \"npm test\"\nworking_directory = \"${WORKSPACE}\"\nrequired = false\nretries = 2\nretry_delay = \"5s\"\n\n[hooks.pre_release]\nname = \"changelog\"\ncommand = \"npm run changelog\"\ncondition = \"test -f CHANGELOG.md\"\n```\n\n### Example 2: Global hooks (~/.panopticon/config.toml)\n\n```toml\n[panopticon]\nversion = \"1.0.0\"\n\n# Global hooks run for all projects\n[[hooks]]\nname = \"notify-start\"\nevent = \"post_agent_spawn\"\ncommand = \"notify-send 'Agent ${AGENT_ID} started for ${ISSUE_ID}'\"\nrequired = false\n\n[[hooks]]\nname = \"notify-complete\"\nevent = \"post_agent_complete\"\ncommand = \"notify-send 'Agent ${AGENT_ID} completed (exit ${EXIT_CODE})'\"\nrequired = false\n\n[[hooks]]\nname = \"alert-error\"\nevent = \"on_agent_error\"\ncommand = \"slack-notify '#alerts' 'Agent error: ${ERROR_MESSAGE}'\"\nrequired = false\n```\n\n### Example 3: Complex hook with multiple steps (.panopticon/project.toml)\n\n```toml\n[[hooks]]\nname = \"full-validation\"\nevent = \"pre_release\"\ncommand = \"\"\"\nnpm run lint \u0026\u0026 \\\nnpm run typecheck \u0026\u0026 \\\nnpm run test:coverage \u0026\u0026 \\\nnpm run build\n\"\"\"\nworking_directory = \"${PROJECT_ROOT}\"\nrequired = true\ntimeout = \"10m\"\nretries = 1\nenv = { NODE_ENV = \"production\", CI = \"true\" }\n```\n\n---\n\n## Verification Checklist\n\n```bash\n# 1. Build\nnpm run build\n# Expected: No errors\n\n# 2. Create test hook configuration\nmkdir -p .panopticon\ncat \u003e .panopticon/project.toml \u003c\u003c 'EOF'\n[project]\nname = \"test-project\"\n\n[hooks.pre_workspace_create]\nname = \"test-pre-hook\"\ncommand = \"echo 'Pre-workspace hook for ${ISSUE_ID}'\"\nrequired = false\n\n[hooks.post_workspace_create]\nname = \"test-post-hook\"\ncommand = \"echo 'Post-workspace hook: ${WORKSPACE}'\"\nrequired = false\nEOF\n\n# 3. List hooks\nnode dist/cli/index.js hooks list\n# Expected: Shows test-pre-hook and test-post-hook\n\n# 4. List hooks as JSON\nnode dist/cli/index.js hooks list --json\n# Expected: JSON array with hook configurations\n\n# 5. Filter hooks by event\nnode dist/cli/index.js hooks list --event pre_workspace_create\n# Expected: Shows only pre_workspace_create hooks\n\n# 6. Dry run a hook\nnode dist/cli/index.js hooks run test-pre-hook --dry-run\n# Expected: Shows command that would be executed\n\n# 7. Run a hook manually\nnode dist/cli/index.js hooks run test-pre-hook\n# Expected: \"Pre-workspace hook for\" output\n\n# 8. Test hooks for an event\nnode dist/cli/index.js hooks test pre_workspace_create\n# Expected: Runs hooks with mock context\n\n# 9. Create workspace (triggers hooks)\nnode dist/cli/index.js workspace create TEST-HOOK-1\n# Expected: Pre and post hooks execute, workspace created\n\n# 10. Check hook with required=true failure\ncat \u003e .panopticon/project.toml \u003c\u003c 'EOF'\n[hooks.pre_workspace_create]\nname = \"failing-hook\"\ncommand = \"exit 1\"\nrequired = true\nEOF\n\nnode dist/cli/index.js workspace create TEST-HOOK-2\n# Expected: Fails with \"Required hook failed\"\n\n# 11. Test timeout\ncat \u003e .panopticon/project.toml \u003c\u003c 'EOF'\n[hooks.pre_workspace_create]\nname = \"slow-hook\"\ncommand = \"sleep 10\"\ntimeout = \"2s\"\nrequired = false\nEOF\n\nnode dist/cli/index.js hooks run slow-hook\n# Expected: Times out after 2 seconds\n\n# 12. Test retries\ncat \u003e .panopticon/project.toml \u003c\u003c 'EOF'\n[hooks.pre_workspace_create]\nname = \"flaky-hook\"\ncommand = \"test -f /tmp/hook-succeeded || (touch /tmp/hook-succeeded \u0026\u0026 exit 1)\"\nretries = 2\nretry_delay = \"1s\"\nEOF\n\nrm -f /tmp/hook-succeeded\nnode dist/cli/index.js hooks run flaky-hook\n# Expected: Fails first attempt, succeeds on retry\n\n# 13. Cleanup\nrm -rf .panopticon/project.toml /tmp/hook-succeeded\n```\n\n---\n\n## Common Gotchas\n\n1. **Variable substitution not working** - Use ${VAR} format, not $VAR in TOML\n2. **Hook not found** - Check hook name matches exactly (case-sensitive)\n3. **Working directory error** - Ensure path exists before hook runs\n4. **Timeout too short** - Network commands may need longer timeouts\n5. **Required hook blocks everything** - Use required=false for optional hooks\n6. **Shell quoting issues** - Use multi-line TOML strings for complex commands\n7. **Environment variables missing** - Add to env section explicitly\n8. **Condition syntax** - Must be valid shell command that exits 0/non-0\n\n---\n\n## Dependencies on Other Phases\n\n- **Depends on**: Phase 1 (config parsing), Phase 3 (agents), Phase 5 (workspace)\n- **Blocks**: None (this is an extensibility layer)\n\n---\n\n## Hook Event Reference\n\n| Event | When Fired | Available Variables |\n|-------|-----------|---------------------|\n| `pre_workspace_create` | Before worktree created | ISSUE_ID, WORKSPACE |\n| `post_workspace_create` | After worktree ready | ISSUE_ID, WORKSPACE, BRANCH_NAME |\n| `pre_agent_spawn` | Before agent starts | ISSUE_ID, AGENT_ID, RUNTIME, MODEL |\n| `post_agent_spawn` | After agent started | ISSUE_ID, AGENT_ID, RUNTIME, MODEL |\n| `post_agent_complete` | When agent finishes | AGENT_ID, ISSUE_ID, EXIT_CODE |\n| `pre_release` | Before npm publish | VERSION |\n| `post_release` | After npm publish | VERSION |\n| `on_agent_error` | When agent crashes | AGENT_ID, ERROR_MESSAGE |\n| `on_health_failure` | When health check fails | AGENT_ID |","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-17T18:08:48.601832388-08:00","created_by":"eltmon","updated_at":"2026-01-17T18:42:57.001445468-08:00","labels":["automation","hooks"],"dependencies":[{"issue_id":"panopticon-6ax.14","depends_on_id":"panopticon-6ax","type":"parent-child","created_at":"2026-01-17T18:08:48.615299124-08:00","created_by":"eltmon"}]}
{"id":"panopticon-6ax.15","title":"Phase 15: Per-Feature Cost Tracking","description":"Implement per-feature cost tracking to know exactly how much each Linear issue costs in tokens and USD.\n\n## Prerequisites\n- Phase 3 complete (agents library with session tracking)\n- Phase 10 complete (beads integration)\n- ccusage installed (`npm install -g ccusage`)\n\n## Data Sources\n\n| Runtime | Token Data Location | Format |\n|---------|---------------------|--------|\n| Claude Code | `~/.claude/projects/\u003cpath\u003e/\u003csession\u003e.jsonl` | Per-message `usage` object |\n| Gemini CLI | `/stats` command + Billing API | API response |\n| Codex CLI | `~/.codex/sessions/\u003csession\u003e.jsonl` | `token_count` events |\n\n## Acceptance Criteria (Testable)\n- [ ] Agent state includes `sessionId` when spawned\n- [ ] `pan work issue MIN-123` records session ID in agent state\n- [ ] On agent completion, cost is calculated and saved to bead\n- [ ] `bd show MIN-123` includes cost section with tokens and USD\n- [ ] `pan cost MIN-123` shows detailed cost breakdown\n- [ ] `pan cost --daily` shows aggregate daily costs by issue\n- [ ] Dashboard shows cost per issue in Kanban cards\n- [ ] Supports Claude Code, Codex, and Gemini CLI\n\n---\n\n## Step 1: Install Dependencies\n\n```bash\ncd /home/eltmon/projects/panopticon\nnpm install litellm  # For pricing data (used by ccusage)\n```\n\n---\n\n## Step 2: Define Cost Types (src/lib/cost/types.ts)\n\n```typescript\nexport interface TokenUsage {\n  inputTokens: number;\n  outputTokens: number;\n  cacheCreationTokens: number;\n  cacheReadTokens: number;\n  totalTokens: number;\n}\n\nexport interface CostBreakdown {\n  inputCost: number;      // USD\n  outputCost: number;     // USD\n  cacheCost: number;      // USD\n  totalCost: number;      // USD\n}\n\nexport interface SessionCost {\n  sessionId: string;\n  runtime: 'claude' | 'codex' | 'gemini';\n  model: string;\n  usage: TokenUsage;\n  cost: CostBreakdown;\n  startTime: Date;\n  endTime: Date;\n  durationMs: number;\n}\n\nexport interface FeatureCost {\n  issueId: string;        // e.g., MIN-123\n  sessions: SessionCost[];\n  totalUsage: TokenUsage;\n  totalCost: CostBreakdown;\n  models: Record\u003cstring, TokenUsage\u003e;  // Breakdown by model\n}\n```\n\n---\n\n## Step 3: Create Pricing Data (src/lib/cost/pricing.ts)\n\n```typescript\n// Pricing per 1M tokens (January 2026)\n// Source: https://www.anthropic.com/pricing, OpenAI, Google\n\nexport interface ModelPricing {\n  inputPerMillion: number;\n  outputPerMillion: number;\n  cacheCreatePerMillion?: number;  // Claude-specific\n  cacheReadPerMillion?: number;    // Claude-specific\n}\n\nexport const PRICING: Record\u003cstring, ModelPricing\u003e = {\n  // Claude models\n  'claude-opus-4-5-20251101': {\n    inputPerMillion: 15.00,\n    outputPerMillion: 75.00,\n    cacheCreatePerMillion: 18.75,\n    cacheReadPerMillion: 1.50,\n  },\n  'claude-sonnet-4-20250514': {\n    inputPerMillion: 3.00,\n    outputPerMillion: 15.00,\n    cacheCreatePerMillion: 3.75,\n    cacheReadPerMillion: 0.30,\n  },\n  'claude-haiku-4-20250514': {\n    inputPerMillion: 0.80,\n    outputPerMillion: 4.00,\n    cacheCreatePerMillion: 1.00,\n    cacheReadPerMillion: 0.08,\n  },\n  // Codex/OpenAI models\n  'gpt-5': {\n    inputPerMillion: 5.00,\n    outputPerMillion: 15.00,\n  },\n  'gpt-4.5-turbo': {\n    inputPerMillion: 2.50,\n    outputPerMillion: 10.00,\n  },\n  // Gemini models\n  'gemini-3-pro': {\n    inputPerMillion: 2.00,\n    outputPerMillion: 6.00,\n  },\n  'gemini-3-flash': {\n    inputPerMillion: 0.10,\n    outputPerMillion: 0.40,\n  },\n};\n\nexport function calculateCost(\n  model: string,\n  usage: { input: number; output: number; cacheCreate?: number; cacheRead?: number }\n): number {\n  const pricing = PRICING[model] || PRICING['claude-sonnet-4-20250514']; // Default\n\n  const inputCost = (usage.input / 1_000_000) * pricing.inputPerMillion;\n  const outputCost = (usage.output / 1_000_000) * pricing.outputPerMillion;\n  const cacheCost = pricing.cacheCreatePerMillion\n    ? ((usage.cacheCreate || 0) / 1_000_000) * pricing.cacheCreatePerMillion +\n      ((usage.cacheRead || 0) / 1_000_000) * (pricing.cacheReadPerMillion || 0)\n    : 0;\n\n  return inputCost + outputCost + cacheCost;\n}\n```\n\n---\n\n## Step 4: Create JSONL Parser for Claude Code (src/lib/cost/parsers/claude.ts)\n\n```typescript\nimport { createReadStream } from 'fs';\nimport { createInterface } from 'readline';\nimport { SessionCost, TokenUsage } from '../types.js';\nimport { calculateCost, PRICING } from '../pricing.js';\n\ninterface ClaudeMessage {\n  type: string;\n  sessionId: string;\n  timestamp: string;\n  message?: {\n    model?: string;\n    usage?: {\n      input_tokens: number;\n      output_tokens: number;\n      cache_creation_input_tokens?: number;\n      cache_read_input_tokens?: number;\n    };\n  };\n}\n\nexport async function parseClaudeSession(\n  jsonlPath: string,\n  sessionId?: string\n): Promise\u003cSessionCost\u003e {\n  const usage: TokenUsage = {\n    inputTokens: 0,\n    outputTokens: 0,\n    cacheCreationTokens: 0,\n    cacheReadTokens: 0,\n    totalTokens: 0,\n  };\n\n  let model = 'claude-sonnet-4-20250514';  // Default\n  let startTime: Date | null = null;\n  let endTime: Date | null = null;\n\n  const rl = createInterface({\n    input: createReadStream(jsonlPath),\n    crlfDelay: Infinity,\n  });\n\n  for await (const line of rl) {\n    try {\n      const msg: ClaudeMessage = JSON.parse(line);\n\n      // Filter by session if specified\n      if (sessionId \u0026\u0026 msg.sessionId !== sessionId) continue;\n\n      // Track timestamps\n      if (msg.timestamp) {\n        const ts = new Date(msg.timestamp);\n        if (!startTime || ts \u003c startTime) startTime = ts;\n        if (!endTime || ts \u003e endTime) endTime = ts;\n      }\n\n      // Extract model\n      if (msg.message?.model) {\n        model = msg.message.model;\n      }\n\n      // Sum token usage\n      if (msg.message?.usage) {\n        const u = msg.message.usage;\n        usage.inputTokens += u.input_tokens || 0;\n        usage.outputTokens += u.output_tokens || 0;\n        usage.cacheCreationTokens += u.cache_creation_input_tokens || 0;\n        usage.cacheReadTokens += u.cache_read_input_tokens || 0;\n      }\n    } catch {\n      // Skip malformed lines\n    }\n  }\n\n  usage.totalTokens = usage.inputTokens + usage.outputTokens +\n                      usage.cacheCreationTokens + usage.cacheReadTokens;\n\n  const totalCost = calculateCost(model, {\n    input: usage.inputTokens,\n    output: usage.outputTokens,\n    cacheCreate: usage.cacheCreationTokens,\n    cacheRead: usage.cacheReadTokens,\n  });\n\n  return {\n    sessionId: sessionId || 'unknown',\n    runtime: 'claude',\n    model,\n    usage,\n    cost: {\n      inputCost: (usage.inputTokens / 1_000_000) * (PRICING[model]?.inputPerMillion || 3),\n      outputCost: (usage.outputTokens / 1_000_000) * (PRICING[model]?.outputPerMillion || 15),\n      cacheCost: 0, // Calculated above\n      totalCost,\n    },\n    startTime: startTime || new Date(),\n    endTime: endTime || new Date(),\n    durationMs: endTime \u0026\u0026 startTime ? endTime.getTime() - startTime.getTime() : 0,\n  };\n}\n```\n\n---\n\n## Step 5: Create Cost Tracker (src/lib/cost/tracker.ts)\n\n```typescript\nimport { join } from 'path';\nimport { existsSync, readdirSync, readFileSync, writeFileSync } from 'fs';\nimport { homedir } from 'os';\nimport { FeatureCost, SessionCost } from './types.js';\nimport { parseClaudeSession } from './parsers/claude.js';\n\nconst COST_DIR = join(homedir(), '.panopticon', 'costs');\n\nexport async function trackSessionCost(\n  issueId: string,\n  sessionId: string,\n  runtime: 'claude' | 'codex' | 'gemini'\n): Promise\u003cSessionCost | null\u003e {\n  let sessionCost: SessionCost | null = null;\n\n  if (runtime === 'claude') {\n    // Find JSONL file for this session\n    const claudeProjects = join(homedir(), '.claude', 'projects');\n    const jsonlPath = findJsonlBySession(claudeProjects, sessionId);\n\n    if (jsonlPath) {\n      sessionCost = await parseClaudeSession(jsonlPath, sessionId);\n    }\n  }\n\n  // TODO: Add codex and gemini parsers\n\n  if (sessionCost) {\n    await saveSessionCost(issueId, sessionCost);\n  }\n\n  return sessionCost;\n}\n\nfunction findJsonlBySession(projectsDir: string, sessionId: string): string | null {\n  if (!existsSync(projectsDir)) return null;\n\n  for (const project of readdirSync(projectsDir)) {\n    const projectPath = join(projectsDir, project);\n    const jsonlPath = join(projectPath, `${sessionId}.jsonl`);\n    if (existsSync(jsonlPath)) {\n      return jsonlPath;\n    }\n  }\n\n  return null;\n}\n\nasync function saveSessionCost(issueId: string, cost: SessionCost): Promise\u003cvoid\u003e {\n  const costFile = join(COST_DIR, `${issueId}.json`);\n\n  let featureCost: FeatureCost;\n\n  if (existsSync(costFile)) {\n    featureCost = JSON.parse(readFileSync(costFile, 'utf8'));\n    featureCost.sessions.push(cost);\n  } else {\n    featureCost = {\n      issueId,\n      sessions: [cost],\n      totalUsage: { ...cost.usage },\n      totalCost: { ...cost.cost },\n      models: { [cost.model]: { ...cost.usage } },\n    };\n  }\n\n  // Recalculate totals\n  featureCost.totalUsage = {\n    inputTokens: 0,\n    outputTokens: 0,\n    cacheCreationTokens: 0,\n    cacheReadTokens: 0,\n    totalTokens: 0,\n  };\n  featureCost.totalCost = {\n    inputCost: 0,\n    outputCost: 0,\n    cacheCost: 0,\n    totalCost: 0,\n  };\n  featureCost.models = {};\n\n  for (const session of featureCost.sessions) {\n    featureCost.totalUsage.inputTokens += session.usage.inputTokens;\n    featureCost.totalUsage.outputTokens += session.usage.outputTokens;\n    featureCost.totalUsage.cacheCreationTokens += session.usage.cacheCreationTokens;\n    featureCost.totalUsage.cacheReadTokens += session.usage.cacheReadTokens;\n    featureCost.totalUsage.totalTokens += session.usage.totalTokens;\n\n    featureCost.totalCost.inputCost += session.cost.inputCost;\n    featureCost.totalCost.outputCost += session.cost.outputCost;\n    featureCost.totalCost.cacheCost += session.cost.cacheCost;\n    featureCost.totalCost.totalCost += session.cost.totalCost;\n\n    if (!featureCost.models[session.model]) {\n      featureCost.models[session.model] = { ...session.usage };\n    } else {\n      const m = featureCost.models[session.model];\n      m.inputTokens += session.usage.inputTokens;\n      m.outputTokens += session.usage.outputTokens;\n      m.cacheCreationTokens += session.usage.cacheCreationTokens;\n      m.cacheReadTokens += session.usage.cacheReadTokens;\n      m.totalTokens += session.usage.totalTokens;\n    }\n  }\n\n  writeFileSync(costFile, JSON.stringify(featureCost, null, 2));\n}\n\nexport function getFeatureCost(issueId: string): FeatureCost | null {\n  const costFile = join(COST_DIR, `${issueId}.json`);\n  if (!existsSync(costFile)) return null;\n  return JSON.parse(readFileSync(costFile, 'utf8'));\n}\n```\n\n---\n\n## Step 6: Create Cost CLI Commands (src/cli/commands/cost.ts)\n\n```typescript\nimport chalk from 'chalk';\nimport { getFeatureCost, trackSessionCost } from '../lib/cost/tracker.js';\nimport { FeatureCost } from '../lib/cost/types.js';\n\ninterface CostOptions {\n  daily?: boolean;\n  json?: boolean;\n}\n\nexport async function costCommand(issueId?: string, options?: CostOptions): Promise\u003cvoid\u003e {\n  if (options?.daily) {\n    await showDailyCosts();\n    return;\n  }\n\n  if (!issueId) {\n    console.log(chalk.yellow('Usage: pan cost \u003cissue-id\u003e'));\n    console.log(chalk.dim('       pan cost --daily'));\n    return;\n  }\n\n  const cost = getFeatureCost(issueId);\n\n  if (!cost) {\n    console.log(chalk.yellow(`No cost data found for ${issueId}`));\n    return;\n  }\n\n  if (options?.json) {\n    console.log(JSON.stringify(cost, null, 2));\n    return;\n  }\n\n  displayCost(cost);\n}\n\nfunction displayCost(cost: FeatureCost): void {\n  console.log('');\n  console.log(chalk.bold(`Cost Report: ${cost.issueId}`));\n  console.log(chalk.dim('─'.repeat(50)));\n\n  // Total cost\n  console.log('');\n  console.log(chalk.bold('Total Cost: ') + chalk.green(`$${cost.totalCost.totalCost.toFixed(2)}`));\n  console.log('');\n\n  // Token breakdown\n  console.log(chalk.bold('Token Usage:'));\n  console.log(`  Input:         ${formatTokens(cost.totalUsage.inputTokens)}`);\n  console.log(`  Output:        ${formatTokens(cost.totalUsage.outputTokens)}`);\n  console.log(`  Cache Create:  ${formatTokens(cost.totalUsage.cacheCreationTokens)}`);\n  console.log(`  Cache Read:    ${formatTokens(cost.totalUsage.cacheReadTokens)}`);\n  console.log(`  ${chalk.bold('Total:')}         ${formatTokens(cost.totalUsage.totalTokens)}`);\n  console.log('');\n\n  // Cost breakdown\n  console.log(chalk.bold('Cost Breakdown:'));\n  console.log(`  Input:   $${cost.totalCost.inputCost.toFixed(4)}`);\n  console.log(`  Output:  $${cost.totalCost.outputCost.toFixed(4)}`);\n  console.log(`  Cache:   $${cost.totalCost.cacheCost.toFixed(4)}`);\n  console.log('');\n\n  // By model\n  console.log(chalk.bold('By Model:'));\n  for (const [model, usage] of Object.entries(cost.models)) {\n    const shortModel = model.replace('claude-', '').replace('-20250514', '').replace('-20251101', '');\n    console.log(`  ${shortModel}: ${formatTokens(usage.totalTokens)}`);\n  }\n  console.log('');\n\n  // Sessions\n  console.log(chalk.bold(`Sessions (${cost.sessions.length}):`));\n  for (const session of cost.sessions) {\n    const duration = formatDuration(session.durationMs);\n    console.log(`  ${session.sessionId.slice(0, 8)}... ${chalk.dim(duration)} $${session.cost.totalCost.toFixed(2)}`);\n  }\n  console.log('');\n}\n\nfunction formatTokens(n: number): string {\n  if (n \u003e= 1_000_000) return `${(n / 1_000_000).toFixed(2)}M`;\n  if (n \u003e= 1_000) return `${(n / 1_000).toFixed(1)}K`;\n  return String(n);\n}\n\nfunction formatDuration(ms: number): string {\n  const minutes = Math.floor(ms / 60000);\n  if (minutes \u003e= 60) {\n    const hours = Math.floor(minutes / 60);\n    return `${hours}h ${minutes % 60}m`;\n  }\n  return `${minutes}m`;\n}\n\nasync function showDailyCosts(): Promise\u003cvoid\u003e {\n  // TODO: Aggregate costs by day\n  console.log(chalk.yellow('Daily cost aggregation coming soon'));\n}\n```\n\n---\n\n## Step 7: Integrate Cost Tracking into Agent Completion\n\nUpdate src/cli/commands/work/issue.ts:\n\n```typescript\nimport { trackSessionCost } from '../../lib/cost/tracker.js';\n\n// When agent completes (in post-agent hook or completion handler):\nasync function onAgentComplete(agentId: string, issueId: string, sessionId: string): Promise\u003cvoid\u003e {\n  // ... existing completion logic ...\n\n  // Track cost\n  const cost = await trackSessionCost(issueId, sessionId, 'claude');\n\n  if (cost) {\n    console.log(chalk.dim(`Cost: $${cost.cost.totalCost.toFixed(2)} (${formatTokens(cost.usage.totalTokens)} tokens)`));\n\n    // Update bead with cost data\n    await execSync(`bd update ${issueId} --set-metadata cost=\"${cost.cost.totalCost.toFixed(2)}\"`);\n  }\n}\n```\n\n---\n\n## Step 8: Add Cost to Dashboard API\n\nUpdate src/dashboard/server/index.ts:\n\n```typescript\nimport { getFeatureCost } from '../../lib/cost/tracker.js';\n\n// Add cost endpoint\napp.get('/api/issues/:id/cost', (req, res) =\u003e {\n  const cost = getFeatureCost(req.params.id);\n  if (!cost) {\n    return res.status(404).json({ error: 'No cost data' });\n  }\n  res.json(cost);\n});\n\n// Update issues endpoint to include cost\napp.get('/api/issues', async (req, res) =\u003e {\n  const issues = await linearClient.issues({ ... });\n\n  const issuesWithCost = issues.nodes.map((issue) =\u003e {\n    const cost = getFeatureCost(issue.identifier);\n    return {\n      ...issue,\n      cost: cost?.totalCost.totalCost || null,\n    };\n  });\n\n  res.json(issuesWithCost);\n});\n```\n\n---\n\n## Step 9: Add Cost Badge to Kanban Cards\n\nUpdate src/dashboard/frontend/src/components/IssueCard.tsx:\n\n```typescript\ninterface Props {\n  issue: Issue \u0026 { cost?: number };\n}\n\nexport function IssueCard({ issue }: Props) {\n  return (\n    \u003cdiv className=\"bg-gray-700 rounded p-3\"\u003e\n      \u003cdiv className=\"flex justify-between items-start\"\u003e\n        \u003cspan className=\"text-sm font-medium\"\u003e{issue.title}\u003c/span\u003e\n        {issue.cost !== null \u0026\u0026 issue.cost !== undefined \u0026\u0026 (\n          \u003cspan className=\"text-xs bg-green-900 text-green-300 px-2 py-0.5 rounded\"\u003e\n            ${issue.cost.toFixed(2)}\n          \u003c/span\u003e\n        )}\n      \u003c/div\u003e\n      \u003cdiv className=\"text-xs text-gray-400 mt-1\"\u003e\n        {issue.identifier}\n      \u003c/div\u003e\n    \u003c/div\u003e\n  );\n}\n```\n\n---\n\n## Verification Checklist\n\n```bash\n# 1. Build\nnpm run build\n# Expected: No errors\n\n# 2. Get cost for an issue (assuming agent work was done)\nnode dist/cli/index.js cost MIN-123\n# Expected: Shows cost breakdown\n\n# 3. Get cost as JSON\nnode dist/cli/index.js cost MIN-123 --json\n# Expected: JSON output with sessions, totals, models\n\n# 4. Check bead includes cost\nbd show MIN-123\n# Expected: Shows cost in metadata\n\n# 5. Check dashboard API\ncurl http://localhost:3002/api/issues/MIN-123/cost\n# Expected: JSON cost data\n\n# 6. Verify Kanban shows cost badge\n# Open http://localhost:3001\n# Expected: Issues show \"$X.XX\" badge\n\n# 7. Spawn agent and verify cost tracking\nnode dist/cli/index.js work issue MIN-999\n# Wait for completion\nnode dist/cli/index.js cost MIN-999\n# Expected: Cost from the session appears\n```\n\n---\n\n## Common Gotchas\n\n1. **JSONL file not found** - Session ID must match exactly\n2. **Wrong model pricing** - Update pricing.ts for new models\n3. **Cache tokens not counted** - Check cache_creation_input_tokens field\n4. **Cost is $0** - Verify JSONL has usage objects (not all lines do)\n5. **Multiple sessions per issue** - Costs aggregate across all sessions\n6. **Different runtimes** - Each runtime has its own parser\n\n---\n\n## Dependencies on Other Phases\n\n- **Depends on**: Phase 3 (agents with sessionId), Phase 10 (beads)\n- **Blocks**: Nothing (this is a monitoring/analytics feature)\n\n---\n\n## Future Enhancements\n\n1. **Real-time cost tracking** - Show running cost during agent work\n2. **Budget alerts** - Warn when approaching budget threshold\n3. **Cost reports** - Daily/weekly/monthly aggregates\n4. **ROI calculation** - Compare cost vs story points or business value\n5. **Gemini/Codex parsers** - Full multi-runtime support","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-17T19:01:26.244588888-08:00","created_by":"eltmon","updated_at":"2026-01-17T19:01:26.244588888-08:00","labels":["cost analytics"],"dependencies":[{"issue_id":"panopticon-6ax.15","depends_on_id":"panopticon-6ax","type":"parent-child","created_at":"2026-01-17T19:01:26.260307296-08:00","created_by":"eltmon"}]}
{"id":"panopticon-6ax.2","title":"Phase 2: Skills System","description":"Create the comprehensive skills library with cross-platform sync.\n\n## Prerequisites\n- Phase 1 complete (pan init, pan sync working)\n- ~/.panopticon/skills/ directory exists\n\n## Acceptance Criteria (Testable)\n- [ ] \\`ls ~/.panopticon/skills/\\` shows 14+ skill directories\n- [ ] Each skill has valid SKILL.md with YAML frontmatter\n- [ ] \\`pan skills\\` lists all skills with descriptions\n- [ ] \\`pan sync\\` creates symlinks in ~/.claude/skills/\n- [ ] Skills work in Claude Code (test: \"/beads\" triggers skill)\n\n---\n\n## Step 1: Add Skills CLI Command\n\nAdd to src/cli/index.ts:\n\\`\\`\\`typescript\nprogram\n  .command('skills')\n  .description('List and manage skills')\n  .option('--json', 'Output as JSON')\n  .action(skillsCommand);\n\\`\\`\\`\n\nCreate src/cli/commands/skills.ts:\n\\`\\`\\`typescript\nimport { readdirSync, readFileSync, existsSync } from 'fs';\nimport { join } from 'path';\nimport chalk from 'chalk';\nimport { SKILLS_DIR } from '../../lib/paths.js';\n\ninterface SkillMeta {\n  name: string;\n  description: string;\n  path: string;\n}\n\nfunction parseSkillFrontmatter(content: string): { name?: string; description?: string } {\n  const match = content.match(/^---\\\\n([\\\\s\\\\S]*?)\\\\n---/);\n  if (!match) return {};\n  \n  const frontmatter = match[1];\n  const name = frontmatter.match(/name:\\\\s*(.+)/)?.[1]?.trim();\n  const description = frontmatter.match(/description:\\\\s*(.+)/)?.[1]?.trim();\n  \n  return { name, description };\n}\n\nexport function listSkills(): SkillMeta[] {\n  if (!existsSync(SKILLS_DIR)) return [];\n  \n  const skills: SkillMeta[] = [];\n  const dirs = readdirSync(SKILLS_DIR, { withFileTypes: true })\n    .filter(d =\u003e d.isDirectory());\n  \n  for (const dir of dirs) {\n    const skillFile = join(SKILLS_DIR, dir.name, 'SKILL.md');\n    if (!existsSync(skillFile)) continue;\n    \n    const content = readFileSync(skillFile, 'utf8');\n    const { name, description } = parseSkillFrontmatter(content);\n    \n    skills.push({\n      name: name || dir.name,\n      description: description || '(no description)',\n      path: skillFile,\n    });\n  }\n  \n  return skills.sort((a, b) =\u003e a.name.localeCompare(b.name));\n}\n\nexport async function skillsCommand(options: { json?: boolean }): Promise\u003cvoid\u003e {\n  const skills = listSkills();\n  \n  if (options.json) {\n    console.log(JSON.stringify(skills, null, 2));\n    return;\n  }\n  \n  console.log(chalk.bold(\\`\\\\nPanopticon Skills (\\${skills.length})\\\\n\\`));\n  \n  for (const skill of skills) {\n    console.log(chalk.cyan(skill.name));\n    console.log(chalk.dim(\\`  \\${skill.description}\\`));\n  }\n  \n  console.log(\\`\\\\n\\${chalk.dim('Run \"pan sync\" to sync skills to Claude Code')}\\`);\n}\n\\`\\`\\`\n\n---\n\n## Step 2: Create Skills Directory Structure\n\nEach skill follows this pattern:\n\\`\\`\\`\n~/.panopticon/skills/\n├── beads/\n│   └── SKILL.md\n├── feature-work/\n│   └── SKILL.md\n├── bug-fix/\n│   └── SKILL.md\n└── ... (14 total)\n\\`\\`\\`\n\n---\n\n## Step 3: Create All 14 Skills\n\n### Skill 1: beads (CRITICAL - task tracking)\n\nFile: \\`~/.panopticon/skills/beads/SKILL.md\\`\n\\`\\`\\`markdown\n---\nname: beads\ndescription: Git-backed task tracking for multi-session work with dependencies\n---\n\n# Beads - Task Tracking\n\nBeads is a git-backed issue tracker for work that spans sessions.\n\n## When to Use\n- Work spans multiple sessions or days\n- Tasks have dependencies or blockers\n- Need to survive conversation compaction\n- Collaboration with team (git sync)\n\n## Core Commands\n\\\\\\`\\\\\\`\\\\\\`bash\nbd ready              # Find unblocked work\nbd show \u003cid\u003e          # Get full context\nbd update \u003cid\u003e --status in_progress  # Start work\nbd notes add \u003cid\u003e \"note\"  # Add progress note (CRITICAL for compaction)\nbd close \u003cid\u003e --reason \"...\"  # Complete task\nbd sync               # Persist to git\n\\\\\\`\\\\\\`\\\\\\`\n\n## Session Protocol\n1. \\\\\\`bd ready\\\\\\` — Find unblocked work\n2. \\\\\\`bd show \u003cid\u003e\\\\\\` — Get full context\n3. \\\\\\`bd update \u003cid\u003e --status in_progress\\\\\\` — Claim it\n4. Add notes as you work (for compaction survival)\n5. \\\\\\`bd close \u003cid\u003e --reason \"...\"\\\\\\` — Complete\n6. \\\\\\`bd sync\\\\\\` — Always run at session end\n\n## Creating Issues\n\\\\\\`\\\\\\`\\\\\\`bash\nbd create \"Task title\" --type task --labels \"label1,label2\"\nbd create \"Subtask\" --parent \u003cparent-id\u003e\nbd create \"Blocked task\" --depends-on \u003cblocker-id\u003e\n\\\\\\`\\\\\\`\\\\\\`\n\\`\\`\\`\n\n### Skill 2: feature-work\n\nFile: \\`~/.panopticon/skills/feature-work/SKILL.md\\`\n\\`\\`\\`markdown\n---\nname: feature-work\ndescription: Standard workflow for implementing new features with testing\n---\n\n# Feature Work\n\nWhen implementing a new feature:\n\n## 1. Understand Requirements\n- Read the Linear/GitHub issue thoroughly\n- Check for associated PRD in \\\\\\`docs/prds/\\\\\\`\n- Identify acceptance criteria\n- Clarify ambiguities BEFORE coding\n\n## 2. Design Approach\n- Identify files that need changes\n- Consider existing patterns in codebase\n- Plan implementation (don't gold-plate)\n\n## 3. Implement\n- Follow existing code conventions\n- Make atomic, focused commits\n- Keep changes scoped to the issue\n- Commit format: \\\\\\`feat: description (ISSUE-XXX)\\\\\\`\n\n## 4. Test\n- Add tests for new functionality\n- Run full test suite\n- All tests must pass before proceeding\n\n## 5. Self-Review\n- Review your diff: \\\\\\`git diff origin/main...HEAD\\\\\\`\n- Check for: bugs, security issues, style, cruft\n- Fix issues found (don't just note them)\n\n## 6. Submit\n- Push branch: \\\\\\`git push -u origin \\$(git branch --show-current)\\\\\\`\n- Create MR/PR with clear description\n\\`\\`\\`\n\n### Skill 3: bug-fix\n\nFile: \\`~/.panopticon/skills/bug-fix/SKILL.md\\`\n\\`\\`\\`markdown\n---\nname: bug-fix\ndescription: Systematic approach to investigating and fixing bugs\n---\n\n# Bug Fix\n\nWhen fixing a bug:\n\n## 1. Reproduce\n- Confirm the bug exists\n- Document exact reproduction steps\n- Identify affected code paths\n\n## 2. Investigate Root Cause\n- Use debugger or logging to trace execution\n- Don't just fix symptoms - find the ROOT CAUSE\n- Check for similar bugs elsewhere\n\n## 3. Implement Fix\n- Make minimal, focused changes\n- Don't refactor unrelated code\n- Commit: \\\\\\`fix: description (ISSUE-XXX)\\\\\\`\n\n## 4. Add Regression Test\n- Write a test that WOULD HAVE caught this bug\n- Test should fail without fix, pass with it\n\n## 5. Verify\n- Run full test suite\n- Manually verify the fix\n- Check for unintended side effects\n\\`\\`\\`\n\n### Skill 4: code-review\n\nFile: \\`~/.panopticon/skills/code-review/SKILL.md\\`\n\\`\\`\\`markdown\n---\nname: code-review\ndescription: Comprehensive code review covering correctness, security, performance\n---\n\n# Code Review\n\nWhen reviewing code, examine these areas:\n\n## Correctness\n- Logic errors, off-by-one, null handling\n- Edge cases and boundary conditions\n- Race conditions in concurrent code\n\n## Security\n- Input validation gaps\n- Injection vulnerabilities (SQL, XSS, command)\n- Authentication/authorization bypasses\n- Sensitive data exposure\n\n## Performance\n- O(n²) where O(n) is possible\n- N+1 query patterns\n- Unnecessary allocations in hot paths\n- Missing caching opportunities\n\n## Design\n- Clear abstractions and naming\n- Single responsibility principle\n- Appropriate coupling/cohesion\n\n## Output Format\nProvide findings as:\n- **P0 (Critical)**: Must fix before merge\n- **P1 (Major)**: Should fix before merge\n- **P2 (Minor)**: Nice to fix\n- **Observations**: Non-blocking notes\n\\`\\`\\`\n\n### Skill 5: code-review-security\n\nFile: \\`~/.panopticon/skills/code-review-security/SKILL.md\\`\n\\`\\`\\`markdown\n---\nname: code-review-security\ndescription: Deep security analysis focusing on OWASP Top 10\n---\n\n# Security Review\n\nDeep security analysis focus:\n\n## OWASP Top 10 Checklist\n- [ ] Injection (SQL, NoSQL, OS, LDAP)\n- [ ] Broken Authentication\n- [ ] Sensitive Data Exposure\n- [ ] XML External Entities (XXE)\n- [ ] Broken Access Control\n- [ ] Security Misconfiguration\n- [ ] Cross-Site Scripting (XSS)\n- [ ] Insecure Deserialization\n- [ ] Using Components with Known Vulnerabilities\n- [ ] Insufficient Logging \u0026 Monitoring\n\n## Additional Checks\n- Hardcoded secrets or credentials\n- Path traversal vulnerabilities\n- SSRF (Server-Side Request Forgery)\n- Cryptographic weaknesses\n- Rate limiting gaps\n\n## Output Format\nFor each finding:\n- **Severity**: Critical/High/Medium/Low\n- **Location**: file:line\n- **Description**: What's wrong\n- **Impact**: What could happen\n- **Remediation**: How to fix\n\\`\\`\\`\n\n### Skill 6: code-review-performance\n\nFile: \\`~/.panopticon/skills/code-review-performance/SKILL.md\\`\n\\`\\`\\`markdown\n---\nname: code-review-performance\ndescription: Deep performance analysis focusing on algorithms and resources\n---\n\n# Performance Review\n\n## Algorithm Complexity\n- Identify O(n²) or worse algorithms\n- Look for unnecessary iterations\n- Check for opportunities to use better data structures\n\n## Database/API Patterns\n- N+1 query detection\n- Missing indexes (check query patterns)\n- Unbounded queries (missing LIMIT)\n- Connection pool exhaustion risks\n\n## Memory \u0026 Resources\n- Memory leaks (unclosed resources)\n- Unbounded caches or buffers\n- Large object allocations in loops\n\n## Concurrency\n- Lock contention hotspots\n- Blocking operations in async contexts\n- Thread pool exhaustion\n\n## Output Format\nFor each finding:\n- **Impact**: High/Medium/Low\n- **Scale factor**: \"At 10x load, this will...\"\n- **Location**: file:line\n- **Suggested optimization**\n\\`\\`\\`\n\n### Skill 7: refactor\n\nFile: \\`~/.panopticon/skills/refactor/SKILL.md\\`\n\\`\\`\\`markdown\n---\nname: refactor\ndescription: Safe refactoring approach with test coverage first\n---\n\n# Refactoring\n\nWhen refactoring code:\n\n## Before Starting\n1. Ensure tests exist for code being refactored\n2. Run tests to establish baseline (must pass)\n3. If test coverage is low, ADD TESTS FIRST\n\n## During Refactoring\n- Make ONE type of change at a time\n- Keep tests green after EACH change\n- Commit frequently with clear messages\n\n## Refactoring Types\n- **Extract**: Pull code into new function/class\n- **Inline**: Remove unnecessary indirection\n- **Rename**: Improve naming clarity\n- **Move**: Relocate to better home\n- **Simplify**: Reduce complexity\n\n## After Refactoring\n- All tests must still pass\n- Behavior must be unchanged\n- Review diff for unintended changes\n\\`\\`\\`\n\n### Skill 8: release\n\nFile: \\`~/.panopticon/skills/release/SKILL.md\\`\n\\`\\`\\`markdown\n---\nname: release\ndescription: Step-by-step release process with versioning\n---\n\n# Release Process\n\n## 1. Version Bump\n- Update version in package.json / pom.xml / etc.\n- Update CHANGELOG.md with new version section\n- Commit: \\\\\\`chore: bump version to X.Y.Z\\\\\\`\n\n## 2. Final Verification\n- Run full test suite\n- Run build process\n- Smoke test critical paths\n\n## 3. Create Release\n- Tag: \\\\\\`git tag -a vX.Y.Z -m \"Release X.Y.Z\"\\\\\\`\n- Push: \\\\\\`git push origin main --tags\\\\\\`\n\n## 4. Post-Release\n- Verify deployment (if auto-deploy)\n- Monitor for issues\n- Announce if needed\n\\`\\`\\`\n\n### Skill 9: incident-response\n\nFile: \\`~/.panopticon/skills/incident-response/SKILL.md\\`\n\\`\\`\\`markdown\n---\nname: incident-response\ndescription: Structured approach to production incidents\n---\n\n# Incident Response\n\n## 1. Assess (First 5 minutes)\n- What is the impact? (users affected, severity)\n- What is the blast radius? (which services/regions)\n- Is it getting worse or stable?\n\n## 2. Mitigate (Stop the bleeding)\n- Can we rollback?\n- Can we feature-flag it off?\n- Can we scale/redirect traffic?\n- Communicate status to stakeholders\n\n## 3. Investigate (Once stable)\n- Gather logs, metrics, traces\n- Identify root cause\n- Document timeline of events\n\n## 4. Fix\n- Implement permanent fix\n- Test thoroughly before deploying\n- Deploy with extra monitoring\n\n## 5. Postmortem\n- Document: What happened, why, how we fixed it\n- Identify: What would have prevented this\n- Action items: Concrete improvements\n\\`\\`\\`\n\n### Skill 10: dependency-update\n\nFile: \\`~/.panopticon/skills/dependency-update/SKILL.md\\`\n\\`\\`\\`markdown\n---\nname: dependency-update\ndescription: Safe approach to updating dependencies\n---\n\n# Dependency Update\n\n## 1. Audit Current State\n\\\\\\`\\\\\\`\\\\\\`bash\nnpm outdated          # See what's outdated\nnpm audit             # Check for vulnerabilities\n\\\\\\`\\\\\\`\\\\\\`\n\n## 2. Update Strategy\n- **Patch versions**: Usually safe, batch update\n- **Minor versions**: Update one at a time, test\n- **Major versions**: Update individually, read changelog\n\n## 3. For Each Update\n\\\\\\`\\\\\\`\\\\\\`bash\nnpm install package@version\nnpm test\n# If tests pass, commit\n# If tests fail, investigate or rollback\n\\\\\\`\\\\\\`\\\\\\`\n\n## 4. Verify\n- Run full test suite\n- Smoke test critical paths\n- Check bundle size (for frontend)\n\\`\\`\\`\n\n### Skill 11: onboard-codebase\n\nFile: \\`~/.panopticon/skills/onboard-codebase/SKILL.md\\`\n\\`\\`\\`markdown\n---\nname: onboard-codebase\ndescription: Systematic approach to understanding a new codebase\n---\n\n# Codebase Onboarding\n\n## 1. High-Level Structure\n- Read README.md\n- Map directory structure\n- Identify main entry points\n\n## 2. Tech Stack\n- What languages/frameworks?\n- What build tools?\n- What testing frameworks?\n- What CI/CD?\n\n## 3. Architecture Patterns\n- How is code organized? (layers, modules, services)\n- How does data flow?\n- What are the key abstractions?\n\n## 4. Development Workflow\n- How to run locally?\n- How to run tests?\n- How to deploy?\n\n## 5. Document Findings\nCreate a summary with:\n- Architecture diagram (ASCII or mermaid)\n- Key files and their purposes\n- Common patterns used\n- Gotchas and quirks\n\\`\\`\\`\n\n### Skill 12: session-health\n\nFile: \\`~/.panopticon/skills/session-health/SKILL.md\\`\n\\`\\`\\`markdown\n---\nname: session-health\ndescription: Detect and clean stuck Claude Code sessions\n---\n\n# Session Health\n\nUse when agents crash, seem stuck, or for routine maintenance.\n\n## Symptoms of Stuck Session\n- Stack overflow errors\n- Agent not responding\n- Repeated same action\n- Context appears corrupted\n\n## Diagnosis\n\\\\\\`\\\\\\`\\\\\\`bash\n# Check tmux sessions\ntmux list-sessions | grep agent\n\n# Check for zombie processes\nps aux | grep claude\n\n# Check disk space (context files)\ndf -h ~/.claude/\n\\\\\\`\\\\\\`\\\\\\`\n\n## Cleanup\n\\\\\\`\\\\\\`\\\\\\`bash\n# Kill stuck session\ntmux kill-session -t agent-XXX\n\n# Clear corrupted context (last resort)\nrm -rf ~/.claude/projects/\u003cproject-id\u003e/\n\n# Restart fresh\npan work issue XXX\n\\\\\\`\\\\\\`\\\\\\`\n\\`\\`\\`\n\n### Skill 13: skill-creator\n\nFile: \\`~/.panopticon/skills/skill-creator/SKILL.md\\`\n\\`\\`\\`markdown\n---\nname: skill-creator\ndescription: Guide for creating effective Claude Code skills\n---\n\n# Creating Skills\n\n## SKILL.md Format\n\\\\\\`\\\\\\`\\\\\\`markdown\n---\nname: my-skill-name\ndescription: Short description (max 500 chars for Codex compatibility)\n---\n\n# Skill Title\n\nInstructions in markdown...\n\\\\\\`\\\\\\`\\\\\\`\n\n## Best Practices\n1. **Be specific** - Concrete steps, not vague guidance\n2. **Use checklists** - Easy to follow\n3. **Include examples** - Show, don't just tell\n4. **Keep it focused** - One skill = one concern\n5. **Test it** - Try the skill yourself\n\n## Frontmatter Requirements\n- \\\\\\`name\\\\\\`: Required, 64 chars max\n- \\\\\\`description\\\\\\`: Required, 500 chars max (Codex limit)\n\n## File Location\n\\\\\\`\\\\\\`\\\\\\`\n~/.panopticon/skills/\u003cskill-name\u003e/SKILL.md\n\\\\\\`\\\\\\`\\\\\\`\n\nAfter creating, run \\\\\\`pan sync\\\\\\` to distribute.\n\\`\\`\\`\n\n### Skill 14: web-design-guidelines\n\nFile: \\`~/.panopticon/skills/web-design-guidelines/SKILL.md\\`\n\\`\\`\\`markdown\n---\nname: web-design-guidelines\ndescription: Review UI code for accessibility and UX best practices\n---\n\n# Web Design Guidelines\n\nBased on Vercel's Web Interface Guidelines.\n\n## Accessibility Checklist\n- [ ] Semantic HTML (button not div, etc.)\n- [ ] ARIA labels where needed\n- [ ] Keyboard navigation works\n- [ ] Color contrast meets WCAG AA\n- [ ] Focus states visible\n- [ ] Screen reader tested\n\n## Performance\n- [ ] Images optimized (WebP, proper sizing)\n- [ ] Lazy loading for below-fold content\n- [ ] No layout shifts (CLS)\n- [ ] Fast initial paint (FCP \u003c 1.8s)\n\n## Mobile\n- [ ] Responsive design\n- [ ] Touch targets 44px minimum\n- [ ] No horizontal scroll\n- [ ] Fast on 3G\n\n## UX Patterns\n- [ ] Loading states for async operations\n- [ ] Error states are helpful\n- [ ] Empty states guide user\n- [ ] Confirmation for destructive actions\n\\`\\`\\`\n\n---\n\n## Step 4: Create Skills Generation Script\n\nCreate \\`scripts/create-skills.sh\\`:\n\\`\\`\\`bash\n#!/bin/bash\n# Run this to create all skill directories and files\n\nSKILLS_DIR=\"\\$HOME/.panopticon/skills\"\nmkdir -p \"\\$SKILLS_DIR\"\n\n# List of skills to create\nSKILLS=(\n  \"beads\"\n  \"feature-work\"\n  \"bug-fix\"\n  \"code-review\"\n  \"code-review-security\"\n  \"code-review-performance\"\n  \"refactor\"\n  \"release\"\n  \"incident-response\"\n  \"dependency-update\"\n  \"onboard-codebase\"\n  \"session-health\"\n  \"skill-creator\"\n  \"web-design-guidelines\"\n)\n\nfor skill in \"\\${SKILLS[@]}\"; do\n  mkdir -p \"\\$SKILLS_DIR/\\$skill\"\n  echo \"Created \\$SKILLS_DIR/\\$skill/\"\ndone\n\necho \"Done! Now copy SKILL.md files to each directory.\"\n\\`\\`\\`\n\n---\n\n## Verification Checklist\n\n\\`\\`\\`bash\n# 1. Check skills exist\nls ~/.panopticon/skills/\n# Expected: 14 directories\n\n# 2. Verify each skill has SKILL.md\nfor d in ~/.panopticon/skills/*/; do\n  ls \"\\$d/SKILL.md\" 2\u003e/dev/null || echo \"MISSING: \\$d\"\ndone\n# Expected: No \"MISSING\" output\n\n# 3. Verify frontmatter\nhead -5 ~/.panopticon/skills/beads/SKILL.md\n# Expected: --- / name: beads / description: ...\n\n# 4. Test skills command\nnode dist/cli/index.js skills\n# Expected: Lists 14 skills with descriptions\n\n# 5. Sync and verify\nnode dist/cli/index.js sync\nls -la ~/.claude/skills/\n# Expected: 14 symlinks pointing to ~/.panopticon/skills/*\n\n# 6. Test in Claude Code\n# Start Claude Code, type \"/beads\" - should trigger skill\n\\`\\`\\`\n\n---\n\n## Dependencies on Other Phases\n\n- **Depends on**: Phase 1 (SKILLS_DIR must exist)\n- **Blocks**: Phase 3 (commands may reference skills)","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-17T17:56:41.141899958-08:00","created_by":"eltmon","updated_at":"2026-01-17T18:22:48.818434316-08:00","labels":["skills"],"dependencies":[{"issue_id":"panopticon-6ax.2","depends_on_id":"panopticon-6ax","type":"parent-child","created_at":"2026-01-17T17:56:41.15429593-08:00","created_by":"eltmon"}]}
{"id":"panopticon-6ax.3","title":"Phase 3: Commands Migration","description":"Migrate and implement all work-* and pan:* commands from MYN infra.\n\n## Prerequisites\n- Phase 1 complete (`pan init`, `pan sync` working)\n- Phase 2 complete (skills system working)\n- ~/.panopticon/commands/ directory exists\n- tmux installed (`which tmux` succeeds)\n- Linear API key in environment (`echo $LINEAR_API_KEY` shows value)\n\n## Acceptance Criteria (Testable)\n- [ ] `ls ~/.panopticon/commands/work/` shows 10 markdown files\n- [ ] `ls ~/.panopticon/commands/pan/` shows 5 markdown files\n- [ ] `node dist/cli/index.js work status` returns (even if empty)\n- [ ] `/work-status` in Claude Code lists agents (even if empty)\n- [ ] `pan work issue TEST-1 --dry-run` shows what would be created\n- [ ] `tmux list-sessions 2\u003e/dev/null | grep agent` works (may be empty)\n\n---\n\n## Step 1: Create Commands Directory Structure\n\n```bash\n# Create the directory structure\nmkdir -p ~/.panopticon/commands/work\nmkdir -p ~/.panopticon/commands/pan\n\n# Verify\nls -la ~/.panopticon/commands/\n# Expected: work/ and pan/ directories\n```\n\n---\n\n## Step 2: Install Dependencies\n\n```bash\ncd /home/eltmon/projects/panopticon\nnpm install @linear/sdk node-pty-prebuilt-multiarch\nnpm install -D @types/node-pty\n```\n\n---\n\n## Step 3: Create Tmux Library (src/lib/tmux.ts)\n\n```typescript\nimport { execSync, exec } from 'child_process';\nimport { existsSync, writeFileSync, readFileSync } from 'fs';\nimport { join } from 'path';\nimport { PANOPTICON_HOME } from './paths.js';\n\nexport interface TmuxSession {\n  name: string;\n  created: Date;\n  attached: boolean;\n  windows: number;\n}\n\nexport function listSessions(): TmuxSession[] {\n  try {\n    const output = execSync('tmux list-sessions -F \"#{session_name}|#{session_created}|#{session_attached}|#{session_windows}\"', {\n      encoding: 'utf8',\n    });\n    \n    return output.trim().split('\\n').filter(Boolean).map(line =\u003e {\n      const [name, created, attached, windows] = line.split('|');\n      return {\n        name,\n        created: new Date(parseInt(created) * 1000),\n        attached: attached === '1',\n        windows: parseInt(windows),\n      };\n    });\n  } catch {\n    return []; // No sessions\n  }\n}\n\nexport function sessionExists(name: string): boolean {\n  try {\n    execSync(`tmux has-session -t ${name} 2\u003e/dev/null`);\n    return true;\n  } catch {\n    return false;\n  }\n}\n\nexport function createSession(name: string, cwd: string, initialCommand?: string): void {\n  const cmd = initialCommand \n    ? `tmux new-session -d -s ${name} -c \"${cwd}\" \"${initialCommand}\"`\n    : `tmux new-session -d -s ${name} -c \"${cwd}\"`;\n  \n  execSync(cmd);\n}\n\nexport function killSession(name: string): void {\n  execSync(`tmux kill-session -t ${name}`);\n}\n\nexport function sendKeys(sessionName: string, keys: string): void {\n  // CRITICAL: Send keys and Enter as separate commands\n  execSync(`tmux send-keys -t ${sessionName} \"${keys.replace(/\"/g, '\\\\\"')}\"`);\n  execSync(`tmux send-keys -t ${sessionName} Enter`);\n}\n\nexport function capturePane(sessionName: string, lines: number = 50): string {\n  try {\n    return execSync(`tmux capture-pane -t ${sessionName} -p -S -${lines}`, {\n      encoding: 'utf8',\n    });\n  } catch {\n    return '';\n  }\n}\n\nexport function getAgentSessions(): TmuxSession[] {\n  return listSessions().filter(s =\u003e s.name.startsWith('agent-'));\n}\n```\n\n---\n\n## Step 4: Create Agents Library (src/lib/agents.ts)\n\n```typescript\nimport { existsSync, mkdirSync, writeFileSync, readFileSync } from 'fs';\nimport { join } from 'path';\nimport { PANOPTICON_HOME, AGENTS_DIR } from './paths.js';\nimport { createSession, killSession, sendKeys, capturePane, sessionExists, getAgentSessions } from './tmux.js';\n\nexport interface AgentState {\n  id: string;\n  issueId: string;\n  workspace: string;\n  runtime: string;\n  model: string;\n  status: 'starting' | 'running' | 'stopped' | 'error';\n  startedAt: Date;\n  lastActivity?: Date;\n}\n\nexport function getAgentDir(agentId: string): string {\n  return join(AGENTS_DIR, agentId);\n}\n\nexport function getAgentState(agentId: string): AgentState | null {\n  const stateFile = join(getAgentDir(agentId), 'state.json');\n  if (!existsSync(stateFile)) return null;\n  \n  const content = readFileSync(stateFile, 'utf8');\n  return JSON.parse(content);\n}\n\nexport function saveAgentState(state: AgentState): void {\n  const dir = getAgentDir(state.id);\n  mkdirSync(dir, { recursive: true });\n  \n  writeFileSync(\n    join(dir, 'state.json'),\n    JSON.stringify(state, null, 2)\n  );\n}\n\nexport interface SpawnOptions {\n  issueId: string;\n  workspace: string;\n  runtime?: string;\n  model?: string;\n  prompt?: string;\n}\n\nexport function spawnAgent(options: SpawnOptions): AgentState {\n  const agentId = `agent-${options.issueId.toLowerCase()}`;\n  \n  // Check if already running\n  if (sessionExists(agentId)) {\n    throw new Error(`Agent ${agentId} already running. Use 'work tell' to message it.`);\n  }\n  \n  // Create state\n  const state: AgentState = {\n    id: agentId,\n    issueId: options.issueId,\n    workspace: options.workspace,\n    runtime: options.runtime || 'claude',\n    model: options.model || 'sonnet',\n    status: 'starting',\n    startedAt: new Date(),\n  };\n  \n  saveAgentState(state);\n  \n  // Create tmux session\n  const claudeCmd = options.prompt \n    ? `claude --model ${state.model} \"${options.prompt}\"`\n    : `claude --model ${state.model}`;\n  \n  createSession(agentId, options.workspace, claudeCmd);\n  \n  // Update status\n  state.status = 'running';\n  saveAgentState(state);\n  \n  return state;\n}\n\nexport function listRunningAgents(): (AgentState \u0026 { tmuxActive: boolean })[] {\n  const tmuxSessions = getAgentSessions();\n  const tmuxNames = new Set(tmuxSessions.map(s =\u003e s.name));\n  \n  const agents: (AgentState \u0026 { tmuxActive: boolean })[] = [];\n  \n  // Read all agent states\n  if (!existsSync(AGENTS_DIR)) return agents;\n  \n  const { readdirSync } = require('fs');\n  const dirs = readdirSync(AGENTS_DIR, { withFileTypes: true })\n    .filter((d: any) =\u003e d.isDirectory());\n  \n  for (const dir of dirs) {\n    const state = getAgentState(dir.name);\n    if (state) {\n      agents.push({\n        ...state,\n        tmuxActive: tmuxNames.has(state.id),\n      });\n    }\n  }\n  \n  return agents;\n}\n\nexport function stopAgent(agentId: string): void {\n  if (sessionExists(agentId)) {\n    killSession(agentId);\n  }\n  \n  const state = getAgentState(agentId);\n  if (state) {\n    state.status = 'stopped';\n    saveAgentState(state);\n  }\n}\n\nexport function messageAgent(agentId: string, message: string): void {\n  if (!sessionExists(agentId)) {\n    throw new Error(`Agent ${agentId} not running`);\n  }\n  \n  sendKeys(agentId, message);\n  \n  // Also save to mail queue\n  const mailDir = join(getAgentDir(agentId), 'mail');\n  mkdirSync(mailDir, { recursive: true });\n  \n  const timestamp = new Date().toISOString().replace(/[:.]/g, '-');\n  writeFileSync(\n    join(mailDir, `${timestamp}.md`),\n    `# Message\\n\\n${message}\\n`\n  );\n}\n```\n\n---\n\n## Step 5: Create Work Commands (src/cli/commands/work/index.ts)\n\n```typescript\nimport { Command } from 'commander';\nimport { issueCommand } from './issue.js';\nimport { statusCommand } from './status.js';\nimport { tellCommand } from './tell.js';\nimport { killCommand } from './kill.js';\nimport { pendingCommand } from './pending.js';\nimport { approveCommand } from './approve.js';\nimport { planCommand } from './plan.js';\nimport { listCommand } from './list.js';\nimport { triageCommand } from './triage.js';\n\nexport function registerWorkCommands(program: Command): void {\n  const work = program\n    .command('work')\n    .description('Agent and work management');\n\n  work\n    .command('issue \u003cid\u003e')\n    .description('Spawn agent for Linear issue')\n    .option('--model \u003cmodel\u003e', 'Claude model (sonnet/opus/haiku)', 'sonnet')\n    .option('--runtime \u003cruntime\u003e', 'AI runtime (claude/codex)', 'claude')\n    .option('--dry-run', 'Show what would be created')\n    .action(issueCommand);\n\n  work\n    .command('status')\n    .description('Show all running agents')\n    .option('--json', 'Output as JSON')\n    .action(statusCommand);\n\n  work\n    .command('tell \u003cid\u003e \u003cmessage\u003e')\n    .description('Send message to running agent')\n    .action(tellCommand);\n\n  work\n    .command('kill \u003cid\u003e')\n    .description('Kill an agent')\n    .option('--force', 'Kill without confirmation')\n    .action(killCommand);\n\n  work\n    .command('pending')\n    .description('Show completed work awaiting review')\n    .action(pendingCommand);\n\n  work\n    .command('approve \u003cid\u003e')\n    .description('Approve agent work, merge MR')\n    .option('--no-merge', 'Skip MR merge')\n    .action(approveCommand);\n\n  work\n    .command('plan \u003cid\u003e')\n    .description('Create execution plan before spawning')\n    .action(planCommand);\n\n  work\n    .command('list')\n    .description('List Linear issues')\n    .option('--all', 'Include secondary tracker')\n    .option('--tracker \u003ctracker\u003e', 'Specific tracker')\n    .action(listCommand);\n\n  work\n    .command('triage [id]')\n    .description('Triage secondary tracker issues')\n    .option('--create', 'Create primary issue from secondary')\n    .option('--dismiss \u003creason\u003e', 'Dismiss from triage')\n    .action(triageCommand);\n}\n```\n\n---\n\n## Step 6: Implement Work Status Command (src/cli/commands/work/status.ts)\n\n```typescript\nimport chalk from 'chalk';\nimport { listRunningAgents } from '../../lib/agents.js';\n\ninterface StatusOptions {\n  json?: boolean;\n}\n\nexport async function statusCommand(options: StatusOptions): Promise\u003cvoid\u003e {\n  const agents = listRunningAgents();\n  \n  if (options.json) {\n    console.log(JSON.stringify(agents, null, 2));\n    return;\n  }\n  \n  if (agents.length === 0) {\n    console.log(chalk.dim('No running agents.'));\n    console.log(chalk.dim('Use \"pan work issue \u003cid\u003e\" to spawn one.'));\n    return;\n  }\n  \n  console.log(chalk.bold('\\nRunning Agents\\n'));\n  \n  for (const agent of agents) {\n    const statusColor = agent.tmuxActive ? chalk.green : chalk.red;\n    const status = agent.tmuxActive ? 'running' : 'stopped';\n    \n    const duration = Math.floor((Date.now() - new Date(agent.startedAt).getTime()) / 1000 / 60);\n    \n    console.log(`${chalk.cyan(agent.id)}`);\n    console.log(`  Issue:    ${agent.issueId}`);\n    console.log(`  Status:   ${statusColor(status)}`);\n    console.log(`  Runtime:  ${agent.runtime} (${agent.model})`);\n    console.log(`  Duration: ${duration} min`);\n    console.log(`  Workspace: ${chalk.dim(agent.workspace)}`);\n    console.log('');\n  }\n}\n```\n\n---\n\n## Step 7: Implement Work Issue Command (src/cli/commands/work/issue.ts)\n\n```typescript\nimport chalk from 'chalk';\nimport ora from 'ora';\nimport { existsSync, mkdirSync } from 'fs';\nimport { join } from 'path';\nimport { spawnAgent } from '../../lib/agents.js';\n\ninterface IssueOptions {\n  model: string;\n  runtime: string;\n  dryRun?: boolean;\n}\n\nexport async function issueCommand(id: string, options: IssueOptions): Promise\u003cvoid\u003e {\n  const spinner = ora(`Preparing workspace for ${id}...`).start();\n  \n  try {\n    // Normalize issue ID (MIN-648 -\u003e min-648)\n    const normalizedId = id.toLowerCase();\n    \n    // For now, use current directory as workspace\n    // Phase 5 will add proper workspace creation\n    const workspace = process.cwd();\n    \n    if (options.dryRun) {\n      spinner.info('Dry run mode');\n      console.log('');\n      console.log(chalk.bold('Would create:'));\n      console.log(`  Agent ID:   agent-${normalizedId}`);\n      console.log(`  Workspace:  ${workspace}`);\n      console.log(`  Runtime:    ${options.runtime}`);\n      console.log(`  Model:      ${options.model}`);\n      return;\n    }\n    \n    spinner.text = 'Spawning agent...';\n    \n    const agent = spawnAgent({\n      issueId: id,\n      workspace,\n      runtime: options.runtime,\n      model: options.model,\n      prompt: `You are working on issue ${id}. Check beads for context: bd show ${id}`,\n    });\n    \n    spinner.succeed(`Agent spawned: ${agent.id}`);\n    \n    console.log('');\n    console.log(chalk.bold('Agent Details:'));\n    console.log(`  Session:    ${chalk.cyan(agent.id)}`);\n    console.log(`  Workspace:  ${workspace}`);\n    console.log(`  Runtime:    ${agent.runtime} (${agent.model})`);\n    console.log('');\n    console.log(chalk.dim('Commands:'));\n    console.log(`  Attach:   tmux attach -t ${agent.id}`);\n    console.log(`  Message:  pan work tell ${id} \"your message\"`);\n    console.log(`  Kill:     pan work kill ${id}`);\n    \n  } catch (error: any) {\n    spinner.fail(error.message);\n    process.exit(1);\n  }\n}\n```\n\n---\n\n## Step 8: Implement Work Tell Command (src/cli/commands/work/tell.ts)\n\n```typescript\nimport chalk from 'chalk';\nimport { messageAgent } from '../../lib/agents.js';\n\nexport async function tellCommand(id: string, message: string): Promise\u003cvoid\u003e {\n  const agentId = id.startsWith('agent-') ? id : `agent-${id.toLowerCase()}`;\n  \n  try {\n    messageAgent(agentId, message);\n    console.log(chalk.green('Message sent to ' + agentId));\n    console.log(chalk.dim(`  \"${message}\"`));\n  } catch (error: any) {\n    console.error(chalk.red('Error: ' + error.message));\n    process.exit(1);\n  }\n}\n```\n\n---\n\n## Step 9: Create Command Markdown Files\n\n### /work-issue Command (work/issue.md)\n\n```markdown\n---\nname: work-issue\ndescription: Create workspace and spawn agent for a Linear issue\n---\n\n# Work Issue\n\nSpawn an autonomous agent to work on a Linear issue.\n\n## Usage in Claude Code\n\n\\`\\`\\`\n/work-issue MIN-648\n/work-issue MIN-648 --model opus\n/work-issue MIN-648 --runtime codex\n\\`\\`\\`\n\n## What This Does\n\n1. Creates a git worktree for the issue (Phase 5)\n2. Starts Docker containers if workspace has them\n3. Generates CLAUDE.md from templates\n4. Spawns Claude Code in a tmux session\n5. Registers agent in ~/.panopticon/agents/\n6. Creates Beads for tracking\n\n## CLI Equivalent\n\n\\`\\`\\`bash\npan work issue MIN-648 --model sonnet\n\\`\\`\\`\n\n## Options\n\n- `--model \u003cmodel\u003e`: sonnet (default), opus, haiku\n- `--runtime \u003cruntime\u003e`: claude (default), codex\n- `--dry-run`: Show what would be created\n\n## After Spawning\n\n- Attach: `tmux attach -t agent-min-648`\n- Message: `/work-tell MIN-648 \"message\"`\n- Kill: `/work-kill MIN-648`\n```\n\n### /work-status Command (work/status.md)\n\n```markdown\n---\nname: work-status\ndescription: Show all running agents and their status\n---\n\n# Work Status\n\nDisplay all running agents with their status.\n\n## Usage in Claude Code\n\n\\`\\`\\`\n/work-status\n\\`\\`\\`\n\n## Output\n\nShows for each agent:\n- Agent ID (e.g., agent-min-648)\n- Issue being worked on\n- Status (running/stopped/stuck)\n- Runtime and model\n- Duration\n- Workspace path\n- Health status (if monitoring enabled)\n\n## CLI Equivalent\n\n\\`\\`\\`bash\npan work status\npan work status --json\n\\`\\`\\`\n```\n\nCreate similar files for all other commands:\n- `work/tell.md`\n- `work/kill.md`\n- `work/pending.md`\n- `work/approve.md`\n- `work/plan.md`\n- `work/list.md`\n- `work/triage.md`\n- `pan/up.md`\n- `pan/down.md`\n- `pan/sync.md`\n- `pan/health.md`\n- `pan/help.md`\n\n---\n\n## Step 10: Register Work Commands in CLI\n\nUpdate src/cli/index.ts:\n\n```typescript\n#!/usr/bin/env node\nimport { Command } from 'commander';\nimport chalk from 'chalk';\nimport { initCommand } from './commands/init.js';\nimport { syncCommand } from './commands/sync.js';\nimport { restoreCommand } from './commands/restore.js';\nimport { skillsCommand } from './commands/skills.js';\nimport { registerWorkCommands } from './commands/work/index.js';\n\nconst program = new Command();\n\nprogram\n  .name('pan')\n  .description('Multi-agent orchestration for Claude Code')\n  .version('0.1.0');\n\n// Existing commands\nprogram.command('init').description('Initialize Panopticon').action(initCommand);\nprogram.command('sync').description('Sync skills/commands').action(syncCommand);\nprogram.command('restore \u003ctimestamp\u003e').description('Restore backup').action(restoreCommand);\nprogram.command('skills').description('List skills').action(skillsCommand);\n\n// Work commands (pan work issue, pan work status, etc.)\nregisterWorkCommands(program);\n\n// Shorthand: pan status = pan work status\nprogram.command('status').description('Show running agents (shorthand)').action(() =\u003e {\n  const { statusCommand } = require('./commands/work/status.js');\n  statusCommand({});\n});\n\nprogram.parse();\n```\n\n---\n\n## Step 11: Sync Commands to Claude Code\n\nAdd commands to sync logic (update src/lib/sync.ts):\n\n```typescript\n// Add after skill syncing\nexport function syncCommands(dryRun: boolean = false): string[] {\n  const COMMANDS_DIR = join(PANOPTICON_HOME, 'commands');\n  const TARGET_DIR = join(homedir(), '.claude', 'commands');\n  \n  return createSymlinks(COMMANDS_DIR, TARGET_DIR, { dryRun });\n}\n```\n\n---\n\n## Verification Checklist\n\n```bash\n# 1. Build\nnpm run build\n# Expected: No errors\n\n# 2. Check command structure\nls -la ~/.panopticon/commands/work/\n# Expected: issue.md, status.md, tell.md, kill.md, etc.\n\n# 3. Test status (empty is OK)\nnode dist/cli/index.js work status\n# Expected: \"No running agents\" or list\n\n# 4. Test dry-run\nnode dist/cli/index.js work issue TEST-1 --dry-run\n# Expected: Shows what would be created\n\n# 5. Verify tmux integration\nwhich tmux\n# Expected: /usr/bin/tmux or similar\n\n# 6. Test actual spawn (if Linear configured)\nnode dist/cli/index.js work issue MIN-TEST --model haiku\n# Expected: Agent spawned message\n\n# 7. Verify Claude Code sees commands\nls -la ~/.claude/commands/\n# Expected: Symlinks to ~/.panopticon/commands/*\n\n# 8. In Claude Code, test slash command\n# Type: /work-status\n# Expected: Lists agents (may be empty)\n```\n\n---\n\n## Common Gotchas\n\n1. **tmux not installed**: Run `apt install tmux` or `brew install tmux`\n2. **Linear API key missing**: Set `LINEAR_API_KEY` environment variable\n3. **Symlinks not created**: Run `pan sync` after adding commands\n4. **tmux send-keys not pressing Enter**: Must be two separate commands!\n5. **Agent already exists**: Use `pan work kill` first, then spawn\n\n---\n\n## Dependencies on Other Phases\n\n- **Depends on**: Phase 1 (CLI core), Phase 2 (skills for agent prompts)\n- **Blocks**: Phase 4 (dashboard needs agent API), Phase 5 (workspace uses these commands)","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-17T17:56:49.077460118-08:00","created_by":"eltmon","updated_at":"2026-01-17T18:25:36.401549693-08:00","labels":["commands"],"dependencies":[{"issue_id":"panopticon-6ax.3","depends_on_id":"panopticon-6ax","type":"parent-child","created_at":"2026-01-17T17:56:49.090357118-08:00","created_by":"eltmon"}]}
{"id":"panopticon-6ax.4","title":"Phase 4: Dashboard","description":"Extract and enhance the web dashboard from MYN with all features from PRD Part 11.\n\n## Prerequisites\n- Phase 1 complete (pan init working)\n- Phase 3 complete (agents library exists)\n- Node.js 18+ installed\n- LINEAR_API_KEY environment variable set\n- Source dashboard exists at /home/eltmon/projects/myn/infra/dashboard/\n\n## Acceptance Criteria (Testable)\n- [ ] `cd src/dashboard \u0026\u0026 npm run dev` starts both frontend and API\n- [ ] `curl http://localhost:3002/api/health` returns `{\"status\":\"ok\"}`\n- [ ] `curl http://localhost:3002/api/agents` returns JSON array\n- [ ] `curl http://localhost:3002/api/issues` returns Linear issues\n- [ ] Browser at http://localhost:3001 shows dashboard\n- [ ] Kanban board displays issues by status\n- [ ] Agent list shows running tmux sessions\n\n---\n\n## Step 1: Create Dashboard Directory Structure\n\n```bash\nmkdir -p /home/eltmon/projects/panopticon/src/dashboard/{frontend,server,shared}\n\n# Verify\nls -la /home/eltmon/projects/panopticon/src/dashboard/\n# Expected: frontend/, server/, shared/\n```\n\n---\n\n## Step 2: Initialize Frontend (React + Vite + TailwindCSS)\n\n```bash\ncd /home/eltmon/projects/panopticon/src/dashboard/frontend\n\n# Initialize package.json\nnpm init -y\n\n# Install dependencies\nnpm install react@^18 react-dom@^18 @tanstack/react-query socket.io-client zustand\nnpm install -D vite@^5 @vitejs/plugin-react typescript @types/react @types/react-dom\nnpm install -D tailwindcss postcss autoprefixer\nnpm install lucide-react  # Icons\n\n# Initialize Tailwind\nnpx tailwindcss init -p\n```\n\n---\n\n## Step 3: Configure Vite (frontend/vite.config.ts)\n\n```typescript\nimport { defineConfig } from 'vite';\nimport react from '@vitejs/plugin-react';\n\nexport default defineConfig({\n  plugins: [react()],\n  server: {\n    port: 3001,\n    proxy: {\n      '/api': {\n        target: 'http://localhost:3002',\n        changeOrigin: true,\n      },\n      '/socket.io': {\n        target: 'http://localhost:3002',\n        ws: true,\n      },\n    },\n  },\n});\n```\n\n---\n\n## Step 4: Configure Tailwind (frontend/tailwind.config.js)\n\n```javascript\n/** @type {import('tailwindcss').Config} */\nexport default {\n  content: [\n    \"./index.html\",\n    \"./src/**/*.{js,ts,jsx,tsx}\",\n  ],\n  theme: {\n    extend: {\n      colors: {\n        'status-healthy': '#22c55e',\n        'status-warning': '#eab308',\n        'status-stuck': '#f97316',\n        'status-dead': '#ef4444',\n      },\n    },\n  },\n  plugins: [],\n};\n```\n\n---\n\n## Step 5: Create Frontend Entry Point (frontend/index.html)\n\n```html\n\u003c!DOCTYPE html\u003e\n\u003chtml lang=\"en\"\u003e\n  \u003chead\u003e\n    \u003cmeta charset=\"UTF-8\" /\u003e\n    \u003cmeta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" /\u003e\n    \u003ctitle\u003ePanopticon\u003c/title\u003e\n  \u003c/head\u003e\n  \u003cbody class=\"bg-gray-900 text-white\"\u003e\n    \u003cdiv id=\"root\"\u003e\u003c/div\u003e\n    \u003cscript type=\"module\" src=\"/src/main.tsx\"\u003e\u003c/script\u003e\n  \u003c/body\u003e\n\u003c/html\u003e\n```\n\n---\n\n## Step 6: Create Main App (frontend/src/main.tsx)\n\n```typescript\nimport React from 'react';\nimport ReactDOM from 'react-dom/client';\nimport { QueryClient, QueryClientProvider } from '@tanstack/react-query';\nimport App from './App';\nimport './index.css';\n\nconst queryClient = new QueryClient({\n  defaultOptions: {\n    queries: {\n      refetchInterval: 5000,\n      staleTime: 2000,\n    },\n  },\n});\n\nReactDOM.createRoot(document.getElementById('root')!).render(\n  \u003cReact.StrictMode\u003e\n    \u003cQueryClientProvider client={queryClient}\u003e\n      \u003cApp /\u003e\n    \u003c/QueryClientProvider\u003e\n  \u003c/React.StrictMode\u003e\n);\n```\n\n---\n\n## Step 7: Create App Component (frontend/src/App.tsx)\n\n```typescript\nimport React, { useState } from 'react';\nimport { KanbanBoard } from './components/KanbanBoard';\nimport { AgentList } from './components/AgentList';\nimport { TerminalView } from './components/TerminalView';\nimport { HealthDashboard } from './components/HealthDashboard';\n\ntype Tab = 'kanban' | 'agents' | 'health';\n\nexport default function App() {\n  const [activeTab, setActiveTab] = useState\u003cTab\u003e('kanban');\n  const [selectedAgent, setSelectedAgent] = useState\u003cstring | null\u003e(null);\n\n  return (\n    \u003cdiv className=\"min-h-screen\"\u003e\n      \u003cheader className=\"bg-gray-800 border-b border-gray-700 px-6 py-4\"\u003e\n        \u003cdiv className=\"flex items-center justify-between\"\u003e\n          \u003ch1 className=\"text-xl font-bold\"\u003ePanopticon\u003c/h1\u003e\n          \u003cnav className=\"flex gap-4\"\u003e\n            {(['kanban', 'agents', 'health'] as Tab[]).map((tab) =\u003e (\n              \u003cbutton\n                key={tab}\n                onClick={() =\u003e setActiveTab(tab)}\n                className={`px-4 py-2 rounded ${\n                  activeTab === tab ? 'bg-blue-600 text-white' : 'text-gray-400 hover:text-white'\n                }`}\n              \u003e\n                {tab.charAt(0).toUpperCase() + tab.slice(1)}\n              \u003c/button\u003e\n            ))}\n          \u003c/nav\u003e\n        \u003c/div\u003e\n      \u003c/header\u003e\n      \u003cmain className=\"p-6\"\u003e\n        {activeTab === 'kanban' \u0026\u0026 \u003cKanbanBoard /\u003e}\n        {activeTab === 'agents' \u0026\u0026 (\n          \u003cdiv className=\"grid grid-cols-2 gap-6\"\u003e\n            \u003cAgentList selectedAgent={selectedAgent} onSelectAgent={setSelectedAgent} /\u003e\n            {selectedAgent \u0026\u0026 \u003cTerminalView agentId={selectedAgent} /\u003e}\n          \u003c/div\u003e\n        )}\n        {activeTab === 'health' \u0026\u0026 \u003cHealthDashboard /\u003e}\n      \u003c/main\u003e\n    \u003c/div\u003e\n  );\n}\n```\n\n---\n\n## Step 8: Create KanbanBoard Component\n\nFile: frontend/src/components/KanbanBoard.tsx\n\nUses @tanstack/react-query to fetch /api/issues and displays them in columns by status (Backlog, Todo, In Progress, In Review, Done).\n\n---\n\n## Step 9: Create AgentList Component\n\nFile: frontend/src/components/AgentList.tsx\n\nFetches /api/agents and displays each agent with:\n- Status indicator (green/red dot)\n- Agent ID\n- Runtime and model\n- Duration\n- Kill button\n\n---\n\n## Step 10: Create TerminalView Component\n\nFile: frontend/src/components/TerminalView.tsx\n\n- Fetches /api/agents/:id/output every 2 seconds\n- Shows terminal output in monospace font\n- Input field to send messages via /api/agents/:id/message\n\n---\n\n## Step 11: Create HealthDashboard Component\n\nFile: frontend/src/components/HealthDashboard.tsx\n\nGrid of agent health cards showing status, failures, and kill count.\n\n---\n\n## Step 12: Initialize Server\n\n```bash\ncd /home/eltmon/projects/panopticon/src/dashboard/server\nnpm init -y\nnpm install express cors socket.io @linear/sdk\nnpm install -D typescript @types/express @types/cors @types/node tsx\n```\n\n---\n\n## Step 13: Create Server (server/index.ts)\n\nExpress server with endpoints:\n- GET /api/health - Returns {status: \"ok\"}\n- GET /api/issues - Fetches from Linear API\n- GET /api/agents - Reads from ~/.panopticon/agents/\n- GET /api/agents/:id/output - Captures tmux pane\n- POST /api/agents/:id/message - Sends to tmux\n- POST /api/agents/:id/kill - Kills tmux session\n\n---\n\n## Verification Checklist\n\n```bash\n# 1. Start dashboard\ncd /home/eltmon/projects/panopticon/src/dashboard\nnpm run dev\n\n# 2. Test API\ncurl http://localhost:3002/api/health\n# Expected: {\"status\":\"ok\"}\n\n# 3. Test agents\ncurl http://localhost:3002/api/agents\n# Expected: [] or array\n\n# 4. Open browser at http://localhost:3001\n# Expected: Dashboard loads\n```\n\n---\n\n## Common Gotchas\n\n1. LINEAR_API_KEY not set - export before starting\n2. Port 3001 in use - kill other Vite processes\n3. CORS errors - ensure server has cors middleware\n4. tmux not found - install it\n\n---\n\n## Dependencies on Other Phases\n\n- Depends on: Phase 1, Phase 3\n- Blocks: Phase 11 (health monitoring)\n\n## Reference Files from MYN\n\n- /home/eltmon/projects/myn/infra/dashboard/","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-17T17:56:56.29061505-08:00","created_by":"eltmon","updated_at":"2026-01-17T18:27:47.191678881-08:00","labels":["dashboard","ui"],"dependencies":[{"issue_id":"panopticon-6ax.4","depends_on_id":"panopticon-6ax","type":"parent-child","created_at":"2026-01-17T17:56:56.303517326-08:00","created_by":"eltmon"}]}
{"id":"panopticon-6ax.5","title":"Phase 5: Workspace Management","description":"Implement workspace creation with Docker, worktrees, and CLAUDE.md templating.\n\n## Prerequisites\n- Phase 1 complete (pan init, config system)\n- Phase 3 complete (work commands exist)\n- Docker and Docker Compose installed\n- Git installed with worktree support (git 2.5+)\n- Project has docker-compose.yml or devcontainer config\n\n## Acceptance Criteria (Testable)\n- [ ] `pan workspace create MIN-123 --dry-run` shows what would be created\n- [ ] `pan workspace create MIN-123` creates worktree at workspaces/feature-min-123/\n- [ ] `git worktree list` shows the new worktree\n- [ ] `cat workspaces/feature-min-123/CLAUDE.md` shows generated context file\n- [ ] `ls -la workspaces/feature-min-123/.claude/skills/` shows symlinks\n- [ ] `pan workspace list` shows all workspaces\n- [ ] `pan workspace destroy MIN-123` removes worktree cleanly\n\n---\n\n## Step 1: Install Dependencies\n\n```bash\ncd /home/eltmon/projects/panopticon\nnpm install yaml dockerode\nnpm install -D @types/dockerode\n```\n\n---\n\n## Step 2: Create Worktree Library (src/lib/worktree.ts)\n\n```typescript\nimport { execSync } from 'child_process';\nimport { existsSync, mkdirSync } from 'fs';\nimport { join, dirname } from 'path';\n\nexport interface WorktreeInfo {\n  path: string;\n  branch: string;\n  head: string;\n  prunable: boolean;\n}\n\nexport function listWorktrees(repoPath: string): WorktreeInfo[] {\n  const output = execSync('git worktree list --porcelain', {\n    cwd: repoPath,\n    encoding: 'utf8',\n  });\n\n  const worktrees: WorktreeInfo[] = [];\n  let current: Partial\u003cWorktreeInfo\u003e = {};\n\n  for (const line of output.split('\\n')) {\n    if (line.startsWith('worktree ')) {\n      if (current.path) worktrees.push(current as WorktreeInfo);\n      current = { path: line.slice(9) };\n    } else if (line.startsWith('HEAD ')) {\n      current.head = line.slice(5);\n    } else if (line.startsWith('branch ')) {\n      current.branch = line.slice(7).replace('refs/heads/', '');\n    } else if (line === 'prunable') {\n      current.prunable = true;\n    }\n  }\n  if (current.path) worktrees.push(current as WorktreeInfo);\n\n  return worktrees;\n}\n\nexport function createWorktree(\n  repoPath: string,\n  targetPath: string,\n  branchName: string\n): void {\n  // Ensure parent directory exists\n  mkdirSync(dirname(targetPath), { recursive: true });\n\n  // Check if branch exists\n  try {\n    execSync(`git show-ref --verify --quiet refs/heads/${branchName}`, {\n      cwd: repoPath,\n    });\n    // Branch exists, just add worktree\n    execSync(`git worktree add \"${targetPath}\" \"${branchName}\"`, {\n      cwd: repoPath,\n    });\n  } catch {\n    // Branch doesn't exist, create it\n    execSync(`git worktree add -b \"${branchName}\" \"${targetPath}\"`, {\n      cwd: repoPath,\n    });\n  }\n}\n\nexport function removeWorktree(repoPath: string, worktreePath: string): void {\n  execSync(`git worktree remove \"${worktreePath}\" --force`, {\n    cwd: repoPath,\n  });\n}\n\nexport function pruneWorktrees(repoPath: string): void {\n  execSync('git worktree prune', { cwd: repoPath });\n}\n```\n\n---\n\n## Step 3: Create Template Library (src/lib/template.ts)\n\n```typescript\nimport { readFileSync, writeFileSync, existsSync, readdirSync } from 'fs';\nimport { join } from 'path';\nimport { PANOPTICON_HOME } from './paths.js';\n\nexport interface TemplateVariables {\n  FEATURE_FOLDER: string;\n  BRANCH_NAME: string;\n  ISSUE_ID: string;\n  WORKSPACE_PATH: string;\n  FRONTEND_URL?: string;\n  API_URL?: string;\n  PROJECT_NAME?: string;\n  [key: string]: string | undefined;\n}\n\nexport function loadTemplate(templatePath: string): string {\n  if (!existsSync(templatePath)) {\n    throw new Error(`Template not found: ${templatePath}`);\n  }\n  return readFileSync(templatePath, 'utf8');\n}\n\nexport function substituteVariables(\n  template: string,\n  variables: TemplateVariables\n): string {\n  let result = template;\n\n  for (const [key, value] of Object.entries(variables)) {\n    if (value !== undefined) {\n      // Replace {{KEY}} and ${KEY} patterns\n      result = result.replace(new RegExp(`\\\\{\\\\{${key}\\\\}\\\\}`, 'g'), value);\n      result = result.replace(new RegExp(`\\\\$\\\\{${key}\\\\}`, 'g'), value);\n    }\n  }\n\n  return result;\n}\n\nexport function generateClaudeMd(\n  projectPath: string,\n  variables: TemplateVariables\n): string {\n  const sections: string[] = [];\n\n  // Layer 1: Panopticon default sections\n  const panopticonSections = join(PANOPTICON_HOME, 'templates', 'claude-md', 'sections');\n  const defaultOrder = [\n    'workspace-info.md',\n    'beads.md',\n    'commands-skills.md',\n    'warnings.md',\n  ];\n\n  for (const section of defaultOrder) {\n    const sectionPath = join(panopticonSections, section);\n    if (existsSync(sectionPath)) {\n      const content = loadTemplate(sectionPath);\n      sections.push(substituteVariables(content, variables));\n    }\n  }\n\n  // Layer 2: Project-specific sections\n  const projectSections = join(projectPath, '.panopticon', 'claude-md', 'sections');\n  if (existsSync(projectSections)) {\n    const projectFiles = readdirSync(projectSections)\n      .filter((f) =\u003e f.endsWith('.md'))\n      .sort();\n\n    for (const file of projectFiles) {\n      const content = loadTemplate(join(projectSections, file));\n      sections.push(substituteVariables(content, variables));\n    }\n  }\n\n  return sections.join('\\n\\n---\\n\\n');\n}\n```\n\n---\n\n## Step 4: Create Default Template Sections\n\nCreate directory:\n```bash\nmkdir -p ~/.panopticon/templates/claude-md/sections\n```\n\n### workspace-info.md\n```markdown\n# Workspace: {{FEATURE_FOLDER}}\n\n**Issue:** {{ISSUE_ID}}\n**Branch:** {{BRANCH_NAME}}\n**Path:** {{WORKSPACE_PATH}}\n\n## URLs (if workspace has Docker)\n- Frontend: {{FRONTEND_URL}}\n- API: {{API_URL}}\n```\n\n### beads.md\n```markdown\n## Task Tracking (Beads)\n\nUse beads for persistent task tracking that survives compaction.\n\n\\`\\`\\`bash\nbd ready              # Find unblocked work\nbd show \u003cid\u003e          # Get full context\nbd update \u003cid\u003e --status in_progress  # Start work\nbd notes add \u003cid\u003e \"note\"  # Add progress (CRITICAL)\nbd close \u003cid\u003e --reason \"...\"  # Complete\nbd sync               # Persist to git\n\\`\\`\\`\n\n**ALWAYS** add notes as you work - they survive context compaction.\n```\n\n### commands-skills.md\n```markdown\n## Available Commands\n\n- `/work-status` - Show all running agents\n- `/work-tell \u003cid\u003e \u003cmsg\u003e` - Message an agent\n- `/work-approve \u003cid\u003e` - Approve and merge work\n\n## Skills\n\nSkills are in \\`~/.panopticon/skills/\\`. Run \\`pan skills\\` to list them.\n```\n\n### warnings.md\n```markdown\n## Warnings\n\n- **DO NOT** modify files outside this workspace\n- **DO NOT** push to main branch directly\n- **ALWAYS** run tests before marking work complete\n- **ALWAYS** add beads notes for long-running tasks\n```\n\n---\n\n## Step 5: Create Skills Merge Library (src/lib/skills-merge.ts)\n\n```typescript\nimport { existsSync, readdirSync, lstatSync, readlinkSync, symlinkSync, appendFileSync } from 'fs';\nimport { join } from 'path';\nimport { execSync } from 'child_process';\nimport { SKILLS_DIR } from './paths.js';\n\ntype ContentOrigin = 'git-tracked' | 'panopticon' | 'user-untracked';\n\nfunction detectContentOrigin(path: string, repoPath: string): ContentOrigin {\n  const stat = lstatSync(path);\n\n  // Check if symlink pointing to panopticon\n  if (stat.isSymbolicLink()) {\n    const target = readlinkSync(path);\n    if (target.includes('.panopticon')) {\n      return 'panopticon';\n    }\n  }\n\n  // Check if git-tracked\n  try {\n    execSync(`git ls-files --error-unmatch \"${path}\" 2\u003e/dev/null`, {\n      cwd: repoPath,\n    });\n    return 'git-tracked';\n  } catch {\n    return 'user-untracked';\n  }\n}\n\nexport function mergeSkillsIntoWorkspace(workspacePath: string): {\n  added: string[];\n  skipped: string[];\n} {\n  const skillsTarget = join(workspacePath, '.claude', 'skills');\n  const added: string[] = [];\n  const skipped: string[] = [];\n\n  // Get existing skills in workspace\n  const existingSkills = new Set\u003cstring\u003e();\n  if (existsSync(skillsTarget)) {\n    for (const item of readdirSync(skillsTarget)) {\n      existingSkills.add(item);\n    }\n  }\n\n  // Get panopticon skills\n  if (!existsSync(SKILLS_DIR)) return { added, skipped };\n\n  const panopticonSkills = readdirSync(SKILLS_DIR, { withFileTypes: true })\n    .filter((d) =\u003e d.isDirectory())\n    .map((d) =\u003e d.name);\n\n  for (const skill of panopticonSkills) {\n    const targetPath = join(skillsTarget, skill);\n\n    // Skip if exists and is git-tracked\n    if (existingSkills.has(skill)) {\n      const origin = detectContentOrigin(targetPath, workspacePath);\n      if (origin === 'git-tracked') {\n        skipped.push(`${skill} (git-tracked)`);\n        continue;\n      }\n      if (origin === 'panopticon') {\n        // Already ours, skip silently\n        continue;\n      }\n    }\n\n    // Create symlink\n    const sourcePath = join(SKILLS_DIR, skill);\n    try {\n      symlinkSync(sourcePath, targetPath);\n      added.push(skill);\n    } catch (error: any) {\n      if (error.code !== 'EEXIST') {\n        throw error;\n      }\n    }\n  }\n\n  // Update .gitignore\n  updateGitignore(workspacePath, added);\n\n  return { added, skipped };\n}\n\nfunction updateGitignore(workspacePath: string, skills: string[]): void {\n  const gitignorePath = join(workspacePath, '.claude', 'skills', '.gitignore');\n\n  const content = `\n# Panopticon-managed symlinks (not committed)\n${skills.join('\\n')}\n`;\n\n  appendFileSync(gitignorePath, content);\n}\n```\n\n---\n\n## Step 6: Create Workspace Command (src/cli/commands/workspace.ts)\n\n```typescript\nimport { Command } from 'commander';\nimport chalk from 'chalk';\nimport ora from 'ora';\nimport { existsSync, mkdirSync, writeFileSync } from 'fs';\nimport { join, basename } from 'path';\nimport { createWorktree, removeWorktree, listWorktrees } from '../lib/worktree.js';\nimport { generateClaudeMd, TemplateVariables } from '../lib/template.js';\nimport { mergeSkillsIntoWorkspace } from '../lib/skills-merge.js';\n\nexport function registerWorkspaceCommands(program: Command): void {\n  const workspace = program.command('workspace').description('Workspace management');\n\n  workspace\n    .command('create \u003cissueId\u003e')\n    .description('Create workspace for issue')\n    .option('--dry-run', 'Show what would be created')\n    .option('--no-docker', 'Skip Docker container setup')\n    .action(createCommand);\n\n  workspace\n    .command('list')\n    .description('List all workspaces')\n    .option('--json', 'Output as JSON')\n    .action(listCommand);\n\n  workspace\n    .command('destroy \u003cissueId\u003e')\n    .description('Destroy workspace')\n    .option('--keep-worktree', 'Keep git worktree for debugging')\n    .action(destroyCommand);\n}\n\ninterface CreateOptions {\n  dryRun?: boolean;\n  docker?: boolean;\n}\n\nasync function createCommand(issueId: string, options: CreateOptions): Promise\u003cvoid\u003e {\n  const spinner = ora('Creating workspace...').start();\n\n  try {\n    // Normalize issue ID\n    const normalizedId = issueId.toLowerCase().replace(/[^a-z0-9-]/g, '-');\n    const branchName = `feature/${normalizedId}`;\n    const folderName = `feature-${normalizedId}`;\n\n    // Determine paths\n    const projectRoot = process.cwd();\n    const workspacesDir = join(projectRoot, 'workspaces');\n    const workspacePath = join(workspacesDir, folderName);\n\n    if (options.dryRun) {\n      spinner.info('Dry run mode');\n      console.log('');\n      console.log(chalk.bold('Would create:'));\n      console.log(`  Workspace: ${workspacePath}`);\n      console.log(`  Branch:    ${branchName}`);\n      console.log(`  CLAUDE.md: ${join(workspacePath, 'CLAUDE.md')}`);\n      console.log(`  Skills:    ${join(workspacePath, '.claude', 'skills')}`);\n      return;\n    }\n\n    // Check if already exists\n    if (existsSync(workspacePath)) {\n      spinner.fail(`Workspace already exists: ${workspacePath}`);\n      process.exit(1);\n    }\n\n    // Create worktree\n    spinner.text = 'Creating git worktree...';\n    createWorktree(projectRoot, workspacePath, branchName);\n\n    // Generate CLAUDE.md\n    spinner.text = 'Generating CLAUDE.md...';\n    const variables: TemplateVariables = {\n      FEATURE_FOLDER: folderName,\n      BRANCH_NAME: branchName,\n      ISSUE_ID: issueId.toUpperCase(),\n      WORKSPACE_PATH: workspacePath,\n      FRONTEND_URL: `https://${folderName}.localhost:3000`,\n      API_URL: `https://api-${folderName}.localhost:8080`,\n    };\n\n    const claudeMd = generateClaudeMd(projectRoot, variables);\n    writeFileSync(join(workspacePath, 'CLAUDE.md'), claudeMd);\n\n    // Merge skills\n    spinner.text = 'Merging skills...';\n    mkdirSync(join(workspacePath, '.claude', 'skills'), { recursive: true });\n    const { added, skipped } = mergeSkillsIntoWorkspace(workspacePath);\n\n    spinner.succeed('Workspace created!');\n\n    console.log('');\n    console.log(chalk.bold('Workspace Details:'));\n    console.log(`  Path:   ${chalk.cyan(workspacePath)}`);\n    console.log(`  Branch: ${branchName}`);\n    console.log('');\n    console.log(chalk.bold('Skills:'));\n    console.log(`  Added:   ${added.length} Panopticon skills`);\n    if (skipped.length \u003e 0) {\n      console.log(`  Skipped: ${skipped.join(', ')}`);\n    }\n    console.log('');\n    console.log(chalk.dim('Next: pan work issue ' + issueId));\n\n  } catch (error: any) {\n    spinner.fail(error.message);\n    process.exit(1);\n  }\n}\n\nasync function listCommand(options: { json?: boolean }): Promise\u003cvoid\u003e {\n  const projectRoot = process.cwd();\n  const worktrees = listWorktrees(projectRoot);\n\n  // Filter to workspaces directory\n  const workspaces = worktrees.filter((w) =\u003e\n    w.path.includes('/workspaces/')\n  );\n\n  if (options.json) {\n    console.log(JSON.stringify(workspaces, null, 2));\n    return;\n  }\n\n  if (workspaces.length === 0) {\n    console.log(chalk.dim('No workspaces found.'));\n    return;\n  }\n\n  console.log(chalk.bold('\\nWorkspaces\\n'));\n\n  for (const ws of workspaces) {\n    const name = basename(ws.path);\n    console.log(`${chalk.cyan(name)}`);\n    console.log(`  Branch: ${ws.branch}`);\n    console.log(`  Path:   ${chalk.dim(ws.path)}`);\n    console.log('');\n  }\n}\n\nasync function destroyCommand(\n  issueId: string,\n  options: { keepWorktree?: boolean }\n): Promise\u003cvoid\u003e {\n  const spinner = ora('Destroying workspace...').start();\n\n  try {\n    const normalizedId = issueId.toLowerCase().replace(/[^a-z0-9-]/g, '-');\n    const folderName = `feature-${normalizedId}`;\n    const projectRoot = process.cwd();\n    const workspacePath = join(projectRoot, 'workspaces', folderName);\n\n    if (!existsSync(workspacePath)) {\n      spinner.fail(`Workspace not found: ${workspacePath}`);\n      process.exit(1);\n    }\n\n    if (!options.keepWorktree) {\n      spinner.text = 'Removing git worktree...';\n      removeWorktree(projectRoot, workspacePath);\n    }\n\n    spinner.succeed('Workspace destroyed');\n\n  } catch (error: any) {\n    spinner.fail(error.message);\n    process.exit(1);\n  }\n}\n```\n\n---\n\n## Step 7: Register Workspace Commands in CLI\n\nUpdate src/cli/index.ts:\n\n```typescript\nimport { registerWorkspaceCommands } from './commands/workspace.js';\n\n// ... existing code ...\n\nregisterWorkspaceCommands(program);\n```\n\n---\n\n## Verification Checklist\n\n```bash\n# 1. Build\nnpm run build\n# Expected: No errors\n\n# 2. Test dry-run\nnode dist/cli/index.js workspace create MIN-123 --dry-run\n# Expected: Shows what would be created\n\n# 3. Create workspace\nnode dist/cli/index.js workspace create MIN-123\n# Expected: \"Workspace created!\"\n\n# 4. Verify worktree\ngit worktree list\n# Expected: Shows workspaces/feature-min-123\n\n# 5. Check CLAUDE.md\ncat workspaces/feature-min-123/CLAUDE.md\n# Expected: Generated context with variables substituted\n\n# 6. Check skills\nls -la workspaces/feature-min-123/.claude/skills/\n# Expected: Symlinks to ~/.panopticon/skills/*\n\n# 7. List workspaces\nnode dist/cli/index.js workspace list\n# Expected: Shows MIN-123 workspace\n\n# 8. Destroy workspace\nnode dist/cli/index.js workspace destroy MIN-123\n# Expected: \"Workspace destroyed\"\n\n# 9. Verify removal\ngit worktree list\n# Expected: MIN-123 no longer listed\n```\n\n---\n\n## Common Gotchas\n\n1. **Git worktree requires clean state** - Commit or stash changes first\n2. **Branch already exists** - Use different issue ID or delete branch\n3. **Symlink permissions** - May need different approach on Windows\n4. **Template not found** - Run `pan init` to create default templates\n5. **Skills directory missing** - Run `pan sync` first\n\n---\n\n## Dependencies on Other Phases\n\n- **Depends on**: Phase 1 (paths), Phase 2 (skills for merge)\n- **Blocks**: Phase 3 (work issue uses workspace create)","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-17T17:57:03.269974903-08:00","created_by":"eltmon","updated_at":"2026-01-17T18:29:17.367177683-08:00","labels":["docker","workspace"],"dependencies":[{"issue_id":"panopticon-6ax.5","depends_on_id":"panopticon-6ax","type":"parent-child","created_at":"2026-01-17T17:57:03.28336584-08:00","created_by":"eltmon"}]}
{"id":"panopticon-6ax.6","title":"Phase 6: Installation System","description":"Implement the full installation flow with platform-specific handling.\n\n## Prerequisites\n- Node.js 18+ installed\n- npm account (eltmon) logged in (for publishing)\n- sudo access (for /etc/hosts, mkcert)\n- Docker Desktop or Docker Engine installed\n\n## Acceptance Criteria (Testable)\n- [ ] `pan install --check` verifies all prerequisites\n- [ ] `mkcert -install` succeeds (CA trusted)\n- [ ] `ls ~/.panopticon/certs/` shows .pem files\n- [ ] `docker network ls | grep panopticon` shows network\n- [ ] `curl https://pan.localhost:3001` works (after Traefik)\n- [ ] `pan install --minimal` skips Traefik (port-based only)\n\n---\n\n## Step 1: Create Install Command (src/cli/commands/install.ts)\n\n```typescript\nimport { Command } from 'commander';\nimport chalk from 'chalk';\nimport ora from 'ora';\nimport { execSync, exec } from 'child_process';\nimport { existsSync, mkdirSync, writeFileSync, appendFileSync, readFileSync } from 'fs';\nimport { join, homedir } from 'path';\nimport { detectPlatform, PANOPTICON_HOME } from '../lib/paths.js';\n\nexport function registerInstallCommand(program: Command): void {\n  program\n    .command('install')\n    .description('Install Panopticon prerequisites')\n    .option('--check', 'Check prerequisites only')\n    .option('--minimal', 'Skip Traefik (use port-based routing)')\n    .option('--skip-mkcert', 'Skip mkcert installation')\n    .option('--skip-docker', 'Skip Docker network setup')\n    .action(installCommand);\n}\n\ninterface InstallOptions {\n  check?: boolean;\n  minimal?: boolean;\n  skipMkcert?: boolean;\n  skipDocker?: boolean;\n}\n\nasync function installCommand(options: InstallOptions): Promise\u003cvoid\u003e {\n  console.log(chalk.bold('\\nPanopticon Installation\\n'));\n\n  const platform = detectPlatform();\n  console.log(`Platform: ${chalk.cyan(platform)}\\n`);\n\n  // Step 1: Check prerequisites\n  const prereqs = checkPrerequisites();\n\n  if (options.check) {\n    printPrereqStatus(prereqs);\n    process.exit(prereqs.allPassed ? 0 : 1);\n  }\n\n  if (!prereqs.allPassed) {\n    printPrereqStatus(prereqs);\n    console.log(chalk.red('\\nFix prerequisites before continuing.'));\n    process.exit(1);\n  }\n\n  // Step 2: Initialize Panopticon\n  const spinner = ora('Initializing Panopticon...').start();\n  await runInit();\n  spinner.succeed('Panopticon initialized');\n\n  // Step 3: mkcert setup\n  if (!options.skipMkcert \u0026\u0026 !options.minimal) {\n    spinner.start('Setting up mkcert...');\n    await setupMkcert(platform);\n    spinner.succeed('mkcert configured');\n  }\n\n  // Step 4: Docker network\n  if (!options.skipDocker) {\n    spinner.start('Creating Docker network...');\n    createDockerNetwork();\n    spinner.succeed('Docker network ready');\n  }\n\n  // Step 5: Traefik setup (unless minimal)\n  if (!options.minimal) {\n    spinner.start('Setting up Traefik...');\n    await setupTraefik();\n    spinner.succeed('Traefik configured');\n  }\n\n  // Step 6: DNS setup\n  spinner.start('Configuring DNS...');\n  await setupDns(platform);\n  spinner.succeed('DNS configured');\n\n  // Done!\n  printSuccessMessage(options.minimal);\n}\n\ninterface PrereqCheck {\n  name: string;\n  passed: boolean;\n  message: string;\n  fix?: string;\n}\n\ninterface PrereqResult {\n  checks: PrereqCheck[];\n  allPassed: boolean;\n}\n\nfunction checkPrerequisites(): PrereqResult {\n  const checks: PrereqCheck[] = [];\n\n  // Node.js version\n  try {\n    const version = execSync('node --version', { encoding: 'utf8' }).trim();\n    const major = parseInt(version.slice(1).split('.')[0]);\n    checks.push({\n      name: 'Node.js',\n      passed: major \u003e= 18,\n      message: `${version} (need 18+)`,\n      fix: 'Install Node.js 18+ from https://nodejs.org',\n    });\n  } catch {\n    checks.push({\n      name: 'Node.js',\n      passed: false,\n      message: 'Not found',\n      fix: 'Install Node.js from https://nodejs.org',\n    });\n  }\n\n  // Docker\n  try {\n    const version = execSync('docker --version', { encoding: 'utf8' }).trim();\n    checks.push({ name: 'Docker', passed: true, message: version });\n  } catch {\n    checks.push({\n      name: 'Docker',\n      passed: false,\n      message: 'Not found',\n      fix: 'Install Docker Desktop or Docker Engine',\n    });\n  }\n\n  // Docker Compose\n  try {\n    const version = execSync('docker compose version', { encoding: 'utf8' }).trim();\n    checks.push({ name: 'Docker Compose', passed: true, message: version });\n  } catch {\n    checks.push({\n      name: 'Docker Compose',\n      passed: false,\n      message: 'Not found',\n      fix: 'Install Docker Compose (usually bundled with Docker Desktop)',\n    });\n  }\n\n  // Git\n  try {\n    const version = execSync('git --version', { encoding: 'utf8' }).trim();\n    checks.push({ name: 'Git', passed: true, message: version });\n  } catch {\n    checks.push({\n      name: 'Git',\n      passed: false,\n      message: 'Not found',\n      fix: 'Install git: apt install git / brew install git',\n    });\n  }\n\n  // tmux\n  try {\n    const version = execSync('tmux -V', { encoding: 'utf8' }).trim();\n    checks.push({ name: 'tmux', passed: true, message: version });\n  } catch {\n    checks.push({\n      name: 'tmux',\n      passed: false,\n      message: 'Not found',\n      fix: 'Install tmux: apt install tmux / brew install tmux',\n    });\n  }\n\n  // mkcert (optional but recommended)\n  try {\n    execSync('which mkcert', { encoding: 'utf8' });\n    checks.push({ name: 'mkcert', passed: true, message: 'Installed' });\n  } catch {\n    checks.push({\n      name: 'mkcert',\n      passed: true, // Optional\n      message: 'Not installed (optional)',\n      fix: 'Install: brew install mkcert / apt install mkcert',\n    });\n  }\n\n  return {\n    checks,\n    allPassed: checks.filter((c) =\u003e c.name !== 'mkcert').every((c) =\u003e c.passed),\n  };\n}\n\nfunction printPrereqStatus(prereqs: PrereqResult): void {\n  console.log(chalk.bold('Prerequisites:\\n'));\n\n  for (const check of prereqs.checks) {\n    const icon = check.passed ? chalk.green('✓') : chalk.red('✗');\n    console.log(`  ${icon} ${check.name}: ${check.message}`);\n    if (!check.passed \u0026\u0026 check.fix) {\n      console.log(`    ${chalk.dim('Fix: ' + check.fix)}`);\n    }\n  }\n}\n\nasync function runInit(): Promise\u003cvoid\u003e {\n  // Create directories\n  const dirs = [\n    PANOPTICON_HOME,\n    join(PANOPTICON_HOME, 'skills'),\n    join(PANOPTICON_HOME, 'commands'),\n    join(PANOPTICON_HOME, 'agents'),\n    join(PANOPTICON_HOME, 'certs'),\n    join(PANOPTICON_HOME, 'templates'),\n    join(PANOPTICON_HOME, 'backups'),\n  ];\n\n  for (const dir of dirs) {\n    mkdirSync(dir, { recursive: true });\n  }\n}\n\nasync function setupMkcert(platform: string): Promise\u003cvoid\u003e {\n  const certsDir = join(PANOPTICON_HOME, 'certs');\n\n  // Install CA\n  try {\n    execSync('mkcert -install', { stdio: 'pipe' });\n  } catch (error: any) {\n    if (!error.message.includes('already installed')) {\n      throw error;\n    }\n  }\n\n  // Generate certificates\n  const certPath = join(certsDir, 'localhost.pem');\n  const keyPath = join(certsDir, 'localhost-key.pem');\n\n  if (!existsSync(certPath)) {\n    execSync(\n      `mkcert -cert-file \"${certPath}\" -key-file \"${keyPath}\" \"*.localhost\" \"*.pan.localhost\" localhost 127.0.0.1`,\n      { cwd: certsDir }\n    );\n  }\n}\n\nfunction createDockerNetwork(): void {\n  try {\n    execSync('docker network inspect panopticon-public', { stdio: 'pipe' });\n  } catch {\n    execSync('docker network create panopticon-public');\n  }\n}\n\nasync function setupTraefik(): Promise\u003cvoid\u003e {\n  const traefikDir = join(PANOPTICON_HOME, 'traefik');\n  mkdirSync(traefikDir, { recursive: true });\n\n  // Create traefik.yml\n  const traefikConfig = `\napi:\n  dashboard: true\n  insecure: true\n\nentryPoints:\n  web:\n    address: \":80\"\n    http:\n      redirections:\n        entryPoint:\n          to: websecure\n  websecure:\n    address: \":443\"\n\nproviders:\n  docker:\n    endpoint: \"unix:///var/run/docker.sock\"\n    exposedByDefault: false\n    network: panopticon-public\n  file:\n    directory: /etc/traefik/dynamic\n    watch: true\n\ntls:\n  certificates:\n    - certFile: /certs/localhost.pem\n      keyFile: /certs/localhost-key.pem\n`;\n\n  writeFileSync(join(traefikDir, 'traefik.yml'), traefikConfig);\n\n  // Create docker-compose.yml for Traefik\n  const dockerCompose = `\nversion: '3.8'\nservices:\n  traefik:\n    image: traefik:v3.0\n    container_name: panopticon-traefik\n    restart: unless-stopped\n    ports:\n      - \"80:80\"\n      - \"443:443\"\n      - \"8080:8080\"\n    volumes:\n      - /var/run/docker.sock:/var/run/docker.sock:ro\n      - ./traefik.yml:/etc/traefik/traefik.yml:ro\n      - ../certs:/certs:ro\n      - ./dynamic:/etc/traefik/dynamic:ro\n    networks:\n      - panopticon-public\n    labels:\n      - \"traefik.enable=true\"\n      - \"traefik.http.routers.traefik.rule=Host(\\`traefik.pan.localhost\\`)\"\n      - \"traefik.http.routers.traefik.tls=true\"\n\nnetworks:\n  panopticon-public:\n    external: true\n`;\n\n  writeFileSync(join(traefikDir, 'docker-compose.yml'), dockerCompose);\n\n  // Create dynamic config directory\n  mkdirSync(join(traefikDir, 'dynamic'), { recursive: true });\n}\n\nasync function setupDns(platform: string): Promise\u003cvoid\u003e {\n  const hostsEntries = `\n# Panopticon\n127.0.0.1 pan.localhost\n127.0.0.1 traefik.pan.localhost\n`;\n\n  if (platform === 'wsl2') {\n    console.log(chalk.yellow('\\nWSL2 detected. Manual DNS setup required:'));\n    console.log('1. Add to Windows hosts file (C:\\\\Windows\\\\System32\\\\drivers\\\\etc\\\\hosts):');\n    console.log(chalk.dim(hostsEntries));\n    console.log('2. Or use the sync-hosts.ps1 script');\n  } else {\n    // Try to update /etc/hosts\n    try {\n      const hosts = readFileSync('/etc/hosts', 'utf8');\n      if (!hosts.includes('pan.localhost')) {\n        console.log(chalk.yellow('\\nAdd these lines to /etc/hosts (requires sudo):'));\n        console.log(chalk.dim(hostsEntries));\n      }\n    } catch {\n      console.log(chalk.yellow('\\nCould not read /etc/hosts'));\n    }\n  }\n}\n\nfunction printSuccessMessage(minimal: boolean): void {\n  console.log('');\n  console.log(chalk.green('═'.repeat(60)));\n  console.log(chalk.green.bold('  PANOPTICON INSTALLED SUCCESSFULLY'));\n  console.log(chalk.green('═'.repeat(60)));\n  console.log('');\n\n  if (minimal) {\n    console.log('  Mode: Minimal (port-based routing)');\n    console.log('  Dashboard: http://localhost:3001');\n    console.log('  API:       http://localhost:3002');\n  } else {\n    console.log('  Dashboard: https://pan.localhost:3001');\n    console.log('  Traefik:   https://traefik.pan.localhost:8080');\n  }\n\n  console.log('');\n  console.log(chalk.bold('  Next steps:'));\n  console.log('    pan sync           # Sync skills to Claude Code');\n  console.log('    pan up             # Start the dashboard');\n  console.log('    pan work issue ID  # Start working on an issue');\n  console.log('');\n}\n```\n\n---\n\n## Step 2: Register Install Command\n\nUpdate src/cli/index.ts:\n\n```typescript\nimport { registerInstallCommand } from './commands/install.js';\n\n// ... existing code ...\n\nregisterInstallCommand(program);\n```\n\n---\n\n## Step 3: Create WSL2 Host Sync Script\n\nCreate scripts/sync-hosts.ps1:\n\n```powershell\n# Panopticon WSL2 Hosts Sync\n# Run as Administrator\n\n$wslHostsFile = \"\\\\wsl$\\Ubuntu\\home\\$env:USERNAME\\.wsl2hosts\"\n$windowsHosts = \"$env:SystemRoot\\System32\\drivers\\etc\\hosts\"\n\nif (Test-Path $wslHostsFile) {\n    $wslContent = Get-Content $wslHostsFile -Raw\n    $currentHosts = Get-Content $windowsHosts -Raw\n\n    # Remove old Panopticon entries\n    $cleanedHosts = $currentHosts -replace \"(?m)^# Panopticon[\\s\\S]*?(?=^[^#]|\\z)\", \"\"\n\n    # Add new entries\n    $newHosts = $cleanedHosts.TrimEnd() + \"`n`n\" + $wslContent\n\n    Set-Content -Path $windowsHosts -Value $newHosts -Force\n    Write-Host \"Hosts file updated successfully\"\n} else {\n    Write-Host \"WSL hosts file not found: $wslHostsFile\"\n}\n```\n\n---\n\n## Step 4: Create Starter Templates\n\n### Minimal Template (templates/minimal/)\n\n```bash\nmkdir -p ~/.panopticon/templates/minimal\n```\n\ntemplates/minimal/template.toml:\n```toml\n[template]\nname = \"minimal\"\ndescription = \"Minimal dev container with Claude Code\"\n\n[docker]\ncompose = \"docker-compose.yml\"\n```\n\ntemplates/minimal/docker-compose.yml:\n```yaml\nversion: '3.8'\nservices:\n  dev:\n    image: mcr.microsoft.com/devcontainers/base:ubuntu\n    volumes:\n      - .:/workspace\n    working_dir: /workspace\n    command: sleep infinity\n```\n\n### Node Fullstack Template (templates/node-fullstack/)\n\ntemplates/node-fullstack/docker-compose.yml:\n```yaml\nversion: '3.8'\nservices:\n  frontend:\n    build: ./frontend\n    volumes:\n      - ./frontend:/app\n    ports:\n      - \"3000:3000\"\n    labels:\n      - \"traefik.enable=true\"\n      - \"traefik.http.routers.fe-{{ISSUE_ID}}.rule=Host(`{{ISSUE_ID}}.localhost`)\"\n      - \"traefik.http.routers.fe-{{ISSUE_ID}}.tls=true\"\n\n  api:\n    build: ./api\n    volumes:\n      - ./api:/app\n    ports:\n      - \"8080:8080\"\n    depends_on:\n      - db\n\n  db:\n    image: postgres:15\n    environment:\n      POSTGRES_DB: app\n      POSTGRES_USER: app\n      POSTGRES_PASSWORD: dev\n    volumes:\n      - pgdata:/var/lib/postgresql/data\n\nvolumes:\n  pgdata:\n```\n\n---\n\n## Verification Checklist\n\n```bash\n# 1. Build\nnpm run build\n# Expected: No errors\n\n# 2. Check prerequisites\nnode dist/cli/index.js install --check\n# Expected: All green checkmarks (except maybe mkcert)\n\n# 3. Install minimal\nnode dist/cli/index.js install --minimal\n# Expected: Success without Traefik\n\n# 4. Verify directories\nls ~/.panopticon/\n# Expected: skills/, commands/, agents/, certs/, templates/\n\n# 5. For full install (if mkcert available)\nnode dist/cli/index.js install\n# Expected: Success with Traefik config\n\n# 6. Check certificates\nls ~/.panopticon/certs/\n# Expected: localhost.pem, localhost-key.pem\n\n# 7. Check Docker network\ndocker network ls | grep panopticon\n# Expected: panopticon-public\n\n# 8. Start Traefik (if full install)\ncd ~/.panopticon/traefik \u0026\u0026 docker compose up -d\n# Expected: Traefik container running\n\n# 9. Verify Traefik dashboard\ncurl -k https://traefik.pan.localhost:8080/api/version\n# Expected: JSON with Traefik version\n```\n\n---\n\n## Common Gotchas\n\n1. **mkcert not installed** - Use `--skip-mkcert` or install it\n2. **Docker not running** - Start Docker Desktop first\n3. **Port 80/443 in use** - Stop other web servers\n4. **WSL2 networking** - May need manual hosts file edit\n5. **Permission denied** - Need sudo for /etc/hosts\n\n---\n\n## Dependencies on Other Phases\n\n- **Depends on**: None (can run standalone)\n- **Blocks**: All other phases (this is the entry point)\n\n---\n\n## Platform-Specific Notes\n\n### macOS\n- mkcert: `brew install mkcert`\n- /etc/hosts editable with sudo\n\n### Linux (Ubuntu/Debian)\n- mkcert: `apt install mkcert` or download binary\n- /etc/hosts editable with sudo\n\n### WSL2\n- mkcert must be installed in BOTH WSL2 and Windows\n- Hosts file in Windows: C:\\Windows\\System32\\drivers\\etc\\hosts\n- Use sync-hosts.ps1 for automation\n- Consider dnsmasq for wildcard DNS","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-17T17:57:10.999620431-08:00","created_by":"eltmon","updated_at":"2026-01-17T18:30:34.93928654-08:00","labels":["infrastructure","install"],"dependencies":[{"issue_id":"panopticon-6ax.6","depends_on_id":"panopticon-6ax","type":"parent-child","created_at":"2026-01-17T17:57:11.011416369-08:00","created_by":"eltmon"}]}
{"id":"panopticon-6ax.7","title":"Phase 7: npm Publishing","description":"Prepare and publish to npm with supply chain security.\n\n## Prerequisites\n- All core phases (1-6) complete and tested\n- npm account created and logged in\n- GitHub account with access to create repos\n- 2FA enabled on npm account\n\n## Acceptance Criteria (Testable)\n- [ ] `npm whoami` shows your npm username\n- [ ] GitHub repo exists at github.com/eltmon/panopticon-cli\n- [ ] `npm run build` produces dist/ with no errors\n- [ ] `npx panopticon-cli --version` works after publish\n- [ ] npm package shows provenance badge\n- [ ] GitHub Actions CI passes on push\n\n---\n\n## Step 1: Finalize package.json\n\n```json\n{\n  \"name\": \"panopticon-cli\",\n  \"version\": \"0.1.0\",\n  \"description\": \"Multi-agent orchestration for Claude Code\",\n  \"keywords\": [\n    \"claude-code\",\n    \"ai-agents\",\n    \"orchestration\",\n    \"dashboard\",\n    \"linear\",\n    \"devtools\",\n    \"claude\",\n    \"codex\",\n    \"cursor\"\n  ],\n  \"author\": \"Edward Becker \u003ced@mindyournow.com\u003e\",\n  \"license\": \"MIT\",\n  \"repository\": {\n    \"type\": \"git\",\n    \"url\": \"https://github.com/eltmon/panopticon-cli.git\"\n  },\n  \"homepage\": \"https://github.com/eltmon/panopticon-cli#readme\",\n  \"bugs\": {\n    \"url\": \"https://github.com/eltmon/panopticon-cli/issues\"\n  },\n  \"bin\": {\n    \"pan\": \"./dist/cli/index.js\",\n    \"panopticon\": \"./dist/cli/index.js\"\n  },\n  \"main\": \"./dist/index.js\",\n  \"types\": \"./dist/index.d.ts\",\n  \"files\": [\n    \"dist\",\n    \"templates\",\n    \"README.md\",\n    \"LICENSE\"\n  ],\n  \"engines\": {\n    \"node\": \"\u003e=18.0.0\"\n  },\n  \"scripts\": {\n    \"build\": \"tsc\",\n    \"dev\": \"tsc --watch\",\n    \"typecheck\": \"tsc --noEmit\",\n    \"test\": \"vitest run\",\n    \"test:watch\": \"vitest\",\n    \"lint\": \"eslint src/\",\n    \"prepublishOnly\": \"npm run build \u0026\u0026 npm run test\"\n  }\n}\n```\n\n---\n\n## Step 2: Create GitHub Repository\n\n```bash\n# Navigate to project\ncd /home/eltmon/projects/panopticon\n\n# Initialize git if not already\ngit init\n\n# Create .gitignore\ncat \u003e .gitignore \u003c\u003c 'EOF'\nnode_modules/\ndist/\n*.log\n.env\n.DS_Store\ncoverage/\nEOF\n\n# Add all files\ngit add .\ngit commit -m \"Initial commit: Panopticon CLI\"\n\n# Create repo on GitHub (using gh CLI)\ngh repo create eltmon/panopticon-cli --public --source=. --remote=origin --push\n\n# Or manually:\n# 1. Go to github.com/new\n# 2. Name: panopticon-cli\n# 3. Public\n# 4. Don't initialize with README\n# 5. git remote add origin https://github.com/eltmon/panopticon-cli.git\n# 6. git push -u origin main\n```\n\n---\n\n## Step 3: Create LICENSE File\n\n```bash\ncat \u003e LICENSE \u003c\u003c 'EOF'\nMIT License\n\nCopyright (c) 2026 Edward Becker\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\nEOF\n```\n\n---\n\n## Step 4: Create GitHub Actions CI Workflow\n\nCreate .github/workflows/ci.yml:\n\n```yaml\nname: CI\n\non:\n  push:\n    branches: [main]\n  pull_request:\n    branches: [main]\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n\n    strategy:\n      matrix:\n        node-version: [18, 20, 22]\n\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n\n      - name: Setup Node.js\n        uses: actions/setup-node@v4\n        with:\n          node-version: ${{ matrix.node-version }}\n          cache: 'npm'\n\n      - name: Install dependencies\n        run: npm ci\n\n      - name: Build\n        run: npm run build\n\n      - name: Type check\n        run: npm run typecheck\n\n      - name: Test\n        run: npm test\n\n  lint:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - uses: actions/setup-node@v4\n        with:\n          node-version: '20'\n          cache: 'npm'\n      - run: npm ci\n      - run: npm run lint\n```\n\n---\n\n## Step 5: Create GitHub Actions Publish Workflow\n\nCreate .github/workflows/publish.yml:\n\n```yaml\nname: Publish to npm\n\non:\n  release:\n    types: [published]\n\njobs:\n  publish:\n    runs-on: ubuntu-latest\n    permissions:\n      contents: read\n      id-token: write  # Required for npm provenance\n\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n\n      - name: Setup Node.js\n        uses: actions/setup-node@v4\n        with:\n          node-version: '20'\n          registry-url: 'https://registry.npmjs.org'\n          cache: 'npm'\n\n      - name: Install dependencies\n        run: npm ci\n\n      - name: Build\n        run: npm run build\n\n      - name: Test\n        run: npm test\n\n      - name: Publish with provenance\n        run: npm publish --provenance --access public\n        env:\n          NODE_AUTH_TOKEN: ${{ secrets.NPM_TOKEN }}\n```\n\n---\n\n## Step 6: Create npm Access Token\n\n1. Go to https://www.npmjs.com/settings/eltmon/tokens\n2. Click \"Generate New Token\"\n3. Select \"Granular Access Token\" (NOT classic)\n4. Name: \"panopticon-cli-publish\"\n5. Expiration: 90 days\n6. Packages and scopes: Only select packages \u003e panopticon-cli\n7. Permissions: Read and write\n8. Copy the token (you won't see it again!)\n\n---\n\n## Step 7: Add npm Token to GitHub Secrets\n\n1. Go to https://github.com/eltmon/panopticon-cli/settings/secrets/actions\n2. Click \"New repository secret\"\n3. Name: NPM_TOKEN\n4. Value: (paste the token from step 6)\n5. Click \"Add secret\"\n\n---\n\n## Step 8: Create Token Rotation Reminder Workflow\n\nCreate .github/workflows/token-rotation.yml:\n\n```yaml\nname: npm Token Rotation Reminder\n\non:\n  schedule:\n    - cron: '0 9 1 */2 *'  # 1st of every 2nd month at 9am UTC\n\njobs:\n  remind:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Create reminder issue\n        uses: actions/github-script@v7\n        with:\n          script: |\n            github.rest.issues.create({\n              owner: context.repo.owner,\n              repo: context.repo.repo,\n              title: 'npm Token Rotation Due',\n              body: `## npm Token Rotation Reminder\n\nThe NPM_TOKEN secret should be rotated every 90 days for security.\n\n### Steps:\n1. Go to https://www.npmjs.com/settings/eltmon/tokens\n2. Generate a new granular access token for panopticon-cli\n3. Update the NPM_TOKEN secret in this repo's settings\n4. Delete the old token from npm\n\nLast rotation: Check secret creation date in settings.`,\n              labels: ['maintenance', 'security']\n            })\n```\n\n---\n\n## Step 9: Create CODEOWNERS\n\nCreate .github/CODEOWNERS:\n\n```\n# Default owner for everything\n* @eltmon\n\n# CI/CD files need careful review\n/.github/ @eltmon\n```\n\n---\n\n## Step 10: Create Issue Templates\n\nCreate .github/ISSUE_TEMPLATE/bug_report.yml:\n\n```yaml\nname: Bug Report\ndescription: Report a bug in Panopticon\ntitle: \"[Bug]: \"\nlabels: [\"bug\", \"triage\"]\nbody:\n  - type: textarea\n    id: description\n    attributes:\n      label: Bug Description\n      description: What happened?\n    validations:\n      required: true\n\n  - type: textarea\n    id: reproduce\n    attributes:\n      label: Steps to Reproduce\n      description: How can we reproduce this?\n      placeholder: |\n        1. Run `pan ...`\n        2. See error\n    validations:\n      required: true\n\n  - type: textarea\n    id: expected\n    attributes:\n      label: Expected Behavior\n      description: What should have happened?\n\n  - type: input\n    id: version\n    attributes:\n      label: Panopticon Version\n      description: Output of `pan --version`\n    validations:\n      required: true\n\n  - type: dropdown\n    id: os\n    attributes:\n      label: Operating System\n      options:\n        - macOS\n        - Linux\n        - WSL2\n        - Windows\n```\n\n---\n\n## Step 11: Create README with Badges\n\n```markdown\n# Panopticon\n\n[![npm version](https://img.shields.io/npm/v/panopticon-cli.svg)](https://www.npmjs.com/package/panopticon-cli)\n[![npm downloads](https://img.shields.io/npm/dm/panopticon-cli.svg)](https://www.npmjs.com/package/panopticon-cli)\n[![CI](https://github.com/eltmon/panopticon-cli/actions/workflows/ci.yml/badge.svg)](https://github.com/eltmon/panopticon-cli/actions/workflows/ci.yml)\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n[![npm provenance](https://img.shields.io/badge/npm-provenance-green)](https://docs.npmjs.com/generating-provenance-statements)\n\nMulti-agent orchestration for Claude Code.\n\n## Quick Start\n\n\\`\\`\\`bash\n# Install globally\nnpm install -g panopticon-cli\n\n# Or use npx\nnpx panopticon-cli install\n\n# Initialize\npan init\n\n# Sync skills to Claude Code\npan sync\n\n# Start dashboard\npan up\n\\`\\`\\`\n\n## Features\n\n- Spawn autonomous agents for Linear issues\n- Real-time dashboard for monitoring agents\n- Cross-platform skills (Claude Code, Codex, Cursor, Gemini CLI)\n- Docker workspace isolation\n- Health monitoring and stuck detection\n\n## Documentation\n\nSee [docs/](./docs/) for full documentation.\n\n## License\n\nMIT\n```\n\n---\n\n## Step 12: Local Testing Before Publish\n\n```bash\n# Build\nnpm run build\n\n# Test locally with npm link\nnpm link\n\n# Verify it works\npan --version\npan --help\n\n# Unlink when done\nnpm unlink panopticon-cli\n```\n\n---\n\n## Step 13: First Publish\n\n```bash\n# Login to npm (if not already)\nnpm login\n\n# Verify you're logged in\nnpm whoami\n# Expected: eltmon\n\n# Publish (first time, no provenance yet)\nnpm publish --access public\n\n# Check on npm\nopen https://www.npmjs.com/package/panopticon-cli\n```\n\n---\n\n## Step 14: Create First Release on GitHub\n\n1. Go to https://github.com/eltmon/panopticon-cli/releases\n2. Click \"Create a new release\"\n3. Tag: v0.1.0\n4. Title: v0.1.0 - Initial Release\n5. Description: Copy from CHANGELOG.md\n6. Click \"Publish release\"\n\nThis triggers the publish workflow with provenance!\n\n---\n\n## Verification Checklist\n\n```bash\n# 1. Verify npm login\nnpm whoami\n# Expected: eltmon\n\n# 2. Verify GitHub repo\ngh repo view eltmon/panopticon-cli\n# Expected: Shows repo info\n\n# 3. Verify CI passes\ngh run list --repo eltmon/panopticon-cli\n# Expected: Shows recent runs\n\n# 4. Test published package\nnpx panopticon-cli@latest --version\n# Expected: 0.1.0\n\n# 5. Check provenance (after first release)\nnpm view panopticon-cli\n# Expected: Shows package with provenance info\n\n# 6. Verify badges on npm page\nopen https://www.npmjs.com/package/panopticon-cli\n# Expected: Shows download count, version, etc.\n```\n\n---\n\n## Common Gotchas\n\n1. **npm 2FA required** - Enable in npm settings\n2. **Provenance only works in GitHub Actions** - Not local publish\n3. **Token scope too narrow** - Must include panopticon-cli package\n4. **prepublishOnly fails** - Fix tests before publishing\n5. **Version already exists** - Bump version in package.json\n\n---\n\n## Dependencies on Other Phases\n\n- **Depends on**: Phases 1-6 (all core functionality)\n- **Blocks**: Nothing (can publish incrementally)\n\n---\n\n## Security Checklist\n\n- [ ] 2FA enabled on npm account\n- [ ] Granular token (not classic)\n- [ ] Token scoped to single package\n- [ ] Token stored in GitHub Secrets (not committed)\n- [ ] Provenance enabled in publish workflow\n- [ ] Dependabot enabled on repo\n- [ ] Branch protection on main","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-17T17:57:18.481585358-08:00","created_by":"eltmon","updated_at":"2026-01-17T18:31:44.163892687-08:00","labels":["npm","publish"],"dependencies":[{"issue_id":"panopticon-6ax.7","depends_on_id":"panopticon-6ax","type":"parent-child","created_at":"2026-01-17T17:57:18.493679494-08:00","created_by":"eltmon"}]}
{"id":"panopticon-6ax.8","title":"Phase 8: Issue Tracker Integration","description":"Implement issue tracker abstraction with Linear and GitHub Issues support.\n\n## Prerequisites\n- Phase 1 complete (config system)\n- Phase 3 complete (work commands)\n- LINEAR_API_KEY environment variable set\n- GITHUB_TOKEN environment variable set (for GitHub Issues)\n\n## Acceptance Criteria (Testable)\n- [ ] `pan work list` shows Linear issues\n- [ ] `pan work list --tracker github` shows GitHub issues\n- [ ] `pan work triage` lists untriaged GitHub issues\n- [ ] `pan work triage #42 --create` creates Linear issue from GitHub\n- [ ] Issue state changes sync between trackers\n- [ ] Dashboard shows issues from configured trackers\n\n---\n\n## Step 1: Install Dependencies\n\n```bash\ncd /home/eltmon/projects/panopticon\nnpm install @linear/sdk @octokit/rest\nnpm install -D @types/node\n```\n\n---\n\n## Step 2: Create Tracker Interface (src/lib/trackers/interface.ts)\n\n```typescript\nexport interface IssueFilters {\n  state?: 'open' | 'in_progress' | 'closed' | 'all';\n  labels?: string[];\n  assignee?: string;\n  limit?: number;\n}\n\nexport interface Issue {\n  id: string;           // Tracker-specific ID\n  ref: string;          // Human-readable (MIN-630, #42)\n  title: string;\n  description: string;\n  state: 'open' | 'in_progress' | 'closed';\n  labels: string[];\n  assignee?: string;\n  url: string;\n  tracker: string;\n  createdAt: Date;\n  updatedAt: Date;\n  linkedIssues?: string[];\n}\n\nexport interface NewIssue {\n  title: string;\n  description?: string;\n  labels?: string[];\n  assignee?: string;\n}\n\nexport interface IssueUpdate {\n  title?: string;\n  description?: string;\n  state?: 'open' | 'in_progress' | 'closed';\n  labels?: string[];\n  assignee?: string;\n}\n\nexport interface Comment {\n  id: string;\n  body: string;\n  author: string;\n  createdAt: Date;\n}\n\nexport interface IssueTracker {\n  readonly name: string;\n\n  // Core operations\n  listIssues(filters?: IssueFilters): Promise\u003cIssue[]\u003e;\n  getIssue(id: string): Promise\u003cIssue\u003e;\n  createIssue(issue: NewIssue): Promise\u003cIssue\u003e;\n  updateIssue(id: string, update: IssueUpdate): Promise\u003cIssue\u003e;\n\n  // Comments\n  getComments(issueId: string): Promise\u003cComment[]\u003e;\n  addComment(issueId: string, body: string): Promise\u003cComment\u003e;\n\n  // State transitions\n  transitionIssue(id: string, state: Issue['state']): Promise\u003cvoid\u003e;\n\n  // PR linking\n  linkPR(issueId: string, prUrl: string): Promise\u003cvoid\u003e;\n}\n```\n\n---\n\n## Step 3: Create Linear Adapter (src/lib/trackers/linear.ts)\n\n```typescript\nimport { LinearClient, Issue as LinearIssue } from '@linear/sdk';\nimport { IssueTracker, Issue, IssueFilters, NewIssue, IssueUpdate, Comment } from './interface.js';\n\nexport class LinearTracker implements IssueTracker {\n  readonly name = 'linear';\n  private client: LinearClient;\n  private teamId: string;\n\n  constructor(apiKey: string, teamKey: string) {\n    this.client = new LinearClient({ apiKey });\n    this.teamId = teamKey;\n  }\n\n  async listIssues(filters?: IssueFilters): Promise\u003cIssue[]\u003e {\n    const stateFilter = filters?.state === 'all' ? undefined : {\n      state: { type: { in: this.mapStateFilter(filters?.state) } }\n    };\n\n    const issues = await this.client.issues({\n      first: filters?.limit || 50,\n      filter: {\n        team: { key: { eq: this.teamId } },\n        ...stateFilter,\n      },\n    });\n\n    return issues.nodes.map((i) =\u003e this.mapIssue(i));\n  }\n\n  async getIssue(id: string): Promise\u003cIssue\u003e {\n    // Try by identifier first (MIN-123)\n    let issue: LinearIssue | null = null;\n\n    try {\n      const result = await this.client.issue(id);\n      issue = result;\n    } catch {\n      // Try searching by identifier\n      const issues = await this.client.issues({\n        filter: { identifier: { eq: id.toUpperCase() } },\n      });\n      issue = issues.nodes[0] || null;\n    }\n\n    if (!issue) {\n      throw new Error(`Issue not found: ${id}`);\n    }\n\n    return this.mapIssue(issue);\n  }\n\n  async createIssue(newIssue: NewIssue): Promise\u003cIssue\u003e {\n    const team = await this.client.team(this.teamId);\n\n    const created = await this.client.createIssue({\n      teamId: team.id,\n      title: newIssue.title,\n      description: newIssue.description,\n    });\n\n    const issue = await created.issue;\n    if (!issue) throw new Error('Failed to create issue');\n\n    return this.mapIssue(issue);\n  }\n\n  async updateIssue(id: string, update: IssueUpdate): Promise\u003cIssue\u003e {\n    const issue = await this.getIssue(id);\n\n    await this.client.updateIssue(issue.id, {\n      title: update.title,\n      description: update.description,\n    });\n\n    return this.getIssue(id);\n  }\n\n  async getComments(issueId: string): Promise\u003cComment[]\u003e {\n    const issue = await this.client.issue(issueId);\n    const comments = await issue.comments();\n\n    return comments.nodes.map((c) =\u003e ({\n      id: c.id,\n      body: c.body,\n      author: c.user?.name || 'Unknown',\n      createdAt: new Date(c.createdAt),\n    }));\n  }\n\n  async addComment(issueId: string, body: string): Promise\u003cComment\u003e {\n    const result = await this.client.createComment({\n      issueId,\n      body,\n    });\n\n    const comment = await result.comment;\n    if (!comment) throw new Error('Failed to create comment');\n\n    return {\n      id: comment.id,\n      body: comment.body,\n      author: 'Panopticon',\n      createdAt: new Date(comment.createdAt),\n    };\n  }\n\n  async transitionIssue(id: string, state: Issue['state']): Promise\u003cvoid\u003e {\n    const issue = await this.client.issue(id);\n    const team = await issue.team;\n    if (!team) throw new Error('No team found');\n\n    const states = await team.states();\n    const targetState = states.nodes.find((s) =\u003e {\n      if (state === 'open') return s.type === 'backlog' || s.type === 'unstarted';\n      if (state === 'in_progress') return s.type === 'started';\n      if (state === 'closed') return s.type === 'completed';\n      return false;\n    });\n\n    if (targetState) {\n      await this.client.updateIssue(id, { stateId: targetState.id });\n    }\n  }\n\n  async linkPR(issueId: string, prUrl: string): Promise\u003cvoid\u003e {\n    await this.addComment(issueId, `PR opened: ${prUrl}`);\n  }\n\n  private mapIssue(issue: any): Issue {\n    return {\n      id: issue.id,\n      ref: issue.identifier,\n      title: issue.title,\n      description: issue.description || '',\n      state: this.mapState(issue.state?.type),\n      labels: issue.labels?.nodes?.map((l: any) =\u003e l.name) || [],\n      assignee: issue.assignee?.name,\n      url: issue.url,\n      tracker: 'linear',\n      createdAt: new Date(issue.createdAt),\n      updatedAt: new Date(issue.updatedAt),\n    };\n  }\n\n  private mapState(type?: string): Issue['state'] {\n    switch (type) {\n      case 'started': return 'in_progress';\n      case 'completed':\n      case 'canceled': return 'closed';\n      default: return 'open';\n    }\n  }\n\n  private mapStateFilter(state?: string): string[] {\n    switch (state) {\n      case 'open': return ['backlog', 'unstarted', 'triage'];\n      case 'in_progress': return ['started'];\n      case 'closed': return ['completed', 'canceled'];\n      default: return ['backlog', 'unstarted', 'started', 'triage'];\n    }\n  }\n}\n```\n\n---\n\n## Step 4: Create GitHub Adapter (src/lib/trackers/github.ts)\n\n```typescript\nimport { Octokit } from '@octokit/rest';\nimport { IssueTracker, Issue, IssueFilters, NewIssue, IssueUpdate, Comment } from './interface.js';\n\nexport class GitHubTracker implements IssueTracker {\n  readonly name = 'github';\n  private client: Octokit;\n  private owner: string;\n  private repo: string;\n\n  constructor(token: string, repoFullName: string) {\n    this.client = new Octokit({ auth: token });\n    const [owner, repo] = repoFullName.split('/');\n    this.owner = owner;\n    this.repo = repo;\n  }\n\n  async listIssues(filters?: IssueFilters): Promise\u003cIssue[]\u003e {\n    const state = filters?.state === 'closed' ? 'closed' :\n                  filters?.state === 'all' ? 'all' : 'open';\n\n    const { data } = await this.client.issues.listForRepo({\n      owner: this.owner,\n      repo: this.repo,\n      state,\n      per_page: filters?.limit || 50,\n    });\n\n    // Filter out pull requests (GitHub includes them in issues)\n    return data\n      .filter((i) =\u003e !i.pull_request)\n      .map((i) =\u003e this.mapIssue(i));\n  }\n\n  async getIssue(id: string): Promise\u003cIssue\u003e {\n    // Extract number from #42 or just 42\n    const issueNumber = parseInt(id.replace('#', ''));\n\n    const { data } = await this.client.issues.get({\n      owner: this.owner,\n      repo: this.repo,\n      issue_number: issueNumber,\n    });\n\n    return this.mapIssue(data);\n  }\n\n  async createIssue(newIssue: NewIssue): Promise\u003cIssue\u003e {\n    const { data } = await this.client.issues.create({\n      owner: this.owner,\n      repo: this.repo,\n      title: newIssue.title,\n      body: newIssue.description,\n      labels: newIssue.labels,\n    });\n\n    return this.mapIssue(data);\n  }\n\n  async updateIssue(id: string, update: IssueUpdate): Promise\u003cIssue\u003e {\n    const issueNumber = parseInt(id.replace('#', ''));\n\n    const { data } = await this.client.issues.update({\n      owner: this.owner,\n      repo: this.repo,\n      issue_number: issueNumber,\n      title: update.title,\n      body: update.description,\n      state: update.state === 'closed' ? 'closed' : 'open',\n      labels: update.labels,\n    });\n\n    return this.mapIssue(data);\n  }\n\n  async getComments(issueId: string): Promise\u003cComment[]\u003e {\n    const issueNumber = parseInt(issueId.replace('#', ''));\n\n    const { data } = await this.client.issues.listComments({\n      owner: this.owner,\n      repo: this.repo,\n      issue_number: issueNumber,\n    });\n\n    return data.map((c) =\u003e ({\n      id: String(c.id),\n      body: c.body || '',\n      author: c.user?.login || 'Unknown',\n      createdAt: new Date(c.created_at),\n    }));\n  }\n\n  async addComment(issueId: string, body: string): Promise\u003cComment\u003e {\n    const issueNumber = parseInt(issueId.replace('#', ''));\n\n    const { data } = await this.client.issues.createComment({\n      owner: this.owner,\n      repo: this.repo,\n      issue_number: issueNumber,\n      body,\n    });\n\n    return {\n      id: String(data.id),\n      body: data.body || '',\n      author: data.user?.login || 'Panopticon',\n      createdAt: new Date(data.created_at),\n    };\n  }\n\n  async transitionIssue(id: string, state: Issue['state']): Promise\u003cvoid\u003e {\n    const issueNumber = parseInt(id.replace('#', ''));\n\n    await this.client.issues.update({\n      owner: this.owner,\n      repo: this.repo,\n      issue_number: issueNumber,\n      state: state === 'closed' ? 'closed' : 'open',\n    });\n  }\n\n  async linkPR(issueId: string, prUrl: string): Promise\u003cvoid\u003e {\n    await this.addComment(issueId, `PR opened: ${prUrl}`);\n  }\n\n  private mapIssue(issue: any): Issue {\n    return {\n      id: String(issue.number),\n      ref: `#${issue.number}`,\n      title: issue.title,\n      description: issue.body || '',\n      state: issue.state === 'closed' ? 'closed' : 'open',\n      labels: issue.labels?.map((l: any) =\u003e l.name) || [],\n      assignee: issue.assignee?.login,\n      url: issue.html_url,\n      tracker: 'github',\n      createdAt: new Date(issue.created_at),\n      updatedAt: new Date(issue.updated_at),\n    };\n  }\n}\n```\n\n---\n\n## Step 5: Create Tracker Factory (src/lib/trackers/factory.ts)\n\n```typescript\nimport { IssueTracker } from './interface.js';\nimport { LinearTracker } from './linear.js';\nimport { GitHubTracker } from './github.js';\nimport { loadConfig } from '../config.js';\n\nexport function createTracker(name: string, projectConfig?: any): IssueTracker {\n  switch (name) {\n    case 'linear': {\n      const apiKey = process.env.LINEAR_API_KEY;\n      if (!apiKey) throw new Error('LINEAR_API_KEY not set');\n      const team = projectConfig?.trackers?.linear?.team || 'MIN';\n      return new LinearTracker(apiKey, team);\n    }\n\n    case 'github': {\n      const token = process.env.GITHUB_TOKEN;\n      if (!token) throw new Error('GITHUB_TOKEN not set');\n      const repo = projectConfig?.trackers?.github?.repo;\n      if (!repo) throw new Error('GitHub repo not configured');\n      return new GitHubTracker(token, repo);\n    }\n\n    default:\n      throw new Error(`Unknown tracker: ${name}`);\n  }\n}\n\nexport function getPrimaryTracker(projectConfig?: any): IssueTracker {\n  const primary = projectConfig?.trackers?.primary || 'linear';\n  return createTracker(primary, projectConfig);\n}\n\nexport function getSecondaryTracker(projectConfig?: any): IssueTracker | null {\n  const secondary = projectConfig?.trackers?.secondary;\n  if (!secondary) return null;\n  return createTracker(secondary, projectConfig);\n}\n```\n\n---\n\n## Step 6: Create Triage Command (src/cli/commands/work/triage.ts)\n\n```typescript\nimport chalk from 'chalk';\nimport ora from 'ora';\nimport { getPrimaryTracker, getSecondaryTracker } from '../../lib/trackers/factory.js';\n\ninterface TriageOptions {\n  create?: boolean;\n  dismiss?: string;\n}\n\nexport async function triageCommand(id?: string, options?: TriageOptions): Promise\u003cvoid\u003e {\n  const secondary = getSecondaryTracker();\n\n  if (!secondary) {\n    console.log(chalk.yellow('No secondary tracker configured.'));\n    console.log(chalk.dim('Add [trackers.secondary] to .panopticon/project.toml'));\n    return;\n  }\n\n  // If no ID, list untriaged issues\n  if (!id) {\n    const spinner = ora('Fetching untriaged issues...').start();\n\n    try {\n      const issues = await secondary.listIssues({ state: 'open' });\n      spinner.succeed(`Found ${issues.length} open ${secondary.name} issues`);\n\n      console.log('');\n      console.log(chalk.bold(`${secondary.name} Issues Needing Triage:\\n`));\n\n      for (const issue of issues) {\n        console.log(`${chalk.cyan(issue.ref)}  ${issue.title}`);\n        if (issue.labels.length \u003e 0) {\n          console.log(`  Labels: ${issue.labels.join(', ')}`);\n        }\n      }\n\n      console.log('');\n      console.log(chalk.dim('Use \"pan work triage \u003cid\u003e --create\" to create primary issue'));\n      console.log(chalk.dim('Use \"pan work triage \u003cid\u003e --dismiss \u003creason\u003e\" to dismiss'));\n\n    } catch (error: any) {\n      spinner.fail(error.message);\n    }\n    return;\n  }\n\n  // Create primary issue from secondary\n  if (options?.create) {\n    const spinner = ora('Creating primary issue...').start();\n\n    try {\n      const secondaryIssue = await secondary.getIssue(id);\n      const primary = getPrimaryTracker();\n\n      const primaryIssue = await primary.createIssue({\n        title: `[${secondary.name}${secondaryIssue.ref}] ${secondaryIssue.title}`,\n        description: `From ${secondary.name}: ${secondaryIssue.url}\\n\\n${secondaryIssue.description}`,\n      });\n\n      // Add comment to secondary linking to primary\n      await secondary.addComment(id, `Tracked in ${primary.name}: ${primaryIssue.url}`);\n\n      spinner.succeed(`Created ${primaryIssue.ref}`);\n      console.log(`  ${secondary.name} ${id} -\u003e ${primary.name} ${primaryIssue.ref}`);\n\n    } catch (error: any) {\n      spinner.fail(error.message);\n    }\n    return;\n  }\n\n  // Dismiss from triage\n  if (options?.dismiss) {\n    const spinner = ora('Dismissing issue...').start();\n\n    try {\n      await secondary.addComment(id, `Triaged: ${options.dismiss}\\n\\nNo primary issue created.`);\n      spinner.succeed(`Dismissed ${id}`);\n\n    } catch (error: any) {\n      spinner.fail(error.message);\n    }\n    return;\n  }\n\n  // Show single issue details\n  try {\n    const issue = await secondary.getIssue(id);\n    console.log('');\n    console.log(chalk.bold(issue.title));\n    console.log(`${secondary.name} ${chalk.cyan(issue.ref)}`);\n    console.log(`URL: ${issue.url}`);\n    console.log(`State: ${issue.state}`);\n    console.log(`Labels: ${issue.labels.join(', ') || 'none'}`);\n    console.log('');\n    console.log(issue.description || '(no description)');\n\n  } catch (error: any) {\n    console.error(chalk.red(error.message));\n  }\n}\n```\n\n---\n\n## Step 7: Update Work List Command\n\nUpdate src/cli/commands/work/list.ts:\n\n```typescript\nimport chalk from 'chalk';\nimport ora from 'ora';\nimport { getPrimaryTracker, getSecondaryTracker } from '../../lib/trackers/factory.js';\n\ninterface ListOptions {\n  all?: boolean;\n  tracker?: string;\n}\n\nexport async function listCommand(options: ListOptions): Promise\u003cvoid\u003e {\n  const spinner = ora('Fetching issues...').start();\n\n  try {\n    const primary = getPrimaryTracker();\n    const secondary = getSecondaryTracker();\n\n    // Determine which trackers to query\n    const trackers: Array\u003c{ tracker: any; label: string }\u003e = [];\n\n    if (options.tracker) {\n      const t = options.tracker === 'primary' ? primary :\n                options.tracker === 'secondary' ? secondary :\n                getPrimaryTracker(); // TODO: support arbitrary tracker names\n      trackers.push({ tracker: t, label: options.tracker });\n    } else if (options.all \u0026\u0026 secondary) {\n      trackers.push({ tracker: primary, label: 'primary' });\n      trackers.push({ tracker: secondary, label: 'secondary' });\n    } else {\n      trackers.push({ tracker: primary, label: 'primary' });\n    }\n\n    spinner.succeed('Issues loaded');\n    console.log('');\n\n    for (const { tracker, label } of trackers) {\n      const issues = await tracker.listIssues({ state: 'open' });\n\n      console.log(chalk.bold(`${tracker.name} (${label}) - ${issues.length} open\\n`));\n\n      for (const issue of issues) {\n        const state = issue.state === 'in_progress' ? chalk.yellow('WIP') :\n                      issue.state === 'closed' ? chalk.green('Done') :\n                      chalk.blue('Open');\n\n        console.log(`${chalk.cyan(issue.ref.padEnd(10))} ${state.padEnd(6)} ${issue.title}`);\n      }\n\n      console.log('');\n    }\n\n  } catch (error: any) {\n    spinner.fail(error.message);\n  }\n}\n```\n\n---\n\n## Verification Checklist\n\n```bash\n# 1. Build\nnpm run build\n# Expected: No errors\n\n# 2. Test Linear listing\nLINEAR_API_KEY=your-key node dist/cli/index.js work list\n# Expected: Shows Linear issues\n\n# 3. Test GitHub listing (if configured)\nGITHUB_TOKEN=your-token node dist/cli/index.js work list --tracker github\n# Expected: Shows GitHub issues\n\n# 4. Test triage listing\nnode dist/cli/index.js work triage\n# Expected: Shows secondary tracker issues\n\n# 5. Test issue creation from triage\nnode dist/cli/index.js work triage \"#42\" --create\n# Expected: Creates Linear issue, links to GitHub\n\n# 6. Test dismiss\nnode dist/cli/index.js work triage \"#43\" --dismiss \"Duplicate of #40\"\n# Expected: Adds comment to GitHub issue\n```\n\n---\n\n## Common Gotchas\n\n1. **LINEAR_API_KEY not set** - Export it or add to .env\n2. **GITHUB_TOKEN needs repo scope** - Create token with repo access\n3. **GitHub includes PRs in issues** - Filter them out\n4. **Linear team key vs ID** - Use the short key (MIN not UUID)\n5. **Rate limiting** - Both APIs have limits\n\n---\n\n## Dependencies on Other Phases\n\n- **Depends on**: Phase 1 (config), Phase 3 (work commands)\n- **Blocks**: Phase 4 (dashboard needs issues API)\n\n---\n\n## Project Config Example\n\n```toml\n# .panopticon/project.toml\n\n[trackers]\nprimary = \"linear\"\nsecondary = \"github\"\n\n[trackers.linear]\nteam = \"MIN\"\n\n[trackers.github]\nrepo = \"eltmon/panopticon-cli\"\nauto_sync = false\n```","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-17T17:57:26.444748274-08:00","created_by":"eltmon","updated_at":"2026-01-17T18:33:06.3186799-08:00","labels":["integration","linear"],"dependencies":[{"issue_id":"panopticon-6ax.8","depends_on_id":"panopticon-6ax","type":"parent-child","created_at":"2026-01-17T17:57:26.457088028-08:00","created_by":"eltmon"}]}
{"id":"panopticon-6ax.9","title":"Phase 9: Testing \u0026 Documentation","description":"Add comprehensive tests, examples, and documentation.\n\n## Prerequisites\n- All core phases (1-8) complete\n- Package compiles with `npm run build`\n\n## Acceptance Criteria (Testable)\n- [ ] `npm test` runs and all tests pass\n- [ ] `npm run test:coverage` shows \u003e80% coverage on core modules\n- [ ] README.md has complete command reference\n- [ ] examples/ directory has working sample configs\n- [ ] API docs generated in docs/api/\n\n---\n\n## Step 1: Install Test Dependencies\n\n```bash\ncd /home/eltmon/projects/panopticon\nnpm install -D vitest @vitest/coverage-v8 memfs\n```\n\n---\n\n## Step 2: Configure Vitest (vitest.config.ts)\n\n```typescript\nimport { defineConfig } from 'vitest/config';\n\nexport default defineConfig({\n  test: {\n    globals: true,\n    environment: 'node',\n    coverage: {\n      provider: 'v8',\n      reporter: ['text', 'html', 'lcov'],\n      exclude: [\n        'node_modules',\n        'dist',\n        '**/*.d.ts',\n        '**/*.test.ts',\n        'src/dashboard/**', // Dashboard tested separately\n      ],\n    },\n  },\n});\n```\n\n---\n\n## Step 3: Update package.json Scripts\n\n```json\n{\n  \"scripts\": {\n    \"test\": \"vitest run\",\n    \"test:watch\": \"vitest\",\n    \"test:coverage\": \"vitest run --coverage\"\n  }\n}\n```\n\n---\n\n## Step 4: Create Test for Config Module (src/lib/config.test.ts)\n\n```typescript\nimport { describe, it, expect, beforeEach, afterEach } from 'vitest';\nimport { vol } from 'memfs';\nimport { writeDefaultConfig, loadConfig, DEFAULT_CONFIG } from './config';\n\n// Mock fs\nvi.mock('fs', async () =\u003e {\n  const memfs = await import('memfs');\n  return memfs.fs;\n});\n\ndescribe('config', () =\u003e {\n  beforeEach(() =\u003e {\n    vol.reset();\n    vol.mkdirSync('/home/test/.panopticon', { recursive: true });\n  });\n\n  afterEach(() =\u003e {\n    vol.reset();\n  });\n\n  describe('writeDefaultConfig', () =\u003e {\n    it('creates config.toml with default values', () =\u003e {\n      // Mock the CONFIG_FILE path\n      vi.stubEnv('HOME', '/home/test');\n\n      writeDefaultConfig();\n\n      const content = vol.readFileSync('/home/test/.panopticon/config.toml', 'utf8');\n      expect(content).toContain('[panopticon]');\n      expect(content).toContain('version = \"1.0.0\"');\n    });\n  });\n\n  describe('loadConfig', () =\u003e {\n    it('throws when config does not exist', () =\u003e {\n      expect(() =\u003e loadConfig()).toThrow('Config not found');\n    });\n\n    it('returns parsed config when file exists', () =\u003e {\n      vol.writeFileSync(\n        '/home/test/.panopticon/config.toml',\n        '[panopticon]\\nversion = \"1.0.0\"\\ndefault_runtime = \"claude\"'\n      );\n\n      const config = loadConfig();\n      expect(config.panopticon.version).toBe('1.0.0');\n    });\n  });\n});\n```\n\n---\n\n## Step 5: Create Test for Paths Module (src/lib/paths.test.ts)\n\n```typescript\nimport { describe, it, expect } from 'vitest';\nimport { detectPlatform, SYNC_TARGETS } from './paths';\n\ndescribe('paths', () =\u003e {\n  describe('detectPlatform', () =\u003e {\n    it('returns a valid platform', () =\u003e {\n      const platform = detectPlatform();\n      expect(['macos', 'linux', 'wsl2', 'windows']).toContain(platform);\n    });\n  });\n\n  describe('SYNC_TARGETS', () =\u003e {\n    it('contains expected targets', () =\u003e {\n      expect(SYNC_TARGETS['claude-skills']).toContain('.claude/skills');\n      expect(SYNC_TARGETS['codex-skills']).toContain('.codex/skills');\n    });\n  });\n});\n```\n\n---\n\n## Step 6: Create Test for Tmux Module (src/lib/tmux.test.ts)\n\n```typescript\nimport { describe, it, expect, vi } from 'vitest';\nimport { execSync } from 'child_process';\n\nvi.mock('child_process', () =\u003e ({\n  execSync: vi.fn(),\n}));\n\nimport { listSessions, sessionExists, sendKeys } from './tmux';\n\ndescribe('tmux', () =\u003e {\n  describe('listSessions', () =\u003e {\n    it('returns empty array when no sessions', () =\u003e {\n      vi.mocked(execSync).mockImplementation(() =\u003e {\n        throw new Error('no server running');\n      });\n\n      expect(listSessions()).toEqual([]);\n    });\n\n    it('parses session list correctly', () =\u003e {\n      vi.mocked(execSync).mockReturnValue(\n        'agent-min-123|1704067200|0|1\\nagent-min-456|1704067300|1|2\\n'\n      );\n\n      const sessions = listSessions();\n      expect(sessions).toHaveLength(2);\n      expect(sessions[0].name).toBe('agent-min-123');\n      expect(sessions[1].attached).toBe(true);\n    });\n  });\n\n  describe('sessionExists', () =\u003e {\n    it('returns true when session exists', () =\u003e {\n      vi.mocked(execSync).mockReturnValue('');\n      expect(sessionExists('agent-min-123')).toBe(true);\n    });\n\n    it('returns false when session does not exist', () =\u003e {\n      vi.mocked(execSync).mockImplementation(() =\u003e {\n        throw new Error('session not found');\n      });\n      expect(sessionExists('agent-min-123')).toBe(false);\n    });\n  });\n\n  describe('sendKeys', () =\u003e {\n    it('sends keys followed by Enter', () =\u003e {\n      vi.mocked(execSync).mockReturnValue('');\n\n      sendKeys('agent-min-123', 'hello world');\n\n      expect(execSync).toHaveBeenCalledTimes(2);\n      expect(execSync).toHaveBeenCalledWith(\n        expect.stringContaining('send-keys -t agent-min-123')\n      );\n    });\n  });\n});\n```\n\n---\n\n## Step 7: Create Integration Test (tests/integration/cli.test.ts)\n\n```typescript\nimport { describe, it, expect, beforeAll, afterAll } from 'vitest';\nimport { execSync } from 'child_process';\nimport { existsSync, rmSync, mkdirSync } from 'fs';\nimport { join } from 'path';\n\nconst TEST_HOME = '/tmp/panopticon-test';\nconst CLI = join(__dirname, '../../dist/cli/index.js');\n\ndescribe('CLI Integration', () =\u003e {\n  beforeAll(() =\u003e {\n    // Build first\n    execSync('npm run build', { cwd: join(__dirname, '../..') });\n\n    // Clean test directory\n    if (existsSync(TEST_HOME)) {\n      rmSync(TEST_HOME, { recursive: true });\n    }\n    mkdirSync(TEST_HOME, { recursive: true });\n  });\n\n  afterAll(() =\u003e {\n    if (existsSync(TEST_HOME)) {\n      rmSync(TEST_HOME, { recursive: true });\n    }\n  });\n\n  describe('pan --version', () =\u003e {\n    it('prints version number', () =\u003e {\n      const output = execSync(`node ${CLI} --version`, { encoding: 'utf8' });\n      expect(output.trim()).toMatch(/^\\d+\\.\\d+\\.\\d+$/);\n    });\n  });\n\n  describe('pan --help', () =\u003e {\n    it('shows help with all commands', () =\u003e {\n      const output = execSync(`node ${CLI} --help`, { encoding: 'utf8' });\n      expect(output).toContain('init');\n      expect(output).toContain('sync');\n      expect(output).toContain('work');\n    });\n  });\n\n  describe('pan init', () =\u003e {\n    it('creates .panopticon directory structure', () =\u003e {\n      const env = { ...process.env, HOME: TEST_HOME };\n      execSync(`node ${CLI} init`, { env, encoding: 'utf8' });\n\n      expect(existsSync(join(TEST_HOME, '.panopticon'))).toBe(true);\n      expect(existsSync(join(TEST_HOME, '.panopticon/config.toml'))).toBe(true);\n      expect(existsSync(join(TEST_HOME, '.panopticon/skills'))).toBe(true);\n    });\n  });\n\n  describe('pan skills', () =\u003e {\n    it('lists available skills', () =\u003e {\n      const env = { ...process.env, HOME: TEST_HOME };\n      const output = execSync(`node ${CLI} skills`, { env, encoding: 'utf8' });\n      expect(output).toContain('Panopticon Skills');\n    });\n  });\n});\n```\n\n---\n\n## Step 8: Create README.md\n\n```markdown\n# Panopticon\n\n[![npm version](https://img.shields.io/npm/v/panopticon-cli.svg)](https://www.npmjs.com/package/panopticon-cli)\n[![CI](https://github.com/eltmon/panopticon-cli/actions/workflows/ci.yml/badge.svg)](https://github.com/eltmon/panopticon-cli/actions)\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n\nMulti-agent orchestration for Claude Code.\n\n## Quick Start\n\n\\`\\`\\`bash\n# Install\nnpm install -g panopticon-cli\n\n# Initialize\npan install\npan init\npan sync\n\n# Start working\npan up                    # Start dashboard\npan work issue MIN-123    # Spawn agent for issue\npan work status           # Check running agents\n\\`\\`\\`\n\n## Features\n\n- **Multi-agent orchestration** - Spawn and manage multiple Claude Code agents\n- **Cross-platform skills** - Works with Claude Code, Codex, Cursor, Gemini CLI\n- **Real-time dashboard** - Monitor agents, view output, send messages\n- **Issue tracker integration** - Linear and GitHub Issues support\n- **Workspace isolation** - Docker containers per feature branch\n- **Health monitoring** - Detect and recover stuck agents\n\n## Commands\n\n### Panopticon Management\n\n| Command | Description |\n|---------|-------------|\n| `pan init` | Initialize ~/.panopticon/ |\n| `pan install` | Install prerequisites (Docker, mkcert, etc.) |\n| `pan sync` | Sync skills/commands to AI tools |\n| `pan up` | Start the dashboard |\n| `pan down` | Stop dashboard and agents |\n| `pan skills` | List available skills |\n\n### Work Management\n\n| Command | Description |\n|---------|-------------|\n| `pan work issue \u003cid\u003e` | Spawn agent for issue |\n| `pan work status` | Show running agents |\n| `pan work tell \u003cid\u003e \u003cmsg\u003e` | Send message to agent |\n| `pan work kill \u003cid\u003e` | Kill an agent |\n| `pan work approve \u003cid\u003e` | Approve and merge work |\n| `pan work list` | List issues from tracker |\n| `pan work triage` | Triage secondary tracker |\n\n### Workspace Management\n\n| Command | Description |\n|---------|-------------|\n| `pan workspace create \u003cid\u003e` | Create workspace for issue |\n| `pan workspace list` | List all workspaces |\n| `pan workspace destroy \u003cid\u003e` | Destroy workspace |\n\n## Configuration\n\n### Global Config (~/.panopticon/config.toml)\n\n\\`\\`\\`toml\n[panopticon]\nversion = \"1.0.0\"\ndefault_runtime = \"claude\"\n\n[dashboard]\nport = 3001\napi_port = 3002\n\n[health]\nping_timeout = \"30s\"\nconsecutive_failures = 3\n\\`\\`\\`\n\n### Project Config (.panopticon/project.toml)\n\n\\`\\`\\`toml\n[project]\nname = \"my-project\"\n\n[trackers]\nprimary = \"linear\"\nsecondary = \"github\"\n\n[trackers.linear]\nteam = \"MIN\"\n\n[trackers.github]\nrepo = \"owner/repo\"\n\\`\\`\\`\n\n## Requirements\n\n- Node.js 18+\n- Docker and Docker Compose\n- Git 2.5+ (for worktrees)\n- tmux\n\n## Documentation\n\nSee [docs/](./docs/) for detailed documentation.\n\n## License\n\nMIT\n```\n\n---\n\n## Step 9: Create Examples Directory\n\n```bash\nmkdir -p examples/{basic,monorepo,custom-skills}\n```\n\n### examples/basic/README.md\n\n```markdown\n# Basic Panopticon Setup\n\nMinimal configuration for a single-repo project.\n\n## Setup\n\n1. Copy `.panopticon/` to your project root\n2. Set `LINEAR_API_KEY` environment variable\n3. Run `pan sync`\n\n## Files\n\n- `.panopticon/project.toml` - Project configuration\n```\n\n### examples/basic/.panopticon/project.toml\n\n```toml\n[project]\nname = \"basic-example\"\ndescription = \"Basic single-repo setup\"\n\n[trackers]\nprimary = \"linear\"\n\n[trackers.linear]\nteam = \"EXAMPLE\"\n```\n\n### examples/monorepo/README.md\n\n```markdown\n# Monorepo Setup\n\nConfiguration for a monorepo with multiple components.\n\n## Files\n\n- `.panopticon/project.toml` - Project configuration\n- `.panopticon/claude-md/sections/` - Custom CLAUDE.md sections\n```\n\n### examples/custom-skills/README.md\n\n```markdown\n# Custom Skills\n\nHow to create project-specific skills that merge with Panopticon defaults.\n\n## Creating a Custom Skill\n\n1. Create `.claude/skills/my-skill/SKILL.md`\n2. Add YAML frontmatter\n3. Run `pan sync`\n\nCustom skills take precedence over Panopticon skills with the same name.\n```\n\n---\n\n## Step 10: Create CONTRIBUTING.md\n\n```markdown\n# Contributing to Panopticon\n\n## Development Setup\n\n\\`\\`\\`bash\ngit clone https://github.com/eltmon/panopticon-cli.git\ncd panopticon-cli\nnpm install\nnpm run build\nnpm link  # For local testing\n\\`\\`\\`\n\n## Running Tests\n\n\\`\\`\\`bash\nnpm test              # Run tests\nnpm run test:watch    # Watch mode\nnpm run test:coverage # Coverage report\n\\`\\`\\`\n\n## Code Style\n\n- TypeScript strict mode\n- ESLint with Airbnb config\n- Prettier for formatting\n\n## Pull Request Process\n\n1. Fork the repo\n2. Create feature branch\n3. Make changes\n4. Run tests\n5. Submit PR\n\n## Adding a New Skill\n\n1. Create `~/.panopticon/skills/my-skill/SKILL.md`\n2. Add YAML frontmatter with name and description\n3. Run `pan sync` to distribute\n4. Test in Claude Code\n\n## Adding a New Tracker\n\n1. Implement `IssueTracker` interface\n2. Add to `src/lib/trackers/`\n3. Register in factory\n4. Add tests\n```\n\n---\n\n## Step 11: Create CHANGELOG.md\n\n```markdown\n# Changelog\n\nAll notable changes to this project will be documented in this file.\n\nThe format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/).\n\n## [Unreleased]\n\n## [0.1.0] - 2026-01-17\n\n### Added\n- Initial release\n- Core CLI commands (init, sync, install)\n- Work commands (issue, status, tell, kill, approve)\n- Workspace management\n- Linear and GitHub Issues integration\n- Dashboard with Kanban and agent monitoring\n- 14 built-in skills\n- Health monitoring and stuck detection\n\n[Unreleased]: https://github.com/eltmon/panopticon-cli/compare/v0.1.0...HEAD\n[0.1.0]: https://github.com/eltmon/panopticon-cli/releases/tag/v0.1.0\n```\n\n---\n\n## Verification Checklist\n\n```bash\n# 1. Run unit tests\nnpm test\n# Expected: All tests pass\n\n# 2. Check coverage\nnpm run test:coverage\n# Expected: \u003e80% on core modules\n\n# 3. Verify examples exist\nls examples/\n# Expected: basic/, monorepo/, custom-skills/\n\n# 4. Verify docs\ncat README.md\n# Expected: Complete command reference\n\n# 5. Build docs (if using typedoc)\nnpm run docs\n# Expected: Generated API docs in docs/api/\n```\n\n---\n\n## Common Gotchas\n\n1. **memfs import** - Use dynamic import for mocking\n2. **vi.mock path** - Must be relative or absolute\n3. **Coverage excludes** - Add test files and generated code\n4. **Integration tests need build** - Run `npm run build` first\n5. **HOME override** - Use env override in tests\n\n---\n\n## Dependencies on Other Phases\n\n- **Depends on**: All phases 1-8 (tests cover all functionality)\n- **Blocks**: Phase 7 (npm publish runs tests)","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-17T17:57:34.45306328-08:00","created_by":"eltmon","updated_at":"2026-01-17T18:34:30.476458513-08:00","labels":["docs","testing"],"dependencies":[{"issue_id":"panopticon-6ax.9","depends_on_id":"panopticon-6ax","type":"parent-child","created_at":"2026-01-17T17:57:34.467313462-08:00","created_by":"eltmon"}]}
