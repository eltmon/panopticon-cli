import express from 'express';
import cors from 'cors';
import http from 'http';
import { WebSocketServer, WebSocket } from 'ws';
import * as pty from '@homebridge/node-pty-prebuilt-multiarch';
import { exec, spawn } from 'child_process';
import { promisify } from 'util';
import { readFileSync, existsSync, readdirSync, appendFileSync, writeFileSync, renameSync, unlinkSync, statSync, mkdirSync, rmSync, symlinkSync, chmodSync } from 'fs';
import { readFile, readdir } from 'fs/promises';
import { join, dirname } from 'path';
import { fileURLToPath } from 'url';
import { homedir } from 'os';
import { getCloisterService } from '../../lib/cloister/service.js';

const execAsync = promisify(exec);
import { loadCloisterConfig, saveCloisterConfig, shouldAutoStart } from '../../lib/cloister/config.js';
import { spawnMergeAgentForBranches } from '../../lib/cloister/merge-agent.js';
import { checkAgentHealthAsync, determineHealthStatusAsync } from '../lib/health-filtering.js';
import { performHandoff } from '../../lib/cloister/handoff.js';
import { readHandoffEvents, readIssueHandoffEvents, readAgentHandoffEvents, getHandoffStats } from '../../lib/cloister/handoff-logger.js';
import { readSpecialistHandoffs, getSpecialistHandoffStats } from '../../lib/cloister/specialist-handoff-logger.js';
import { checkAllTriggers } from '../../lib/cloister/triggers.js';
import { getAgentState, getAgentRuntimeState, saveAgentRuntimeState, getActivity, appendActivity, saveSessionId, getSessionId, resumeAgent } from '../../lib/agents.js';
import { cleanupOldAgents } from '../../lib/cleanup.js';
import { getAgentHealth } from '../../lib/cloister/health.js';
import { getRuntimeForAgent } from '../../lib/runtimes/index.js';
import { resolveProjectFromIssue, listProjects, hasProjects, ProjectConfig, findProjectByTeam, extractTeamPrefix } from '../../lib/projects.js';
import { calculateCost, getPricing, TokenUsage } from '../../lib/cost.js';
import { normalizeModelName, getActiveSessionModel } from '../../lib/cost-parsers/jsonl-parser.js';
import { startConvoy, stopConvoy, getConvoyStatus, listConvoys, type ConvoyContext } from '../../lib/convoy.js';
import type { Issue } from '../frontend/src/types.js';

/**
 * Get a Date object representing 24 hours ago from now.
 * Used for filtering recently completed issues.
 */
function getOneDayAgo(): Date {
  const date = new Date();
  date.setDate(date.getDate() - 1);
  return date;
}

import type { Issue } from '../frontend/src/types.js';

// Ensure tmux server is running (starts one if not)
async function ensureTmuxRunning(): Promise<void> {
  try {
    await execAsync('tmux list-sessions 2>/dev/null', { encoding: 'utf-8' });
  } catch (e) {
    // Tmux server not running, start it with a dummy session
    try {
      await execAsync('tmux new-session -d -s panopticon-init', { encoding: 'utf-8' });
      console.log('Started tmux server');
    } catch (startErr) {
      console.error('Failed to start tmux server:', startErr);
    }
  }
}

// Activity log for tracking pan command output
const ACTIVITY_LOG = '/tmp/panopticon-activity.log';

interface ActivityEntry {
  id: string;
  timestamp: string;
  command: string;
  status: 'running' | 'completed' | 'failed';
  output: string[];
}

// In-memory activity store (last 50 entries)
const activities: ActivityEntry[] = [];
const MAX_ACTIVITIES = 50;

// Cache for agents list to avoid repeated subprocess calls
let agentsCache: { data: any[] | null; timestamp: number } = {
  data: null,
  timestamp: 0,
};
const AGENTS_CACHE_TTL_MS = 2000; // 2 seconds

function logActivity(entry: ActivityEntry) {
  activities.unshift(entry);
  if (activities.length > MAX_ACTIVITIES) {
    activities.pop();
  }
}

function updateActivity(id: string, updates: Partial<ActivityEntry>) {
  const activity = activities.find(a => a.id === id);
  if (activity) {
    Object.assign(activity, updates);
  }
}

function appendActivityOutput(id: string, line: string) {
  const activity = activities.find(a => a.id === id);
  if (activity) {
    activity.output.push(line);
    // Keep only last 100 lines per activity
    if (activity.output.length > 100) {
      activity.output.shift();
    }
  }
}

// ============================================================================
// Pending Operations State - Persists across refreshes and server restarts
// ============================================================================

interface PendingOperation {
  type: 'approve' | 'close' | 'containerize' | 'start' | 'review' | 'merge';
  issueId: string;
  startedAt: string;
  status: 'pending' | 'running' | 'completed' | 'failed';
  error?: string;
}

// ============================================================================
// Review Status Tracking - Tracks review/test pipeline progress
// ============================================================================

interface ReviewStatus {
  issueId: string;
  reviewStatus: 'pending' | 'reviewing' | 'passed' | 'failed' | 'blocked';
  testStatus: 'pending' | 'testing' | 'passed' | 'failed' | 'skipped';
  mergeStatus?: 'pending' | 'merging' | 'merged' | 'failed';
  reviewNotes?: string;
  testNotes?: string;
  updatedAt: string;
  readyForMerge: boolean;
  autoRequeueCount?: number; // Circuit breaker: max 3 auto-requeues before human intervention required
}

const REVIEW_STATUS_FILE = join(homedir(), '.panopticon', 'review-status.json');

function loadReviewStatuses(): Record<string, ReviewStatus> {
  try {
    if (existsSync(REVIEW_STATUS_FILE)) {
      return JSON.parse(readFileSync(REVIEW_STATUS_FILE, 'utf-8'));
    }
  } catch (err) {
    console.error('Failed to load review statuses:', err);
  }
  return {};
}

function saveReviewStatuses(statuses: Record<string, ReviewStatus>): void {
  try {
    const dir = dirname(REVIEW_STATUS_FILE);
    if (!existsSync(dir)) {
      mkdirSync(dir, { recursive: true });
    }
    writeFileSync(REVIEW_STATUS_FILE, JSON.stringify(statuses, null, 2));
  } catch (err) {
    console.error('Failed to save review statuses:', err);
  }
}

function setReviewStatus(issueId: string, update: Partial<ReviewStatus>): ReviewStatus {
  const statuses = loadReviewStatuses();
  const existing = statuses[issueId] || {
    issueId,
    reviewStatus: 'pending',
    testStatus: 'pending',
    updatedAt: new Date().toISOString(),
    readyForMerge: false,
  };

  // Merge existing with update
  const merged = { ...existing, ...update };

  // readyForMerge logic:
  // - True if review passed AND test passed AND not yet merged
  // - False if explicitly set in update (e.g., after merge completion)
  // - False if merge is complete
  const readyForMerge = update.readyForMerge !== undefined
    ? update.readyForMerge
    : (merged.reviewStatus === 'passed' && merged.testStatus === 'passed' && merged.mergeStatus !== 'merged');

  const updated: ReviewStatus = {
    ...merged,
    issueId,
    updatedAt: new Date().toISOString(),
    readyForMerge,
  };

  statuses[issueId] = updated;
  saveReviewStatuses(statuses);
  return updated;
}

function getReviewStatus(issueId: string): ReviewStatus | null {
  const statuses = loadReviewStatuses();
  return statuses[issueId] || null;
}

function clearReviewStatus(issueId: string): void {
  const statuses = loadReviewStatuses();
  delete statuses[issueId];
  saveReviewStatuses(statuses);
}

/**
 * Close an issue after successful merge
 * Handles both GitHub issues (PAN-*) and Linear issues
 */
async function closeIssueAfterMerge(issueId: string): Promise<void> {
  try {
    // Check if it's a GitHub issue (PAN-* prefix)
    if (issueId.toUpperCase().startsWith('PAN-')) {
      const issueNumber = issueId.replace(/^PAN-/i, '');
      console.log(`[merge] Closing GitHub issue #${issueNumber}...`);

      // Use gh CLI to close the issue
      await execAsync(`gh issue close ${issueNumber} --repo eltmon/panopticon-cli --comment "Merged to main"`, {
        encoding: 'utf-8',
      });
      console.log(`[merge] GitHub issue #${issueNumber} closed`);
    } else {
      // Linear issue - update to Done state via GraphQL API
      console.log(`[merge] Moving Linear issue ${issueId} to Done...`);

      const linearApiKey = process.env.LINEAR_API_KEY;
      if (!linearApiKey) {
        console.warn(`[merge] LINEAR_API_KEY not set, cannot auto-close Linear issue ${issueId}`);
        return;
      }

      // First, get the issue to find its team and the Done state
      const issueQuery = `query { issue(id: "${issueId}") { id team { id states { nodes { id name type } } } } }`;
      const issueRes = await fetch('https://api.linear.app/graphql', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': linearApiKey,
        },
        body: JSON.stringify({ query: issueQuery }),
      });

      if (!issueRes.ok) {
        throw new Error(`Linear API error: ${issueRes.status}`);
      }

      const issueData = await issueRes.json() as any;
      const states = issueData.data?.issue?.team?.states?.nodes || [];
      const doneState = states.find((s: any) => s.type === 'completed' || s.name === 'Done');

      if (!doneState) {
        console.warn(`[merge] Could not find Done state for Linear issue ${issueId}`);
        return;
      }

      // Update the issue to Done state
      const updateMutation = `mutation { issueUpdate(id: "${issueId}", input: { stateId: "${doneState.id}" }) { success } }`;
      const updateRes = await fetch('https://api.linear.app/graphql', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': linearApiKey,
        },
        body: JSON.stringify({ query: updateMutation }),
      });

      if (!updateRes.ok) {
        throw new Error(`Linear API update error: ${updateRes.status}`);
      }

      const updateData = await updateRes.json() as any;
      if (updateData.data?.issueUpdate?.success) {
        console.log(`[merge] Linear issue ${issueId} moved to Done`);
      } else {
        console.warn(`[merge] Linear update returned success=false for ${issueId}`);
      }
    }
  } catch (error: unknown) {
    // Log but don't fail the merge - closing is a nice-to-have
    const message = error instanceof Error ? error.message : String(error);
    console.error(`[merge] Failed to close issue ${issueId}:`, message);
  }
}

// ============================================================================
// AUTOMATIC COMPLETION DETECTION
// ============================================================================
// Monitors specialist output and automatically updates review status
// instead of relying on agents to call curl commands manually.

interface ActiveReview {
  issueId: string;
  startedAt: string;
  lastChecked: string;
  phase: 'review' | 'test' | 'merge';
}

const activeReviews: Map<string, ActiveReview> = new Map();

// ============================================================================
// PAN-80: Terminal Parsing Removed
// ============================================================================
// Specialists now report status explicitly via:
//   POST /api/specialists/:name/report-status
// This replaces unreliable terminal output parsing (detectSpecialistCompletion).
// ============================================================================

const PENDING_OPS_FILE = join(homedir(), '.panopticon', 'pending-operations.json');

function loadPendingOperations(): Record<string, PendingOperation> {
  try {
    if (existsSync(PENDING_OPS_FILE)) {
      const data = JSON.parse(readFileSync(PENDING_OPS_FILE, 'utf-8'));
      // Clean up stale operations (older than 10 minutes with running status)
      const now = Date.now();
      const tenMinutes = 10 * 60 * 1000;
      for (const key of Object.keys(data)) {
        const op = data[key];
        if (op.status === 'running' && now - new Date(op.startedAt).getTime() > tenMinutes) {
          op.status = 'failed';
          op.error = 'Operation timed out';
        }
      }
      return data;
    }
  } catch (err) {
    console.error('Failed to load pending operations:', err);
  }
  return {};
}

function savePendingOperations(ops: Record<string, PendingOperation>): void {
  try {
    const dir = dirname(PENDING_OPS_FILE);
    if (!existsSync(dir)) {
      mkdirSync(dir, { recursive: true });
    }
    writeFileSync(PENDING_OPS_FILE, JSON.stringify(ops, null, 2));
  } catch (err) {
    console.error('Failed to save pending operations:', err);
  }
}

function setPendingOperation(issueId: string, type: PendingOperation['type']): void {
  const ops = loadPendingOperations();
  ops[issueId] = {
    type,
    issueId,
    startedAt: new Date().toISOString(),
    status: 'running',
  };
  savePendingOperations(ops);
}

function completePendingOperation(issueId: string, error?: string): void {
  const ops = loadPendingOperations();
  if (ops[issueId]) {
    if (error) {
      ops[issueId].status = 'failed';
      ops[issueId].error = error;
    } else {
      // Remove successful operations after a short delay
      delete ops[issueId];
    }
    savePendingOperations(ops);
  }
}

function getPendingOperation(issueId: string): PendingOperation | null {
  const ops = loadPendingOperations();
  return ops[issueId] || null;
}

function clearPendingOperation(issueId: string): void {
  const ops = loadPendingOperations();
  delete ops[issueId];
  savePendingOperations(ops);
}

// Get the first registered project path from pan
function getDefaultProjectPath(): string {
  try {
    const projectsFile = join(homedir(), '.panopticon', 'projects.json');
    if (existsSync(projectsFile)) {
      const projects = JSON.parse(readFileSync(projectsFile, 'utf-8'));
      if (Array.isArray(projects) && projects.length > 0) {
        return projects[0].path;
      }
    }
  } catch {}
  return homedir();
}

// Spawn a pan command and track its output
function spawnPanCommand(args: string[], description: string, cwd?: string): string {
  const id = `${Date.now()}-${Math.random().toString(36).slice(2, 8)}`;
  const timestamp = new Date().toISOString();
  const command = `pan ${args.join(' ')}`;
  const workingDir = cwd || homedir();

  logActivity({
    id,
    timestamp,
    command,
    status: 'running',
    output: [`[${timestamp}] Starting: ${command}`, `[cwd] ${workingDir}`],
  });

  const child = spawn('pan', args, {
    cwd: workingDir,
    env: { ...process.env, FORCE_COLOR: '0' },
  });

  child.stdout?.on('data', (data) => {
    const lines = data.toString().split('\n').filter((l: string) => l.trim());
    lines.forEach((line: string) => appendActivityOutput(id, line));
  });

  child.stderr?.on('data', (data) => {
    const lines = data.toString().split('\n').filter((l: string) => l.trim());
    lines.forEach((line: string) => appendActivityOutput(id, `[stderr] ${line}`));
  });

  child.on('close', (code) => {
    const status = code === 0 ? 'completed' : 'failed';
    appendActivityOutput(id, `[${new Date().toISOString()}] Process exited with code ${code}`);
    updateActivity(id, { status });
  });

  child.on('error', (err) => {
    appendActivityOutput(id, `[error] ${err.message}`);
    updateActivity(id, { status: 'failed' });
  });

  return id;
}

const app = express();
const PORT = parseInt(process.env.PORT || '3011', 10);

app.use(cors());
app.use(express.json());

// Load Linear API key from ~/.panopticon.env or environment
function getLinearApiKey(): string | null {
  const envFile = join(homedir(), '.panopticon.env');
  if (existsSync(envFile)) {
    const content = readFileSync(envFile, 'utf-8');
    const match = content.match(/LINEAR_API_KEY=(.+)/);
    if (match) return match[1].trim();
  }
  return process.env.LINEAR_API_KEY || null;
}

// Rally configuration
interface RallyConfig {
  apiKey: string;
  server?: string;
  workspace?: string;
  project?: string;
}

function getRallyConfig(): RallyConfig | null {
  const envFile = join(homedir(), '.panopticon.env');
  if (!existsSync(envFile)) return null;

  const content = readFileSync(envFile, 'utf-8');

  // Look for RALLY_API_KEY
  const apiKeyMatch = content.match(/RALLY_API_KEY=(.+)/);
  if (!apiKeyMatch) return null;

  const apiKey = apiKeyMatch[1].trim();

  // Optional: RALLY_SERVER
  const serverMatch = content.match(/RALLY_SERVER=(.+)/);
  const server = serverMatch?.[1].trim();

  // Optional: RALLY_WORKSPACE
  const workspaceMatch = content.match(/RALLY_WORKSPACE=(.+)/);
  const workspace = workspaceMatch?.[1].trim();

  // Optional: RALLY_PROJECT
  const projectMatch = content.match(/RALLY_PROJECT=(.+)/);
  const project = projectMatch?.[1].trim();

  return { apiKey, server, workspace, project };
}

// GitHub configuration
interface GitHubConfig {
  token: string;
  repos: Array<{ owner: string; repo: string; prefix?: string }>;
}

function getGitHubConfig(): GitHubConfig | null {
  const envFile = join(homedir(), '.panopticon.env');
  if (!existsSync(envFile)) return null;

  const content = readFileSync(envFile, 'utf-8');

  // Look for GITHUB_TOKEN
  const tokenMatch = content.match(/GITHUB_TOKEN=(.+)/);
  if (!tokenMatch) return null;

  const token = tokenMatch[1].trim();

  // Look for GITHUB_REPOS (format: owner/repo,owner/repo:PREFIX)
  const reposMatch = content.match(/GITHUB_REPOS=(.+)/);
  if (!reposMatch) return null;

  const repos = reposMatch[1].trim().split(',').map(r => {
    const [repoPath, prefix] = r.trim().split(':');
    const [owner, repo] = repoPath.split('/');
    return { owner, repo, prefix };
  }).filter(r => r.owner && r.repo);

  if (repos.length === 0) return null;

  return { token, repos };
}

// Get GitHub local paths mapping
function getGitHubLocalPaths(): Record<string, string> {
  const envFile = join(homedir(), '.panopticon.env');
  if (!existsSync(envFile)) return {};

  const content = readFileSync(envFile, 'utf-8');
  const match = content.match(/GITHUB_LOCAL_PATHS=(.+)/);
  if (!match) return {};

  return Object.fromEntries(
    match[1].trim().split(',').filter(Boolean).map(p => {
      const [repo, path] = p.split('=');
      return [repo, path];
    })
  );
}

// ============================================================================
// AskUserQuestion Interception Helpers (PAN-20)
// ============================================================================

/**
 * Get workspace path from agent state file
 * Agent state is stored in ~/.panopticon/agents/<agent-id>/state.json
 */
function getAgentWorkspace(agentId: string): string | null {
  const stateFile = join(homedir(), '.panopticon', 'agents', agentId, 'state.json');
  if (!existsSync(stateFile)) return null;
  try {
    const state = JSON.parse(readFileSync(stateFile, 'utf-8'));
    return state.workspace || null;
  } catch {
    return null;
  }
}

/**
 * Transform workspace path to Claude project directory
 * /home/user/projects/panopticon/workspaces/feature-pan-1
 * -> ~/.claude/projects/-home-user-projects-panopticon-workspaces-feature-pan-1/
 */
function getClaudeProjectDir(workspacePath: string): string {
  // Remove leading slash and replace all slashes with dashes
  const dirName = workspacePath.replace(/^\//, '').replace(/\//g, '-');
  return join(homedir(), '.claude', 'projects', `-${dirName}`);
}

/**
 * Sessions index entry structure from Claude Code
 */
interface SessionIndexEntry {
  sessionId: string;
  fullPath: string;
  modified: string;
}

/**
 * Get the active (most recently modified) session JSONL path for a Claude project
 * Always uses actual file mtime since sessions-index.json can be stale
 */
function getActiveSessionPath(projectDir: string): string | null {
  if (!existsSync(projectDir)) return null;

  try {
    // Find all .jsonl files and sort by actual file modification time
    // This is more reliable than sessions-index.json which can be stale
    const files = readdirSync(projectDir)
      .filter(f => f.endsWith('.jsonl'))
      .map(f => ({
        name: f,
        path: join(projectDir, f),
        mtime: statSync(join(projectDir, f)).mtime.getTime()
      }))
      .sort((a, b) => b.mtime - a.mtime);

    return files.length > 0 ? files[0].path : null;
  } catch {
    return null;
  }
}

/**
 * Get the JSONL session path for an agent by traversing:
 * agent ID -> state.json -> workspace -> Claude project dir -> sessions-index.json -> JSONL
 */
function getAgentJsonlPath(agentId: string): string | null {
  const workspace = getAgentWorkspace(agentId);
  if (!workspace) return null;

  const projectDir = getClaudeProjectDir(workspace);
  return getActiveSessionPath(projectDir);
}

/**
 * AskUserQuestion option structure
 */
interface QuestionOption {
  label: string;
  description: string;
}

/**
 * Single question within an AskUserQuestion tool call
 */
interface Question {
  question: string;
  header: string;
  options: QuestionOption[];
  multiSelect: boolean;
}

/**
 * A pending (unanswered) AskUserQuestion from JSONL
 */
interface PendingQuestion {
  toolId: string;
  timestamp: string;
  questions: Question[];
}

/**
 * Scan a JSONL file for pending (unanswered) AskUserQuestion tool calls
 * A question is pending if there's a tool_use with name='AskUserQuestion'
 * but no corresponding tool_result with matching tool_use_id
 *
 * NOTE: Uses async file reading to avoid blocking the event loop on large JSONL files
 */
async function getPendingQuestions(jsonlPath: string): Promise<PendingQuestion[]> {
  if (!existsSync(jsonlPath)) return [];

  try {
    // Use async readFile to avoid blocking on large JSONL files
    const content = await readFile(jsonlPath, 'utf-8');
    const lines = content.split('\n').filter(line => line.trim());

    // Track tool calls and which ones have been answered
    const toolCalls = new Map<string, PendingQuestion>();
    const answeredIds = new Set<string>();

    for (const line of lines) {
      try {
        const entry = JSON.parse(line);
        const messageContent = entry.message?.content;
        if (!Array.isArray(messageContent)) continue;

        for (const item of messageContent) {
          // Track AskUserQuestion tool calls
          if (item.type === 'tool_use' && item.name === 'AskUserQuestion') {
            toolCalls.set(item.id, {
              toolId: item.id,
              timestamp: entry.timestamp || new Date().toISOString(),
              questions: item.input?.questions || []
            });
          }
          // Track answered questions (tool_result)
          if (item.type === 'tool_result' && item.tool_use_id) {
            answeredIds.add(item.tool_use_id);
          }
        }
      } catch {
        // Skip malformed JSON lines
      }
    }

    // Return only unanswered questions
    return Array.from(toolCalls.entries())
      .filter(([id]) => !answeredIds.has(id))
      .map(([, question]) => question);
  } catch {
    return [];
  }
}

/**
 * Get pending questions for an agent by ID
 */
async function getAgentPendingQuestions(agentId: string): Promise<PendingQuestion[]> {
  const jsonlPath = getAgentJsonlPath(agentId);
  if (!jsonlPath) return [];
  return getPendingQuestions(jsonlPath);
}

// Map GitHub issue state + labels to canonical state
function mapGitHubStateToCanonical(state: string, labels: string[]): string {
  // Handle both API lowercase and gh CLI uppercase
  const stateLower = state.toLowerCase();

  // Closed issues are always done (regardless of labels)
  if (stateLower === 'closed') {
    return 'done';
  }

  // For open issues, check labels for workflow state
  // Order matters: more progressed states take precedence
  const labelNames = labels.map(l => l.toLowerCase());

  // Most progressed states first
  // "done" label on OPEN issues = work complete, pending merge/closure â†’ in_review
  // (actual "done" status only for CLOSED issues, handled above)
  if (labelNames.some(l => l === 'done' || l.includes('completed'))) {
    return 'in_review';
  }
  if (labelNames.some(l => l.includes('in review') || l.includes('in-review') || l.includes('review') || l.includes('qa'))) {
    return 'in_review';
  }
  if (labelNames.some(l => l.includes('in progress') || l.includes('in-progress') || l.includes('wip'))) {
    return 'in_progress';
  }
  // Early workflow stages
  if (labelNames.some(l => l.includes('planning') || l.includes('discovery'))) {
    return 'planning';
  }
  if (labelNames.some(l => l === 'planned')) {
    return 'planned';
  }
  if (labelNames.some(l => l.includes('backlog') || l.includes('icebox'))) {
    return 'backlog';
  }
  if (labelNames.some(l => l.includes('todo') || l.includes('ready'))) {
    return 'todo';
  }

  // Default open issues to todo
  return 'todo';
}

// Fetch GitHub issues using gh CLI for better auth
async function fetchGitHubIssues(): Promise<any[]> {
  const config = getGitHubConfig();
  if (!config) return [];

  const allIssues: any[] = [];

  for (const { owner, repo, prefix } of config.repos) {
    try {
      // Use gh CLI for fetching issues (better OAuth handling)
      let openIssues: any[] = [];
      let closedIssues: any[] = [];

      try {
        // Use async execAsync to avoid blocking event loop
        const { stdout: openJson } = await execAsync(
          `gh issue list --repo ${owner}/${repo} --state open --limit 100 --json number,title,body,state,labels,assignees,createdAt,updatedAt,url`,
          { timeout: 30000 }
        );
        openIssues = JSON.parse(openJson);
      } catch (ghError: any) {
        console.error(`gh CLI failed for ${owner}/${repo} open issues:`, ghError.message);
        // Fallback to API if gh fails
        const openResponse = await fetch(
          `https://api.github.com/repos/${owner}/${repo}/issues?state=open&per_page=100`,
          {
            headers: {
              'Authorization': `token ${config.token}`,
              'Accept': 'application/vnd.github.v3+json',
              'User-Agent': 'Panopticon-Dashboard',
            },
          }
        );
        if (openResponse.ok) {
          openIssues = await openResponse.json();
        }
      }

      try {
        const dateFilter = getOneDayAgo().toISOString().split('T')[0]; // YYYY-MM-DD

        // Use async execAsync to avoid blocking event loop
        const { stdout: closedJson } = await execAsync(
          `gh issue list --repo ${owner}/${repo} --state closed --search "closed:>=${dateFilter}" --limit 50 --json number,title,body,state,labels,assignees,createdAt,updatedAt,closedAt,url`,
          { timeout: 30000 }
        );
        closedIssues = JSON.parse(closedJson);
      } catch (ghError: any) {
        console.error(`gh CLI failed for ${owner}/${repo} closed issues:`, ghError.message);
        // Fallback to API
        const oneDayAgo = getOneDayAgo();
        const closedResponse = await fetch(
          `https://api.github.com/repos/${owner}/${repo}/issues?state=closed&since=${oneDayAgo.toISOString()}&per_page=50`,
          {
            headers: {
              'Authorization': `token ${config.token}`,
              'Accept': 'application/vnd.github.v3+json',
              'User-Agent': 'Panopticon-Dashboard',
            },
          }
        );
        if (closedResponse.ok) {
          closedIssues = await closedResponse.json();
        }
      }

      // Combine and filter out PRs (they have pull_request key)
      const issues = [...openIssues, ...closedIssues].filter(
        (issue: any) => !issue.pull_request
      );

      // Format issues to match our schema
      // Handle both gh CLI format (camelCase) and API format (snake_case)
      for (const issue of issues) {
        const labelNames = issue.labels?.map((l: any) => l.name || l) || [];
        const canonicalStatus = mapGitHubStateToCanonical(issue.state, labelNames);

        // Create identifier: use prefix if provided, otherwise repo name
        const issuePrefix = prefix || repo.toUpperCase();
        const identifier = `${issuePrefix}-${issue.number}`;

        // Handle assignee: gh CLI uses assignees array, API uses assignee object
        const firstAssignee = issue.assignees?.[0] || issue.assignee;

        allIssues.push({
          id: `github-${owner}-${repo}-${issue.number}`,
          identifier,
          title: issue.title,
          description: issue.body || '',
          status: canonicalStatus === 'todo' ? 'Todo' :
                  canonicalStatus === 'planning' ? 'In Planning' :
                  canonicalStatus === 'planned' ? 'Planned' :
                  canonicalStatus === 'in_progress' ? 'In Progress' :
                  canonicalStatus === 'in_review' ? 'In Review' :
                  canonicalStatus === 'done' ? 'Done' :
                  canonicalStatus === 'backlog' ? 'Backlog' : 'Todo',
          priority: labelNames.some((l: string) => l.includes('priority') && l.includes('high')) ? 2 :
                    labelNames.some((l: string) => l.includes('priority') && l.includes('urgent')) ? 1 :
                    labelNames.some((l: string) => l.includes('priority') && l.includes('low')) ? 4 : 3,
          assignee: firstAssignee ? {
            name: firstAssignee.login,
            email: `${firstAssignee.login}@github`,
          } : undefined,
          labels: labelNames,
          // gh CLI uses 'url', API uses 'html_url'
          url: issue.url || issue.html_url,
          // gh CLI uses camelCase, API uses snake_case
          createdAt: issue.createdAt || issue.created_at,
          updatedAt: issue.updatedAt || issue.updated_at,
          completedAt: issue.closedAt || issue.closed_at,
          // Use repo as project
          project: {
            id: `github-${owner}-${repo}`,
            name: `${owner}/${repo}`,
            color: '#333',
            icon: 'github',
          },
          // Mark source as GitHub
          source: 'github',
          sourceRepo: `${owner}/${repo}`,
        });
      }
    } catch (error) {
      console.error(`Error fetching GitHub issues for ${owner}/${repo}:`, error);
    }
  }

  console.log(`Fetched ${allIssues.length} GitHub issues`);
  return allIssues;
}

// Map Rally ScheduleState to canonical dashboard state
function mapRallyStateToCanonical(scheduleState: string): string {
  const stateLower = scheduleState.toLowerCase();

  if (stateLower === 'defined') return 'todo';
  if (stateLower === 'in-progress') return 'in_progress';
  if (stateLower === 'completed' || stateLower === 'accepted') return 'done';

  return 'todo';
}

// Fetch Rally issues using the Rally adapter
async function fetchRallyIssues(): Promise<any[]> {
  const config = getRallyConfig();
  if (!config) return [];

  try {
    // Dynamically import the Rally tracker
    const { RallyTracker } = await import('../../lib/tracker/rally.js');

    const tracker = new RallyTracker({
      apiKey: config.apiKey,
      server: config.server,
      workspace: config.workspace,
      project: config.project,
    });

    // Fetch all open issues
    const issues = await tracker.listIssues({
      includeClosed: false,
      limit: 100,
    });

    // Format issues to match dashboard schema
    const formattedIssues = issues.map((issue: any) => {
      const canonicalStatus = mapRallyStateToCanonical(issue.state);

      return {
        id: `rally-${issue.id}`,
        identifier: issue.ref,
        title: issue.title,
        description: issue.description || '',
        status: canonicalStatus === 'todo' ? 'Todo' :
                canonicalStatus === 'in_progress' ? 'In Progress' :
                canonicalStatus === 'done' ? 'Done' : 'Todo',
        priority: issue.priority ?? 3,
        assignee: issue.assignee ? {
          name: issue.assignee,
          email: `${issue.assignee.replace(/\s+/g, '.').toLowerCase()}@rally`,
        } : undefined,
        labels: issue.labels || [],
        url: issue.url,
        createdAt: issue.createdAt,
        updatedAt: issue.updatedAt,
        project: {
          id: 'rally-project',
          name: 'Rally',
          color: '#00C7B1',
          icon: 'rally',
        },
        source: 'rally',
      };
    });

    console.log(`Fetched ${formattedIssues.length} Rally issues`);
    return formattedIssues;
  } catch (error: any) {
    console.error('Error fetching Rally issues:', error.message);
    return [];
  }
}

// Get Linear issues using raw GraphQL for efficiency (single query with all data)
// Query params:
//   - cycle: 'current' (default) | 'all' | 'backlog' - filter by cycle
//   - includeCompleted: 'true' | 'false' (default) - include completed issues
app.get('/api/issues', async (req, res) => {
  try {
    const apiKey = getLinearApiKey();
    if (!apiKey) {
      return res.status(500).json({ error: 'LINEAR_API_KEY not configured' });
    }

    const cycleFilter = (req.query.cycle as string) || 'current';
    const includeCompleted = req.query.includeCompleted === 'true';

    // Build filter conditions as array
    const filterConditions: string[] = [];

    if (cycleFilter === 'current') {
      // Filter to current active cycle only
      filterConditions.push('cycle: { isActive: { eq: true } }');
    } else if (cycleFilter === 'backlog') {
      // Issues not in any cycle
      filterConditions.push('cycle: { null: true }');
    }
    // 'all' = no cycle filter

    // Optionally exclude completed issues
    if (!includeCompleted) {
      filterConditions.push('state: { type: { nin: ["completed", "canceled"] } }');
    }

    // Build final filter clause
    let filterClause = '';
    if (filterConditions.length === 1) {
      filterClause = `filter: { ${filterConditions[0]} }`;
    } else if (filterConditions.length > 1) {
      filterClause = `filter: { and: [${filterConditions.map(c => `{ ${c} }`).join(', ')}] }`;
    }

    // Use raw GraphQL to fetch all data in one query per page (no lazy loading)
    const allIssues: any[] = [];
    let hasMore = true;
    let cursor: string | undefined;

    while (hasMore) {
      const query = `
        query GetIssues($after: String) {
          issues(first: 100, after: $after, ${filterClause ? filterClause + ', ' : ''}orderBy: updatedAt) {
            pageInfo {
              hasNextPage
              endCursor
            }
            nodes {
              id
              identifier
              title
              description
              priority
              url
              createdAt
              updatedAt
              completedAt
              state {
                name
                type
              }
              assignee {
                name
                email
              }
              labels {
                nodes {
                  name
                }
              }
              project {
                id
                name
                color
                icon
              }
              team {
                id
                name
                color
                icon
              }
              cycle {
                id
                name
                number
              }
            }
          }
        }
      `;

      const response = await fetch('https://api.linear.app/graphql', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': apiKey,
        },
        body: JSON.stringify({ query, variables: { after: cursor } }),
      });

      const json = await response.json();

      if (json.errors) {
        console.error('GraphQL errors:', json.errors);
        throw new Error(json.errors[0]?.message || 'GraphQL error');
      }

      const issues = json.data?.issues;
      if (!issues) break;

      allIssues.push(...issues.nodes);
      hasMore = issues.pageInfo.hasNextPage;
      cursor = issues.pageInfo.endCursor;

      // Safety limit
      if (allIssues.length > 1000) break;
    }

    console.log(`Fetched ${allIssues.length} Linear issues (cycle=${cycleFilter}, includeCompleted=${includeCompleted})`);

    // Format Linear issues (data is already resolved, no extra API calls)
    const linearFormatted = allIssues.map((issue: any) => ({
      id: issue.id,
      identifier: issue.identifier,
      title: issue.title,
      description: issue.description,
      status: issue.state?.name || 'Backlog',
      stateType: issue.state?.type,
      priority: issue.priority,
      assignee: issue.assignee ? { name: issue.assignee.name, email: issue.assignee.email } : undefined,
      labels: issue.labels?.nodes?.map((l: any) => l.name) || [],
      url: issue.url,
      createdAt: issue.createdAt,
      updatedAt: issue.updatedAt,
      completedAt: issue.completedAt,
      // Use project if available, otherwise fall back to team
      project: issue.project ? {
        id: issue.project.id,
        name: issue.project.name,
        color: issue.project.color,
        icon: issue.project.icon,
      } : issue.team ? {
        id: issue.team.id,
        name: issue.team.name,
        color: issue.team.color,
        icon: issue.team.icon,
      } : undefined,
      // Include cycle info
      cycle: issue.cycle ? {
        id: issue.cycle.id,
        name: issue.cycle.name,
        number: issue.cycle.number,
      } : undefined,
      // Mark source as Linear
      source: 'linear',
    }));

    // Fetch GitHub and Rally issues in parallel
    const [githubIssues, rallyIssues] = await Promise.all([
      fetchGitHubIssues(),
      fetchRallyIssues(),
    ]);

    // Merge all issues
    let allFormatted = [...linearFormatted, ...githubIssues, ...rallyIssues];

    const oneDayAgoTime = getOneDayAgo().getTime();

    allFormatted = allFormatted.filter((issue: Issue) => {
      const isDone = issue.status === 'Done' || issue.status === 'Completed' || issue.status === 'Closed';
      const isCanceled = issue.status === 'Canceled' || issue.status === 'Cancelled';

      // Keep all non-done/canceled issues
      if (!isDone && !isCanceled) return true;

      // For done/canceled issues, only keep if completed in last 24 hours
      if (issue.completedAt) {
        const completedTime = new Date(issue.completedAt).getTime();
        return completedTime >= oneDayAgoTime;
      }

      // If no completedAt, exclude done/canceled items (shouldn't happen with new data)
      return false;
    });

    // Sort by updatedAt
    allFormatted.sort((a, b) =>
      new Date(b.updatedAt).getTime() - new Date(a.updatedAt).getTime()
    );

    res.json(allFormatted);
  } catch (error: any) {
    console.error('Error fetching issues:', error);
    res.status(500).json({ error: 'Failed to fetch issues: ' + error.message });
  }
});

// Analyze issue complexity
app.get('/api/issues/:id/analyze', async (req, res) => {
  try {
    const { id } = req.params;
    const apiKey = getLinearApiKey();
    if (!apiKey) {
      return res.status(500).json({ error: 'LINEAR_API_KEY not configured' });
    }

    // Linear's issue query accepts both UUIDs and identifiers (MIN-123)
    const query = `
      query GetIssue($id: String!) {
        issue(id: $id) {
          id
          identifier
          title
          description
          priority
          url
          state { name }
          labels { nodes { name } }
          project { id name }
        }
      }
    `;

    const response = await fetch('https://api.linear.app/graphql', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': apiKey,
      },
      body: JSON.stringify({ query, variables: { id } }),
    });
    const json = await response.json();
    if (json.errors) throw new Error(json.errors[0]?.message || 'GraphQL error');
    const issue = json.data?.issue;

    if (!issue) {
      return res.status(404).json({ error: 'Issue not found' });
    }

    // Analyze complexity
    const desc = (issue.description || '').toLowerCase();
    const title = issue.title.toLowerCase();
    const combined = `${title} ${desc}`;

    const reasons: string[] = [];
    const subsystems: string[] = [];
    let estimatedTasks = 1;

    // Check for multiple subsystems
    if (combined.includes('frontend') || combined.includes('ui') || combined.includes('component')) {
      subsystems.push('frontend');
    }
    if (combined.includes('backend') || combined.includes('api') || combined.includes('endpoint')) {
      subsystems.push('backend');
    }
    if (combined.includes('database') || combined.includes('migration') || combined.includes('schema')) {
      subsystems.push('database');
    }
    if (combined.includes('test') || combined.includes('e2e') || combined.includes('playwright')) {
      subsystems.push('tests');
    }

    if (subsystems.length > 1) {
      reasons.push(`Multiple subsystems involved: ${subsystems.join(', ')}`);
      estimatedTasks += subsystems.length;
    }

    // Check for ambiguous requirements
    const ambiguousPatterns = ['should we', 'maybe', 'or', 'consider', 'option', 'approach', 'tbd', 'unclear'];
    for (const pattern of ambiguousPatterns) {
      if (combined.includes(pattern)) {
        reasons.push('Requirements may be ambiguous');
        break;
      }
    }

    // Check for architecture keywords
    const architecturePatterns = ['refactor', 'architecture', 'redesign', 'migrate', 'integration', 'authentication'];
    for (const pattern of architecturePatterns) {
      if (combined.includes(pattern)) {
        reasons.push(`Architecture decision needed: ${pattern}`);
        estimatedTasks += 2;
        break;
      }
    }

    // Check description length
    if (desc.length > 500) {
      reasons.push('Detailed description suggests complexity');
      estimatedTasks += 1;
    }

    // Check labels for complexity hints
    const labels = issue.labels?.nodes?.map((l: any) => l.name) || [];
    const complexLabels = ['complex', 'large', 'epic', 'multi-phase', 'architecture'];
    for (const label of labels) {
      if (complexLabels.some(cl => label.toLowerCase().includes(cl))) {
        reasons.push(`Label indicates complexity: ${label}`);
        estimatedTasks += 2;
      }
    }

    const isComplex = reasons.length >= 2 || subsystems.length > 1 || estimatedTasks >= 4;

    res.json({
      issue: {
        id: issue.id,
        identifier: issue.identifier,
        title: issue.title,
        description: issue.description,
        status: issue.state?.name || 'Unknown',
        priority: issue.priority,
        url: issue.url,
        labels,
      },
      complexity: {
        isComplex,
        reasons,
        subsystems,
        estimatedTasks: Math.max(estimatedTasks, subsystems.length + 1),
      },
    });
  } catch (error: any) {
    console.error('Error analyzing issue:', error);
    res.status(500).json({ error: 'Failed to analyze issue: ' + error.message });
  }
});

// Create execution plan for an issue
app.post('/api/issues/:id/plan', async (req, res) => {
  try {
    const { id } = req.params;
    const { answers, tasks } = req.body;

    if (!tasks || !Array.isArray(tasks) || tasks.length === 0) {
      return res.status(400).json({ error: 'Tasks are required' });
    }

    // Get issue details first
    const apiKey = getLinearApiKey();
    if (!apiKey) {
      return res.status(500).json({ error: 'LINEAR_API_KEY not configured' });
    }

    // Linear's issue query accepts both UUIDs and identifiers (MIN-123)
    const query = `
      query GetIssue($id: String!) {
        issue(id: $id) {
          id
          identifier
          title
          description
          url
        }
      }
    `;
    const response = await fetch('https://api.linear.app/graphql', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': apiKey,
      },
      body: JSON.stringify({ query, variables: { id } }),
    });
    const json = await response.json();
    if (json.errors) throw new Error(json.errors[0]?.message || 'GraphQL error');
    const issue = json.data?.issue;

    if (!issue) {
      return res.status(404).json({ error: 'Issue not found' });
    }

    // Find project path for this issue
    const mappings = getProjectMappings();
    const prefix = issue.identifier.split('-')[0];
    const mapping = mappings.find(m => m.linearPrefix.toUpperCase() === prefix.toUpperCase());
    const projectPath = mapping?.localPath || getDefaultProjectPath();

    // Generate STATE.md content
    const stateContent = [
      `# Agent State: ${issue.identifier}`,
      '',
      `**Last Updated:** ${new Date().toISOString()}`,
      '',
      '## Current Position',
      '',
      `- **Issue:** ${issue.identifier}`,
      `- **Title:** ${issue.title}`,
      `- **Status:** Planning complete, ready for execution`,
      `- **Linear:** ${issue.url}`,
      '',
      '## Decisions Made During Planning',
      '',
    ];

    if (answers && Object.keys(answers).length > 0) {
      if (answers.scope) stateContent.push(`- **Scope:** ${answers.scope}`);
      if (answers.approach) stateContent.push(`- **Technical approach:** ${answers.approach}`);
      if (answers.edgeCases) stateContent.push(`- **Edge cases:** ${answers.edgeCases}`);
      if (answers.testing && answers.testing.length > 0) stateContent.push(`- **Testing:** ${answers.testing.join(', ')}`);
      if (answers.outOfScope) stateContent.push(`- **Out of scope:** ${answers.outOfScope}`);
    } else {
      stateContent.push('- No specific decisions recorded');
    }

    stateContent.push('');
    stateContent.push('## Planned Tasks');
    stateContent.push('');

    for (const task of tasks) {
      stateContent.push(`- [ ] ${task.name}${task.dependsOn ? ` (after: ${task.dependsOn})` : ''}`);
    }

    stateContent.push('');
    stateContent.push('## Blockers/Concerns');
    stateContent.push('');
    stateContent.push('- None identified during planning');
    stateContent.push('');
    stateContent.push('## Notes');
    stateContent.push('');
    stateContent.push('<!-- Add notes as work progresses -->');
    stateContent.push('');

    // Generate WORKSPACE.md content
    const workspaceContent = [
      `# Workspace: ${issue.identifier}`,
      '',
      `> ${issue.title}`,
      '',
      '## Quick Links',
      '',
      `- [Linear Issue](${issue.url})`,
      '',
      '## Context Files',
      '',
      '- `STATE.md` - Current progress and decisions',
      '- `WORKSPACE.md` - This file',
      '',
      '## Beads',
      '',
      'Check current task status:',
      '```bash',
      'bd ready  # Next actionable task',
      `bd list --tag ${issue.identifier}  # All tasks for this issue`,
      '```',
      '',
      '## Agent Instructions',
      '',
      '1. Run `bd ready` to get next task',
      '2. Complete the task following relevant skills',
      '3. Run `bd close "<task name>" --reason "..."` when done',
      '4. Update STATE.md with progress',
      '5. Repeat until all tasks complete',
      '',
    ];

    // Write files to .planning directory
    const { mkdirSync, writeFileSync: writeSync } = require('fs');
    const planningDir = join(projectPath, '.planning');
    mkdirSync(planningDir, { recursive: true });

    const statePath = join(planningDir, 'STATE.md');
    const workspacePath = join(planningDir, 'WORKSPACE.md');
    writeSync(statePath, stateContent.join('\n'));
    writeSync(workspacePath, workspaceContent.join('\n'));

    // Copy to PRD directory
    let prdPath: string | undefined;
    try {
      const prdDir = join(projectPath, 'docs', 'prds', 'active');
      mkdirSync(prdDir, { recursive: true });
      prdPath = join(prdDir, `${issue.identifier.toLowerCase()}-plan.md`);
      writeSync(prdPath, stateContent.join('\n'));
    } catch {
      // PRD copy is optional
    }

    // Create Beads tasks
    const beadsResult = { success: false, created: [] as string[], errors: [] as string[] };
    try {
      const { stdout: bdPath } = await execAsync('which bd', { encoding: 'utf-8' });
      if (bdPath.trim()) {
        const taskIds = new Map<string, string>();

        for (const task of tasks) {
          const fullName = `${issue.identifier}: ${task.name}`;
          try {
            let cmd = `bd create "${fullName.replace(/"/g, '\\"')}" --type task -l "${issue.identifier},linear"`;

            if (task.dependsOn) {
              const depName = `${issue.identifier}: ${task.dependsOn}`;
              const depId = taskIds.get(depName);
              if (depId) {
                cmd += ` --deps "blocks:${depId}"`;
              }
            }

            if (task.description) {
              cmd += ` -d "${task.description.replace(/"/g, '\\"')}"`;
            }

            const { stdout: result } = await execAsync(cmd, { encoding: 'utf-8', cwd: projectPath });
            const idMatch = result.match(/bd-[a-f0-9]+/i) || result.match(/([a-f0-9-]{8,})/i);
            if (idMatch) {
              taskIds.set(fullName, idMatch[0]);
            }
            beadsResult.created.push(fullName);
          } catch (error: any) {
            beadsResult.errors.push(`Failed to create "${task.name}": ${error.message}`);
          }
        }

        if (beadsResult.created.length > 0) {
          try {
            await execAsync('bd flush', { encoding: 'utf-8', cwd: projectPath });
          } catch {}
        }

        beadsResult.success = beadsResult.errors.length === 0;
      }
    } catch {
      beadsResult.errors.push('bd (beads) CLI not found');
    }

    res.json({
      success: true,
      complexity: null, // Not re-analyzed
      tasks,
      files: {
        state: statePath.replace(projectPath, '.'),
        workspace: workspacePath.replace(projectPath, '.'),
        prd: prdPath ? prdPath.replace(projectPath, '.') : undefined,
      },
      beads: beadsResult,
    });
  } catch (error: any) {
    console.error('Error creating plan:', error);
    res.status(500).json({ error: 'Failed to create plan: ' + error.message });
  }
});

// Get project mappings (Linear project -> local directory)
const PROJECT_MAPPINGS_FILE = join(homedir(), '.panopticon', 'project-mappings.json');

interface ProjectMapping {
  linearProjectId: string;
  linearProjectName: string;
  linearPrefix: string;  // e.g., "MIN"
  localPath: string;
}

function getProjectMappings(): ProjectMapping[] {
  try {
    if (existsSync(PROJECT_MAPPINGS_FILE)) {
      return JSON.parse(readFileSync(PROJECT_MAPPINGS_FILE, 'utf-8'));
    }
  } catch {}
  return [];
}

function saveProjectMappings(mappings: ProjectMapping[]) {
  const dir = join(homedir(), '.panopticon');
  if (!existsSync(dir)) {
    require('fs').mkdirSync(dir, { recursive: true });
  }
  writeFileSync(PROJECT_MAPPINGS_FILE, JSON.stringify(mappings, null, 2));
}

// Get all project mappings
app.get('/api/project-mappings', (_req, res) => {
  res.json(getProjectMappings());
});

// Update project mappings
app.put('/api/project-mappings', (req, res) => {
  const mappings = req.body;
  if (!Array.isArray(mappings)) {
    return res.status(400).json({ error: 'Expected array of mappings' });
  }
  saveProjectMappings(mappings);
  res.json({ success: true, mappings });
});

// Add or update a single project mapping
app.post('/api/project-mappings', (req, res) => {
  const { linearProjectId, linearProjectName, linearPrefix, localPath } = req.body;
  if (!linearProjectId || !localPath) {
    return res.status(400).json({ error: 'linearProjectId and localPath required' });
  }

  const mappings = getProjectMappings();
  const existing = mappings.findIndex(m => m.linearProjectId === linearProjectId);

  const mapping: ProjectMapping = {
    linearProjectId,
    linearProjectName: linearProjectName || '',
    linearPrefix: linearPrefix || '',
    localPath,
  };

  if (existing >= 0) {
    mappings[existing] = mapping;
  } else {
    mappings.push(mapping);
  }

  saveProjectMappings(mappings);
  res.json({ success: true, mapping });
});

// Get local path for a Linear project (used when creating workspaces)
// Now integrates with YAML-based project registry (projects.yaml) as primary source
function getProjectPath(linearProjectId?: string, issuePrefix?: string, issueLabels?: string[]): string {
  // First, try the new YAML-based project registry (preferred)
  // This supports label-based routing for multi-repo projects like MYN
  if (issuePrefix) {
    const issueId = `${issuePrefix}-1`; // Construct a dummy issue ID for resolution
    const resolved = resolveProjectFromIssue(issueId, issueLabels || []);
    if (resolved) {
      return resolved.projectPath;
    }
  }

  // Fall back to legacy JSON mappings
  const mappings = getProjectMappings();

  // Try to find by project ID first
  if (linearProjectId) {
    const mapping = mappings.find(m => m.linearProjectId === linearProjectId);
    if (mapping) return mapping.localPath;
  }

  // Try to find by issue prefix (e.g., "MIN" from "MIN-645")
  if (issuePrefix) {
    const mapping = mappings.find(m => m.linearPrefix === issuePrefix);
    if (mapping) return mapping.localPath;
  }

  // Handle GitHub issue prefixes from GITHUB_REPOS config
  // Format: owner/repo:PREFIX or owner/repo (uses uppercase repo name)
  if (issuePrefix) {
    const config = getGitHubConfig();
    if (config) {
      for (const { owner, repo, prefix } of config.repos) {
        // Match against prefix or uppercase repo name
        const repoPrefix = prefix || repo.toUpperCase().replace(/-CLI$/, '').replace(/-/g, '');
        if (repoPrefix.toUpperCase() === issuePrefix.toUpperCase()) {
          // GitHub repos - look in ~/projects/{repo}/ or ~/projects/{owner}/{repo}/
          const possiblePaths = [
            join(homedir(), 'projects', repo),
            join(homedir(), 'projects', repo.replace(/-cli$/, '')),
            join(homedir(), 'projects', owner, repo),
          ];
          for (const path of possiblePaths) {
            if (existsSync(path)) {
              return path;
            }
          }
        }
      }
    }
  }

  // Fall back to default project
  return getDefaultProjectPath();
}

// Get git status for a workspace path (ASYNC - non-blocking)
async function getGitStatusAsync(workspacePath: string): Promise<{ branch: string; uncommittedFiles: number; latestCommit: string } | null> {
  try {
    if (!existsSync(workspacePath)) return null;

    // Run all git commands in parallel for better performance
    const [branchResult, uncommittedResult, commitResult] = await Promise.all([
      execAsync('git rev-parse --abbrev-ref HEAD 2>/dev/null || echo ""', { cwd: workspacePath }),
      execAsync('git status --porcelain 2>/dev/null | wc -l', { cwd: workspacePath }),
      execAsync('git log -1 --pretty=format:"%s" 2>/dev/null || echo ""', { cwd: workspacePath }),
    ]);

    const branch = branchResult.stdout.trim();
    const uncommitted = uncommittedResult.stdout.trim();
    const latestCommit = commitResult.stdout.trim();

    if (!branch) return null;

    return {
      branch,
      uncommittedFiles: parseInt(uncommitted) || 0,
      latestCommit: latestCommit.slice(0, 60) + (latestCommit.length > 60 ? '...' : ''),
    };
  } catch {
    return null;
  }
}

// Async version for non-blocking git operations
async function getGitStatus(workspacePath: string): Promise<{ branch: string; uncommittedFiles: number; latestCommit: string } | null> {
  try {
    if (!existsSync(workspacePath)) return null;

    const { stdout: branch } = await execAsync('git rev-parse --abbrev-ref HEAD 2>/dev/null', {
      cwd: workspacePath,
      encoding: 'utf-8',
    });

    const { stdout: uncommitted } = await execAsync('git status --porcelain 2>/dev/null | wc -l', {
      cwd: workspacePath,
      encoding: 'utf-8',
    });

    const { stdout: latestCommit } = await execAsync('git log -1 --pretty=format:"%s" 2>/dev/null', {
      cwd: workspacePath,
      encoding: 'utf-8',
    });

    return {
      branch: branch.trim(),
      uncommittedFiles: parseInt(uncommitted.trim()) || 0,
      latestCommit: latestCommit.trim().slice(0, 60) + (latestCommit.trim().length > 60 ? '...' : ''),
    };
  } catch {
    return null;
  }
}

// Get running agents from tmux sessions
app.get('/api/agents', async (_req, res) => {
  try {
    const now = Date.now();

    // Return cached data if still fresh
    if (agentsCache.data && (now - agentsCache.timestamp) < AGENTS_CACHE_TTL_MS) {
      return res.json(agentsCache.data);
    }

    const { stdout } = await execAsync('tmux list-sessions -F "#{session_name}|#{session_created}" 2>/dev/null || true');

    const agentLines = stdout
      .trim()
      .split('\n')
      .filter((line) => line.startsWith('agent-') || line.startsWith('planning-'));

    // Process agents in parallel to avoid blocking
    const agents = await Promise.all(
      agentLines.map(async (line) => {
        const [name, created] = line.split('|');
        const startedAt = new Date(parseInt(created) * 1000).toISOString();
        const isPlanning = name.startsWith('planning-');

        // Check agent state from ~/.panopticon/agents/
        const stateFile = join(homedir(), '.panopticon', 'agents', name, 'state.json');
        const healthFile = join(homedir(), '.panopticon', 'agents', name, 'health.json');
        let state: any = { runtime: 'claude', model: isPlanning ? 'opus' : 'sonnet', workspace: process.cwd() };
        let health: any = { consecutiveFailures: 0, killCount: 0 };

        if (existsSync(stateFile)) {
          try {
            state = { ...state, ...JSON.parse(readFileSync(stateFile, 'utf-8')) };
          } catch {}
        }

        if (existsSync(healthFile)) {
          try {
            health = { ...health, ...JSON.parse(readFileSync(healthFile, 'utf-8')) };
          } catch {}
        }

        // Get git status for workspace (ASYNC - doesn't block event loop)
        const gitStatus = state.workspace ? await getGitStatusAsync(state.workspace) : null;

        // Extract issue ID from session name
        const issueId = isPlanning
          ? name.replace('planning-', '').toUpperCase()
          : name.replace('agent-', '').toUpperCase();

        // Check for pending AskUserQuestion (agent waiting for user input)
        const pendingQuestions = await getAgentPendingQuestions(name);

        return {
          id: name,
          issueId,
          runtime: state.runtime || 'claude',
          model: state.model || (isPlanning ? 'opus' : 'sonnet'),
          status: 'healthy' as const,
          startedAt,
          consecutiveFailures: health.consecutiveFailures || 0,
          killCount: health.killCount || 0,
          workspace: state.workspace || null,
          git: gitStatus,
          type: isPlanning ? 'planning' : 'agent',
          hasPendingQuestion: pendingQuestions.length > 0,
          pendingQuestionCount: pendingQuestions.length,
        };
      })
    );

    // Cache the result
    agentsCache = { data: agents, timestamp: now };
    res.json(agents);
  } catch (error) {
    console.error('Error listing agents:', error);
    res.json([]);
  }
});

// Get agent output
app.get('/api/agents/:id/output', async (req, res) => {
  const { id } = req.params;
  const lines = req.query.lines || 100;

  try {
    const { stdout } = await execAsync(
      `tmux capture-pane -t "${id}" -p -S -${lines} 2>/dev/null || echo "Session not found"`,
      { maxBuffer: 10 * 1024 * 1024 }
    );

    res.json({ output: stdout });
  } catch (error) {
    res.json({ output: 'Failed to capture output' });
  }
});

// Send message to agent (async to avoid blocking event loop)
app.post('/api/agents/:id/message', async (req, res) => {
  const { id } = req.params;
  const { message } = req.body;

  if (!message) {
    return res.status(400).json({ error: 'Message required' });
  }

  try {
    // Send message to tmux session (async)
    await execAsync(`tmux send-keys -t "${id}" "${message.replace(/"/g, '\\"')}"`);
    // Press Enter (C-m is more reliable than literal 'Enter')
    await execAsync(`tmux send-keys -t "${id}" C-m`);

    res.json({ success: true });
  } catch (error) {
    console.error('Error sending message:', error);
    res.status(500).json({ error: 'Failed to send message' });
  }
});

// Kill agent (async to avoid blocking event loop)
app.delete('/api/agents/:id', async (req, res) => {
  const { id } = req.params;

  try {
    await execAsync(`tmux kill-session -t "${id}" 2>/dev/null || true`);

    // Clean up agent state files to prevent stale "running" status
    const agentStateDir = join(homedir(), '.panopticon', 'agents', id);
    try {
      if (existsSync(agentStateDir)) {
        rmSync(agentStateDir, { recursive: true, force: true });
      }
    } catch (cleanupErr) {
      console.log('Warning: Could not clean up agent state:', cleanupErr);
    }

    res.json({ success: true });
  } catch (error) {
    console.error('Error killing agent:', error);
    res.status(500).json({ error: 'Failed to kill agent' });
  }
});

// Get health history for an agent (last 24h by default)
app.get('/api/agents/:id/health-history', async (req, res) => {
  const { id } = req.params;
  const { hours = '24' } = req.query;

  try {
    const { getHealthHistory } = await import('../../lib/cloister/database.js');

    // Calculate time range
    const endTime = new Date();
    const startTime = new Date(endTime.getTime() - parseInt(hours as string) * 60 * 60 * 1000);

    const events = getHealthHistory(id, startTime.toISOString(), endTime.toISOString());

    res.json({
      agentId: id,
      startTime: startTime.toISOString(),
      endTime: endTime.toISOString(),
      events,
    });
  } catch (error) {
    console.error('Error fetching health history:', error);
    res.status(500).json({ error: 'Failed to fetch health history' });
  }
});

// Poke an agent (send nudge message) - ASYNC to avoid blocking event loop
app.post('/api/agents/:id/poke', async (req, res) => {
  const { id } = req.params;
  const { message } = req.body;

  const defaultPokeMessage =
    'You seem to have been inactive for a while. If you\'re stuck:\n' +
    '1. Check your current task in STATE.md\n' +
    '2. Try an alternative approach if blocked\n' +
    '3. Ask for help if needed\n\n' +
    'What\'s your current status?';

  const pokeMsg = message || defaultPokeMessage;

  try {
    // Send message via tmux (two separate commands: text then Enter)
    const escapedMsg = pokeMsg.replace(/"/g, '\\"').replace(/'/g, "\\'");
    await execAsync(`tmux send-keys -t "${id}" "${escapedMsg}"`);
    await execAsync(`tmux send-keys -t "${id}" C-m`, { encoding: 'utf-8' });

    res.json({ success: true, message: 'Agent poked successfully' });
  } catch (error) {
    console.error('Error poking agent:', error);
    res.status(500).json({ error: 'Failed to poke agent' });
  }
});

// ============================================================================
// AskUserQuestion Interception Endpoints (PAN-20)
// ============================================================================

// Get pending questions for an agent (polls JSONL for unanswered AskUserQuestion calls)
app.get('/api/agents/:id/pending-questions', async (req, res) => {
  const { id } = req.params;

  try {
    const questions = await getAgentPendingQuestions(id);
    res.json({
      pending: questions.length > 0,
      questions
    });
  } catch (error) {
    console.error('Error checking pending questions:', error);
    res.json({ pending: false, questions: [] });
  }
});

// Submit answer to a pending question (sends keystrokes to tmux session)
// ASYNC to avoid blocking event loop
app.post('/api/agents/:id/answer-question', async (req, res) => {
  const { id } = req.params;
  const { answers } = req.body; // Array of selected option labels (one per question)

  if (!answers || !Array.isArray(answers) || answers.length === 0) {
    return res.status(400).json({ error: 'answers array required' });
  }

  try {
    // Get the pending questions to map labels to option indices
    const pendingQuestions = await getAgentPendingQuestions(id);
    if (pendingQuestions.length === 0) {
      return res.status(400).json({ error: 'No pending questions found' });
    }

    const questionSet = pendingQuestions[0]; // Most recent question set
    const questions = questionSet.questions;

    // Claude's AskUserQuestion UI:
    // - Number key (1-4) selects an option for current question
    // - Tab moves to next question
    // - When on Submit, Enter submits all answers

    // Helper for small delay (non-blocking)
    const delay = (ms: number) => new Promise(resolve => setTimeout(resolve, ms));

    for (let i = 0; i < answers.length && i < questions.length; i++) {
      const answer = answers[i];
      const question = questions[i];

      // Find the 1-based index of the selected option
      const optionIndex = question.options.findIndex(
        (opt: { label: string }) => opt.label === answer
      );

      if (optionIndex === -1) {
        // Answer not found in options - might be custom text (option 4)
        // Send "4" to select "Type something" then type the answer
        await execAsync(`tmux send-keys -t "${id}" "4"`);
        // Small delay then type the custom answer
        const escapedAnswer = answer.replace(/'/g, "'\\''");
        await execAsync(`tmux send-keys -t "${id}" '${escapedAnswer}'`);
        await execAsync(`tmux send-keys -t "${id}" C-m`);
      } else {
        // Send the number key (1-based index)
        const keyNumber = optionIndex + 1;
        await execAsync(`tmux send-keys -t "${id}" "${keyNumber}"`);
      }

      // Tab to next question (or to Submit if last)
      await execAsync(`tmux send-keys -t "${id}" Tab`);

      // Small delay between keystrokes for reliability (non-blocking)
      await delay(100);
    }

    // Press Enter to submit (should be on Submit button now)
    await execAsync(`tmux send-keys -t "${id}" C-m`);

    res.json({ success: true });
  } catch (error) {
    console.error('Error sending answer:', error);
    res.status(500).json({ error: 'Failed to send answer' });
  }
});

// ============================================================================
// Agent State Management Endpoints (PAN-80)
// ============================================================================

// Receive heartbeat from hooks (PreToolUse, Stop)
app.post('/api/agents/:id/heartbeat', async (req, res) => {
  const { id } = req.params;
  const { state, tool, timestamp } = req.body;

  try {
    // Update runtime state
    saveAgentRuntimeState(id, {
      state,
      lastActivity: timestamp || new Date().toISOString(),
      currentTool: tool,
    });

    res.json({ success: true });
  } catch (error) {
    console.error('Error saving heartbeat:', error);
    res.status(500).json({ error: 'Failed to save heartbeat' });
  }
});

// Get activity log for an agent
app.get('/api/agents/:id/activity', (req, res) => {
  const { id } = req.params;
  const limit = parseInt(req.query.limit as string) || 100;

  try {
    const activity = getActivity(id, limit);
    res.json({ activity });
  } catch (error) {
    console.error('Error reading activity:', error);
    res.status(500).json({ error: 'Failed to read activity' });
  }
});

// Suspend an agent (save session ID, kill tmux)
app.post('/api/agents/:id/suspend', async (req, res) => {
  const { id } = req.params;
  const { sessionId } = req.body;

  try {
    // Get current session ID from API call or try to read from hook state
    const effectiveSessionId = sessionId || getSessionId(id);

    if (!effectiveSessionId) {
      return res.status(400).json({ error: 'Session ID required for suspend' });
    }

    // Save session ID for later resume
    saveSessionId(id, effectiveSessionId);

    // Kill tmux session
    await execAsync(`tmux kill-session -t "${id}" 2>/dev/null || true`);

    // Update state
    saveAgentRuntimeState(id, {
      state: 'suspended',
      suspendedAt: new Date().toISOString(),
      sessionId: effectiveSessionId,
    });

    res.json({ success: true });
  } catch (error) {
    console.error('Error suspending agent:', error);
    res.status(500).json({ error: 'Failed to suspend agent' });
  }
});

// Resume a suspended agent
app.post('/api/agents/:id/resume', async (req, res) => {
  const { id } = req.params;
  const { message } = req.body; // Optional message to send after resume

  try {
    const result = await resumeAgent(id, message);

    if (result.success) {
      res.json({ success: true });
    } else {
      res.status(400).json({ error: result.error });
    }
  } catch (error) {
    console.error('Error resuming agent:', error);
    res.status(500).json({ error: 'Failed to resume agent' });
  }
});

// Get agent health status (ASYNC - doesn't block event loop)
app.get('/api/health/agents', async (_req, res) => {
  try {
    const agentsDir = join(homedir(), '.panopticon', 'agents');
    if (!existsSync(agentsDir)) {
      return res.json([]);
    }

    const agentNames = readdirSync(agentsDir).filter((name) =>
      name.startsWith('agent-') || name.startsWith('planning-')
    );

    // Process agents in parallel to avoid blocking
    const agents = await Promise.all(
      agentNames.map(async (name) => {
        const stateFile = join(agentsDir, name, 'state.json');
        const healthFile = join(agentsDir, name, 'health.json');

        // Get stored health info
        let storedHealth = {
          consecutiveFailures: 0,
          killCount: 0,
        };
        if (existsSync(healthFile)) {
          try {
            storedHealth = { ...storedHealth, ...JSON.parse(readFileSync(healthFile, 'utf-8')) };
          } catch {}
        }

        // Check live status (ASYNC)
        const healthStatus = await determineHealthStatusAsync(name, stateFile);

        // Filter out agents that should be hidden (completed/stopped)
        if (!healthStatus) {
          return null;
        }

        return {
          agentId: name,
          status: healthStatus.status,
          reason: healthStatus.reason,
          lastPing: new Date().toISOString(),
          consecutiveFailures: storedHealth.consecutiveFailures,
          killCount: storedHealth.killCount,
        };
      })
    );

    // Filter out null results (hidden agents)
    const visibleAgents = agents.filter((agent) => agent !== null);

    res.json(visibleAgents);
  } catch (error) {
    console.error('Error fetching health:', error);
    res.json([]);
  }
});

// Ping an agent to check if it's responsive (ASYNC)
app.post('/api/health/agents/:id/ping', async (req, res) => {
  const { id } = req.params;
  const health = await checkAgentHealthAsync(id);

  if (!health.alive) {
    return res.json({ success: false, status: 'dead' });
  }

  // Update last ping time in state file
  const stateFile = join(homedir(), '.panopticon', 'agents', id, 'state.json');
  if (existsSync(stateFile)) {
    try {
      const state = JSON.parse(readFileSync(stateFile, 'utf-8'));
      state.lastPing = new Date().toISOString();
      require('fs').writeFileSync(stateFile, JSON.stringify(state, null, 2));
    } catch {}
  }

  res.json({ success: true, status: 'healthy', hasOutput: !!health.lastOutput });
});

// ============== Cloister API ==============

// Get Cloister status
app.get('/api/cloister/status', (_req, res) => {
  try {
    const service = getCloisterService();
    const status = service.getStatus();
    res.json(status);
  } catch (error: any) {
    console.error('Error getting Cloister status:', error);
    res.status(500).json({ error: 'Failed to get Cloister status: ' + error.message });
  }
});

// Start Cloister
app.post('/api/cloister/start', async (_req, res) => {
  try {
    const service = getCloisterService();
    await service.start();
    res.json({ success: true, message: 'Cloister started' });
  } catch (error: any) {
    console.error('Error starting Cloister:', error);
    res.status(500).json({ error: 'Failed to start Cloister: ' + error.message });
  }
});

// Stop Cloister (monitoring only, does NOT kill agents)
app.post('/api/cloister/stop', (_req, res) => {
  try {
    const service = getCloisterService();
    service.stop();
    res.json({ success: true, message: 'Cloister stopped (agents still running)' });
  } catch (error: any) {
    console.error('Error stopping Cloister:', error);
    res.status(500).json({ error: 'Failed to stop Cloister: ' + error.message });
  }
});

// Emergency stop - kill ALL agents
app.post('/api/cloister/emergency-stop', (_req, res) => {
  try {
    const service = getCloisterService();
    const killedAgents = service.emergencyStop();
    res.json({
      success: true,
      message: 'Emergency stop executed',
      killedAgents,
    });
  } catch (error: any) {
    console.error('Error executing emergency stop:', error);
    res.status(500).json({ error: 'Failed to execute emergency stop: ' + error.message });
  }
});

// Resume spawns after mass death (PAN-33)
app.post('/api/cloister/resume-spawns', (_req, res) => {
  try {
    const service = getCloisterService();
    service.resumeSpawns();
    res.json({ success: true, message: 'Agent spawns resumed' });
  } catch (error: any) {
    console.error('Error resuming spawns:', error);
    res.status(500).json({ error: 'Failed to resume spawns: ' + error.message });
  }
});

// Check if spawns are paused (PAN-33)
app.get('/api/cloister/spawn-status', (_req, res) => {
  try {
    const service = getCloisterService();
    const isPaused = service.isSpawnPaused();
    res.json({ spawnsPaused: isPaused });
  } catch (error: any) {
    console.error('Error checking spawn status:', error);
    res.status(500).json({ error: 'Failed to check spawn status: ' + error.message });
  }
});

// Get Cloister configuration
app.get('/api/cloister/config', (_req, res) => {
  try {
    const config = loadCloisterConfig();
    res.json(config);
  } catch (error: any) {
    console.error('Error loading Cloister config:', error);
    res.status(500).json({ error: 'Failed to load Cloister config: ' + error.message });
  }
});

// Update Cloister configuration
app.put('/api/cloister/config', (req, res) => {
  try {
    const updates = req.body;
    const service = getCloisterService();

    // Save configuration
    saveCloisterConfig(updates);

    // Reload service configuration
    service.reloadConfig();

    res.json({ success: true, config: updates });
  } catch (error: any) {
    console.error('Error updating Cloister config:', error);
    res.status(500).json({ error: 'Failed to update Cloister config: ' + error.message });
  }
});

// ============================================================================
// Deacon API Endpoints (PAN-33 Phase 6 - Specialist Health Monitor)
// ============================================================================

// Get deacon status
app.get('/api/deacon/status', (_req, res) => {
  try {
    const service = getCloisterService();
    const status = service.getDeaconStatus();
    res.json(status);
  } catch (error: any) {
    console.error('Error getting deacon status:', error);
    res.status(500).json({ error: 'Failed to get deacon status: ' + error.message });
  }
});

// Run manual patrol
app.post('/api/deacon/patrol', async (_req, res) => {
  try {
    const service = getCloisterService();
    const result = await service.runDeaconPatrol();
    res.json(result);
  } catch (error: any) {
    console.error('Error running deacon patrol:', error);
    res.status(500).json({ error: 'Failed to run patrol: ' + error.message });
  }
});

// ============================================================================
// Metrics API Endpoints (PAN-33 Phase 6)
// ============================================================================

// Get metrics summary
app.get('/api/metrics/summary', (_req, res) => {
  try {
    const service = getCloisterService();
    const costSummary = service.getCostSummary();
    const status = service.getStatus();

    res.json({
      today: {
        totalCost: costSummary.dailyTotal,
        agentCount: status.summary.total,
        activeCount: status.summary.active,
        stuckCount: status.summary.stuck,
        warningCount: status.summary.warning,
      },
      topSpenders: {
        agents: costSummary.topAgents.slice(0, 5),
        issues: costSummary.topIssues.slice(0, 5),
      },
    });
  } catch (error: any) {
    console.error('Error getting metrics summary:', error);
    res.status(500).json({ error: 'Failed to get metrics summary: ' + error.message });
  }
});

// Get cost metrics (date range)
app.get('/api/metrics/costs', (_req, res) => {
  try {
    const service = getCloisterService();
    const costSummary = service.getCostSummary();

    res.json({
      dailyTotal: costSummary.dailyTotal,
      topAgents: costSummary.topAgents,
      topIssues: costSummary.topIssues,
    });
  } catch (error: any) {
    console.error('Error getting cost metrics:', error);
    res.status(500).json({ error: 'Failed to get cost metrics: ' + error.message });
  }
});

// Get handoff metrics
app.get('/api/metrics/handoffs', (_req, res) => {
  try {
    // Placeholder - would need handoff stats from handoff-logger
    res.json({
      totalHandoffs: 0,
      successRate: 0,
      byType: {},
    });
  } catch (error: any) {
    console.error('Error getting handoff metrics:', error);
    res.status(500).json({ error: 'Failed to get handoff metrics: ' + error.message });
  }
});

// Get stuck agent incidents
app.get('/api/metrics/stuck', (_req, res) => {
  try {
    const service = getCloisterService();
    const status = service.getStatus();

    res.json({
      current: status.summary.stuck,
      incidents: [], // Placeholder - would need historical tracking
    });
  } catch (error: any) {
    console.error('Error getting stuck agent metrics:', error);
    res.status(500).json({ error: 'Failed to get stuck agent metrics: ' + error.message });
  }
});

// ============================================================================
// Confirmation Dialog System (PAN-33)
// ============================================================================

/**
 * In-memory store for pending confirmation requests.
 * In the future, this could be enhanced with tmux output polling to automatically
 * detect confirmation prompts from agents.
 */
interface ConfirmationRequest {
  id: string;
  agentId: string;
  sessionName: string;
  action: string;
  details?: string;
  timestamp: string;
}

const pendingConfirmations = new Map<string, ConfirmationRequest>();

// Get pending confirmation requests
app.get('/api/confirmations', (_req, res) => {
  res.json(Array.from(pendingConfirmations.values()));
});

// Respond to a confirmation request
app.post('/api/confirmations/:id/respond', async (req, res) => {
  const { id } = req.params;
  const { confirmed } = req.body;

  const request = pendingConfirmations.get(id);
  if (!request) {
    return res.status(404).json({ error: 'Confirmation request not found' });
  }

  try {
    // Send response to the agent's tmux session
    const response = confirmed ? 'y' : 'n';
    await execAsync(`tmux send-keys -t "${request.sessionName}" '${response}'`, { encoding: 'utf-8' });
    await new Promise(resolve => setTimeout(resolve, 100));
    await execAsync(`tmux send-keys -t "${request.sessionName}" C-m`, { encoding: 'utf-8' });

    // Remove from pending
    pendingConfirmations.delete(id);

    res.json({ success: true, confirmed });
  } catch (error: any) {
    console.error('Error sending confirmation response:', error);
    res.status(500).json({ error: 'Failed to send response: ' + error.message });
  }
});

// ============================================================================
// Specialist Agent Endpoints (PAN-27)
// ============================================================================

// Get all specialists with status
app.get('/api/specialists', async (_req, res) => {
  try {
    const { getAllSpecialistStatus } = await import('../../lib/cloister/specialists.js');
    const specialists = await getAllSpecialistStatus();
    res.json(specialists);
  } catch (error: any) {
    console.error('Error getting specialists:', error);
    res.status(500).json({ error: 'Failed to get specialists: ' + error.message });
  }
});

// Wake a specialist agent
app.post('/api/specialists/:name/wake', async (req, res) => {
  const { name } = req.params;
  const { sessionId } = req.body;

  try {
    const {
      getTmuxSessionName,
      getSessionId,
      recordWake,
      isRunning
    } = await import('../../lib/cloister/specialists.js');

    // Check if already running
    if (await isRunning(name as any)) {
      return res.status(400).json({ error: `Specialist ${name} is already running` });
    }

    const existingSessionId = getSessionId(name as any);
    const tmuxSession = getTmuxSessionName(name as any);

    if (!existingSessionId && !sessionId) {
      return res.status(400).json({
        error: 'No session ID found. Specialist must be initialized first or provide sessionId in request.'
      });
    }

    const useSessionId = sessionId || existingSessionId;

    // Spawn Claude Code with resume flag in tmux
    const cwd = homedir();
    await execAsync(
      `tmux new-session -d -s "${tmuxSession}" -c "${cwd}" "claude --resume ${useSessionId}"`,
      { encoding: 'utf-8' }
    );

    // Record wake event
    recordWake(name as any, useSessionId);

    res.json({
      success: true,
      message: `Specialist ${name} woken up`,
      tmuxSession,
      sessionId: useSessionId,
    });
  } catch (error: any) {
    console.error('Error waking specialist:', error);
    res.status(500).json({ error: 'Failed to wake specialist: ' + error.message });
  }
});

// Reset all specialist agents (kills running ones first)
// NOTE: Must come BEFORE :name/reset to avoid matching "reset-all" as a name
app.post('/api/specialists/reset-all', async (_req, res) => {
  try {
    const {
      getAllSpecialists,
      clearSessionId,
      isRunning,
      getTmuxSessionName
    } = await import('../../lib/cloister/specialists.js');
    const { clearHook } = await import('../../lib/hooks.js');

    const specialists = getAllSpecialists();
    const results: { name: string; killed: boolean; sessionCleared: boolean; queueCleared: boolean }[] = [];

    for (const specialist of specialists) {
      const name = specialist.name;
      let killed = false;

      // Kill if running
      if (isRunning(name)) {
        const tmuxSession = getTmuxSessionName(name);
        try {
          await execAsync(`tmux kill-session -t "${tmuxSession}"`);
          killed = true;
        } catch {
          // Session might not exist, continue
        }
      }

      // Clear session file
      const sessionCleared = clearSessionId(name);

      // Clear queue
      clearHook(name);

      results.push({ name, killed, sessionCleared, queueCleared: true });
    }

    // Reset any "reviewing" statuses to "pending"
    let reviewStatusesReset = 0;
    if (existsSync(REVIEW_STATUS_FILE)) {
      try {
        const statuses = JSON.parse(readFileSync(REVIEW_STATUS_FILE, 'utf-8'));
        for (const key of Object.keys(statuses)) {
          if (statuses[key].reviewStatus === 'reviewing') {
            statuses[key].reviewStatus = 'pending';
            statuses[key].updatedAt = new Date().toISOString();
            reviewStatusesReset++;
          }
        }
        if (reviewStatusesReset > 0) {
          writeFileSync(REVIEW_STATUS_FILE, JSON.stringify(statuses, null, 2));
        }
      } catch (e) {
        console.error('Failed to reset review statuses:', e);
      }
    }

    res.json({
      success: true,
      message: `Reset ${results.length} specialists, cleared queues, reset ${reviewStatusesReset} review statuses`,
      results,
      reviewStatusesReset,
    });
  } catch (error: any) {
    console.error('Error resetting all specialists:', error);
    res.status(500).json({ error: 'Failed to reset specialists: ' + error.message });
  }
});

// Reset a specialist agent (clear session)
app.post('/api/specialists/:name/reset', async (req, res) => {
  const { name } = req.params;
  const { reinitialize = false } = req.body;

  try {
    const {
      clearSessionId,
      isRunning,
      getTmuxSessionName
    } = await import('../../lib/cloister/specialists.js');

    // Check if running - must be stopped first
    if (await isRunning(name as any)) {
      const tmuxSession = getTmuxSessionName(name as any);
      return res.status(400).json({
        error: `Specialist ${name} is currently running. Stop it first (tmux kill-session -t ${tmuxSession})`
      });
    }

    // Clear session file
    const wasDeleted = clearSessionId(name as any);

    if (reinitialize) {
      // TODO: Add initialization logic if needed
      // For now, just clearing is sufficient
    }

    res.json({
      success: true,
      message: `Specialist ${name} reset`,
      sessionCleared: wasDeleted,
    });
  } catch (error: any) {
    console.error('Error resetting specialist:', error);
    res.status(500).json({ error: 'Failed to reset specialist: ' + error.message });
  }
});

// Initialize a specialist agent (first-time setup)
app.post('/api/specialists/:name/init', async (req, res) => {
  const { name } = req.params;

  try {
    const { initializeSpecialist } = await import('../../lib/cloister/specialists.js');

    const result = await initializeSpecialist(name as any);

    if (!result.success) {
      return res.status(400).json({ error: result.message });
    }

    res.json({
      success: true,
      message: result.message,
      tmuxSession: result.tmuxSession,
      note: 'Session ID will be available after Claude responds. Use "claude config get sessionId" in the tmux session to get it, then update via /reset with reinitialize.'
    });
  } catch (error: any) {
    console.error('Error initializing specialist:', error);
    res.status(500).json({ error: 'Failed to initialize specialist: ' + error.message });
  }
});

// Specialist reports status (PAN-80 - replaces terminal parsing)
app.post('/api/specialists/:name/report-status', async (req, res) => {
  const { name } = req.params;
  const { issueId, status, notes } = req.body;

  if (!issueId || !status) {
    return res.status(400).json({ error: 'issueId and status required' });
  }

  if (!['passed', 'blocked', 'failed', 'in-progress'].includes(status)) {
    return res.status(400).json({ error: 'status must be: passed, blocked, failed, or in-progress' });
  }

  try {
    // Write status to specialist's state directory
    const specialistDir = join(homedir(), '.panopticon', 'specialists', name);
    mkdirSync(specialistDir, { recursive: true });

    const statusFile = join(specialistDir, `${issueId}-status.json`);
    const statusData = {
      issueId,
      specialist: name,
      status,
      notes: notes || '',
      timestamp: new Date().toISOString(),
    };

    writeFileSync(statusFile, JSON.stringify(statusData, null, 2));

    console.log(`[specialists] ${name} reported status for ${issueId}: ${status}`);

    // When specialist reports completion (passed/blocked/failed), set state to idle
    if (['passed', 'blocked', 'failed'].includes(status)) {
      const { getTmuxSessionName } = await import('../../lib/cloister/specialists.js');
      const tmuxSession = getTmuxSessionName(name as any);
      saveAgentRuntimeState(tmuxSession, {
        state: 'idle',
        lastActivity: new Date().toISOString(),
      });
    }

    res.json({ success: true });
  } catch (error: unknown) {
    console.error('Error saving specialist status:', error);
    const message = error instanceof Error ? error.message : 'Unknown error';
    res.status(500).json({ error: 'Failed to save status: ' + message });
  }
});

// Get specialist cost
app.get('/api/specialists/:name/cost', async (req, res) => {
  const { name } = req.params;

  try {
    const { getSessionId } = await import('../../lib/cloister/specialists.js');
    const sessionId = getSessionId(name as any);

    if (!sessionId) {
      return res.json({ cost: 0, inputTokens: 0, outputTokens: 0 });
    }

    // Find the JSONL session file
    const homeDir = process.env.HOME || '/home/eltmon';
    const claudeProjectsDir = join(homeDir, '.claude', 'projects');

    // Specialists run from home directory, so the project dir is just the home dir
    const projectDirName = `-${homeDir.replace(/^\//, '').replace(/\//g, '-')}`;
    const projectDir = join(claudeProjectsDir, projectDirName);
    const sessionsIndexPath = join(projectDir, 'sessions-index.json');

    let cost = 0;
    let inputTokens = 0;
    let outputTokens = 0;
    let cacheReadTokens = 0;
    let cacheWriteTokens = 0;
    let detectedModel = '';

    if (existsSync(sessionsIndexPath)) {
      const indexContent = JSON.parse(readFileSync(sessionsIndexPath, 'utf-8'));
      const sessionEntry = indexContent.entries?.find((e: any) => e.sessionId === sessionId);

      if (sessionEntry?.fullPath && existsSync(sessionEntry.fullPath)) {
        const jsonlContent = readFileSync(sessionEntry.fullPath, 'utf-8');
        const lines = jsonlContent.split('\n').filter((l: string) => l.trim());

        for (const line of lines) {
          try {
            const entry = JSON.parse(line);
            // Extract usage from message.usage or top-level usage
            const usage = entry.message?.usage || entry.usage;
            const model = entry.message?.model || entry.model;

            if (usage) {
              inputTokens += usage.input_tokens || 0;
              outputTokens += usage.output_tokens || 0;
              cacheReadTokens += usage.cache_read_input_tokens || 0;
              cacheWriteTokens += usage.cache_creation_input_tokens || 0;
            }
            // Track the model being used
            if (model && !detectedModel) {
              detectedModel = model;
            }
          } catch {
            // Skip malformed lines
          }
        }
      }
    }

    // Calculate cost from usage using pricing data
    if (inputTokens > 0 || outputTokens > 0) {
      const modelInfo = normalizeModelName(detectedModel || 'claude-sonnet-4');
      const pricing = getPricing(modelInfo.provider, modelInfo.model);
      if (pricing) {
        const usage: TokenUsage = {
          inputTokens,
          outputTokens,
          cacheReadTokens,
          cacheWriteTokens,
        };
        cost = calculateCost(usage, pricing);
      }
    }

    res.json({ cost, inputTokens, outputTokens, cacheReadTokens, cacheWriteTokens, model: detectedModel });
  } catch (error: any) {
    console.error('Error getting specialist cost:', error);
    res.json({ cost: 0, inputTokens: 0, outputTokens: 0 });
  }
});

// ============================================================================
// Specialist Queue Management (PAN-74)
// ============================================================================

// Get all specialist queues with counts and items
app.get('/api/specialists/queues', async (_req, res) => {
  try {
    const { getAllSpecialists, checkSpecialistQueue } = await import('../../lib/cloister/specialists.js');
    const specialists = getAllSpecialists();

    const queues = await Promise.all(
      specialists.map(async (specialist) => {
        const queue = checkSpecialistQueue(specialist.name);
        return {
          specialistName: specialist.name,
          hasWork: queue.hasWork,
          urgentCount: queue.urgentCount,
          totalCount: queue.items.length,
          items: queue.items,
        };
      })
    );

    res.json({ queues });
  } catch (error: unknown) {
    const msg = error instanceof Error ? error.message : String(error);
    console.error('Error getting specialist queues:', error);
    res.status(500).json({ error: 'Failed to get specialist queues: ' + msg });
  }
});

// Get specific specialist's queue
app.get('/api/specialists/:name/queue', async (req, res) => {
  const { name } = req.params;

  try {
    const { checkSpecialistQueue } = await import('../../lib/cloister/specialists.js');
    type SpecialistType = 'merge-agent' | 'review-agent' | 'test-agent';

    // Validate specialist name
    const validNames: string[] = ['merge-agent', 'review-agent', 'test-agent'];
    if (!validNames.includes(name)) {
      return res.status(400).json({ error: `Invalid specialist name: ${name}` });
    }

    const queue = checkSpecialistQueue(name as SpecialistType);

    res.json({
      specialistName: name,
      hasWork: queue.hasWork,
      urgentCount: queue.urgentCount,
      totalCount: queue.items.length,
      items: queue.items,
    });
  } catch (error: unknown) {
    const msg = error instanceof Error ? error.message : String(error);
    console.error(`Error getting queue for ${name}:`, error);
    res.status(500).json({ error: `Failed to get queue for ${name}: ${msg}` });
  }
});

// Queue work to a specialist (uses wakeSpecialistOrQueue - handles busy specialists)
app.post('/api/specialists/:name/queue', async (req, res) => {
  const { name } = req.params;
  const { issueId, workspace, branch, customPrompt, priority = 'normal' } = req.body;

  try {
    const { wakeSpecialistOrQueue } = await import('../../lib/cloister/specialists.js');
    type SpecialistType = 'merge-agent' | 'review-agent' | 'test-agent';

    // Validate specialist name
    const validNames: string[] = ['merge-agent', 'review-agent', 'test-agent'];
    if (!validNames.includes(name)) {
      return res.status(400).json({ error: `Invalid specialist name: ${name}` });
    }

    if (!issueId) {
      return res.status(400).json({ error: 'issueId is required' });
    }

    const result = await wakeSpecialistOrQueue(
      name as SpecialistType,
      {
        issueId,
        workspace,
        branch,
        customPrompt,
      },
      {
        priority: priority as 'urgent' | 'normal' | 'low',
        source: 'api-queue',
      }
    );

    res.json({
      success: true,
      ...result,
    });
  } catch (error: unknown) {
    const msg = error instanceof Error ? error.message : String(error);
    console.error(`Error queuing work to ${name}:`, error);
    res.status(500).json({ error: `Failed to queue work to ${name}: ${msg}` });
  }
});

// Remove item from specialist's queue
app.delete('/api/specialists/:name/queue/:itemId', async (req, res) => {
  const { name, itemId } = req.params;

  try {
    const { completeSpecialistTask } = await import('../../lib/cloister/specialists.js');
    type SpecialistType = 'merge-agent' | 'review-agent' | 'test-agent';

    // Validate specialist name
    const validNames: string[] = ['merge-agent', 'review-agent', 'test-agent'];
    if (!validNames.includes(name)) {
      return res.status(400).json({ error: `Invalid specialist name: ${name}` });
    }

    const success = completeSpecialistTask(name as SpecialistType, itemId);

    if (!success) {
      return res.status(404).json({ error: `Item ${itemId} not found in queue for ${name}` });
    }

    res.json({
      success: true,
      message: `Removed item ${itemId} from ${name}'s queue`,
    });
  } catch (error: unknown) {
    const msg = error instanceof Error ? error.message : String(error);
    console.error(`Error removing item from ${name}'s queue:`, error);
    res.status(500).json({ error: `Failed to remove item: ${msg}` });
  }
});

// Reorder specialist's queue
app.put('/api/specialists/:name/queue/reorder', async (req, res) => {
  const { name } = req.params;
  const { itemIds } = req.body;

  if (!Array.isArray(itemIds)) {
    return res.status(400).json({ error: 'itemIds must be an array' });
  }

  try {
    const { reorderHookItems } = await import('../../lib/hooks.js');

    // Validate specialist name
    const validNames: string[] = ['merge-agent', 'review-agent', 'test-agent'];
    if (!validNames.includes(name)) {
      return res.status(400).json({ error: `Invalid specialist name: ${name}` });
    }

    const success = reorderHookItems(name, itemIds);

    if (!success) {
      return res.status(400).json({ error: 'Failed to reorder queue. Check that all item IDs are valid.' });
    }

    res.json({
      success: true,
      message: `Reordered queue for ${name}`,
    });
  } catch (error: unknown) {
    const msg = error instanceof Error ? error.message : String(error);
    console.error(`Error reordering queue for ${name}:`, error);
    res.status(500).json({ error: `Failed to reorder queue: ${msg}` });
  }
});

// Auto-complete: Hook-triggered specialist completion detection
// Called by specialist-stop-hook when it detects completion patterns in terminal output
app.post('/api/specialists/:name/auto-complete', async (req, res) => {
  const { name } = req.params;
  const { issueId, status } = req.body;

  if (!issueId || !status) {
    return res.status(400).json({ error: 'issueId and status required' });
  }

  console.log(`[specialists] Auto-detected completion for ${name}: ${issueId} -> ${status}`);

  try {
    const {
      getTmuxSessionName,
      completeSpecialistTask,
      getNextSpecialistTask,
      wakeSpecialistWithTask,
      checkSpecialistQueue,
      submitToSpecialistQueue,
    } = await import('../../lib/cloister/specialists.js');

    type SpecialistType = 'merge-agent' | 'review-agent' | 'test-agent';

    // Validate specialist name
    const validNames: string[] = ['merge-agent', 'review-agent', 'test-agent'];
    if (!validNames.includes(name)) {
      return res.status(400).json({ error: `Invalid specialist name: ${name}` });
    }

    const tmuxSession = getTmuxSessionName(name as SpecialistType);

    // Set specialist to idle and clear currentIssue
    saveAgentRuntimeState(tmuxSession, {
      state: 'idle',
      lastActivity: new Date().toISOString(),
      currentIssue: undefined,
    });

    // Update review/test status based on specialist type
    if (name === 'review-agent') {
      setReviewStatus(issueId, {
        reviewStatus: status === 'passed' ? 'passed' : 'blocked',
        reviewNotes: `Auto-detected: ${status}`,
      });

      // If passed, queue test-agent
      if (status === 'passed') {
        // Get workspace info from work agent state
        const workAgentId = `agent-${issueId.toLowerCase()}`;
        const workStateFile = join(homedir(), '.panopticon', 'agents', workAgentId, 'state.json');
        let workspace: string | undefined;
        let branch: string | undefined;

        if (existsSync(workStateFile)) {
          try {
            const workState = JSON.parse(readFileSync(workStateFile, 'utf-8'));
            workspace = workState.workspace;
            branch = workState.branch || `feature/${issueId.toLowerCase()}`;
          } catch {}
        }

        submitToSpecialistQueue('test-agent', {
          priority: 'high',
          source: 'review-agent-auto',
          issueId,
          workspace,
          branch,
        });
        console.log(`[specialists] Queued test-agent for ${issueId} after review passed`);
      }
    } else if (name === 'test-agent') {
      setReviewStatus(issueId, {
        testStatus: status === 'passed' ? 'passed' : 'failed',
        testNotes: `Auto-detected: ${status}`,
      });
    }

    // Clear the current task from queue (if it matches)
    const queueStatus = checkSpecialistQueue(name as SpecialistType);
    for (const item of queueStatus.items) {
      if (item.payload?.issueId?.toUpperCase() === issueId.toUpperCase()) {
        completeSpecialistTask(name as SpecialistType, item.id);
        console.log(`[specialists] Cleared ${issueId} from ${name} queue`);
        break;
      }
    }

    // Check for next queued task and wake if available
    const nextTask = getNextSpecialistTask(name as SpecialistType);
    if (nextTask) {
      console.log(`[specialists] Waking ${name} for next task: ${nextTask.payload.issueId}`);
      await wakeSpecialistWithTask(name as SpecialistType, {
        issueId: nextTask.payload.issueId!,
        workspace: nextTask.payload.context?.workspace,
        branch: nextTask.payload.context?.branch,
      });
      completeSpecialistTask(name as SpecialistType, nextTask.id);
    }

    res.json({
      success: true,
      status,
      issueId,
      nextTaskQueued: !!nextTask,
    });
  } catch (error: unknown) {
    const msg = error instanceof Error ? error.message : String(error);
    console.error(`Error processing auto-complete for ${name}:`, error);
    res.status(500).json({ error: msg });
  }
});

// Get agent health (Cloister-based)
app.get('/api/agents/:id/cloister-health', (req, res) => {
  try {
    const { id } = req.params;
    const service = getCloisterService();
    const health = service.getAgentHealth(id);

    if (!health) {
      return res.status(404).json({ error: 'Agent not found or runtime not available' });
    }

    res.json(health);
  } catch (error: any) {
    console.error('Error getting agent health:', error);
    res.status(500).json({ error: 'Failed to get agent health: ' + error.message });
  }
});

// Get all agents health
app.get('/api/cloister/agents/health', (_req, res) => {
  try {
    const service = getCloisterService();
    const agentHealths = service.getAllAgentHealth();
    res.json({ agents: agentHealths });
  } catch (error: any) {
    console.error('Error getting agents health:', error);
    res.status(500).json({ error: 'Failed to get agents health: ' + error.message });
  }
});

// Get activity log
app.get('/api/activity', (_req, res) => {
  res.json(activities);
});

// Get specific activity
app.get('/api/activity/:id', (req, res) => {
  const activity = activities.find(a => a.id === req.params.id);
  if (!activity) {
    return res.status(404).json({ error: 'Activity not found' });
  }
  res.json(activity);
});

// ============================================================================
// Convoy API Endpoints
// ============================================================================

// List all convoys
app.get('/api/convoys', (_req, res) => {
  try {
    const convoys = listConvoys();
    res.json({ convoys });
  } catch (error: any) {
    console.error('Error listing convoys:', error);
    res.status(500).json({ error: 'Failed to list convoys: ' + error.message });
  }
});

// Get convoy status
app.get('/api/convoys/:id', (req, res) => {
  try {
    const convoy = getConvoyStatus(req.params.id);
    if (!convoy) {
      return res.status(404).json({ error: 'Convoy not found' });
    }
    res.json(convoy);
  } catch (error: any) {
    console.error('Error getting convoy status:', error);
    res.status(500).json({ error: 'Failed to get convoy status: ' + error.message });
  }
});

// Start a new convoy
app.post('/api/convoys/start', async (req, res) => {
  try {
    const { template, context } = req.body;

    if (!template) {
      return res.status(400).json({ error: 'Template name is required' });
    }

    if (!context || !context.projectPath) {
      return res.status(400).json({ error: 'Context with projectPath is required' });
    }

    const convoy = await startConvoy(template, context as ConvoyContext);
    res.json(convoy);
  } catch (error: any) {
    console.error('Error starting convoy:', error);
    res.status(500).json({ error: 'Failed to start convoy: ' + error.message });
  }
});

// Stop a convoy
app.post('/api/convoys/:id/stop', async (req, res) => {
  try {
    await stopConvoy(req.params.id);
    res.json({ success: true, message: 'Convoy stopped' });
  } catch (error: any) {
    console.error('Error stopping convoy:', error);
    res.status(500).json({ error: 'Failed to stop convoy: ' + error.message });
  }
});

// Get convoy output (combined from all agents)
app.get('/api/convoys/:id/output', (req, res) => {
  try {
    const convoy = getConvoyStatus(req.params.id);
    if (!convoy) {
      return res.status(404).json({ error: 'Convoy not found' });
    }

    const outputs: Record<string, string> = {};

    for (const agent of convoy.agents) {
      if (agent.outputFile && existsSync(agent.outputFile)) {
        try {
          outputs[agent.role] = readFileSync(agent.outputFile, 'utf-8');
        } catch (err) {
          outputs[agent.role] = `Error reading output: ${err}`;
        }
      }
    }

    res.json({ outputs });
  } catch (error: any) {
    console.error('Error getting convoy output:', error);
    res.status(500).json({ error: 'Failed to get convoy output: ' + error.message });
  }
});

// ============================================================================
// Handoff API Endpoints (Phase 4)
// ============================================================================

// Get handoff suggestion for an agent
app.get('/api/agents/:id/handoff/suggestion', async (req, res) => {
  try {
    const agentId = req.params.id;
    const agentState = getAgentState(agentId);

    if (!agentState) {
      return res.status(404).json({ error: 'Agent not found' });
    }

    // Get agent health
    const runtime = getRuntimeForAgent(agentId);
    if (!runtime) {
      return res.status(404).json({ error: 'Runtime not found for agent' });
    }

    const health = getAgentHealth(agentId, runtime);

    // Check all triggers
    const triggers = await checkAllTriggers(
      agentId,
      agentState.workspace,
      agentState.issueId,
      agentState.model,
      health,
      loadCloisterConfig()
    );

    if (triggers.length > 0) {
      const trigger = triggers[0];
      return res.json({
        suggested: true,
        trigger: trigger.type,
        currentModel: agentState.model,
        suggestedModel: trigger.suggestedModel,
        reason: trigger.reason,
      });
    }

    res.json({
      suggested: false,
      trigger: null,
      currentModel: agentState.model,
      suggestedModel: null,
      reason: 'No handoff triggers detected',
    });
  } catch (error: any) {
    console.error('Error getting handoff suggestion:', error);
    res.status(500).json({ error: 'Failed to get handoff suggestion: ' + error.message });
  }
});

// Execute handoff for an agent
app.post('/api/agents/:id/handoff', async (req, res) => {
  try {
    const agentId = req.params.id;
    const { toModel, reason } = req.body;

    if (!toModel) {
      return res.status(400).json({ error: 'toModel is required' });
    }

    const result = await performHandoff(agentId, {
      targetModel: toModel,
      reason: reason || 'Manual handoff from dashboard',
    });

    if (result.success) {
      res.json({
        success: true,
        newAgentId: result.newAgentId,
        newSessionId: result.newSessionId,
      });
    } else {
      res.status(500).json({
        success: false,
        error: result.error,
      });
    }
  } catch (error: any) {
    console.error('Error executing handoff:', error);
    res.status(500).json({ error: 'Failed to execute handoff: ' + error.message });
  }
});

// Get handoff history for an issue
app.get('/api/issues/:id/handoffs', (req, res) => {
  try {
    const issueId = req.params.id;
    const handoffs = readIssueHandoffEvents(issueId);
    res.json({ handoffs });
  } catch (error: any) {
    console.error('Error getting issue handoffs:', error);
    res.status(500).json({ error: 'Failed to get issue handoffs: ' + error.message });
  }
});

// Get handoff history for an agent
app.get('/api/agents/:id/handoffs', (req, res) => {
  try {
    const agentId = req.params.id;
    const handoffs = readAgentHandoffEvents(agentId);
    res.json({ handoffs });
  } catch (error: any) {
    console.error('Error getting agent handoffs:', error);
    res.status(500).json({ error: 'Failed to get agent handoffs: ' + error.message });
  }
});

// Get all handoff events
app.get('/api/handoffs', (req, res) => {
  try {
    const limit = req.query.limit ? parseInt(req.query.limit as string) : 50;
    const handoffs = readHandoffEvents(limit);
    res.json({
      handoffs,
      total: handoffs.length,
    });
  } catch (error: any) {
    console.error('Error getting handoffs:', error);
    res.status(500).json({ error: 'Failed to get handoffs: ' + error.message });
  }
});

// Get handoff statistics
app.get('/api/handoffs/stats', (req, res) => {
  try {
    const stats = getHandoffStats();
    res.json(stats);
  } catch (error: any) {
    console.error('Error getting handoff stats:', error);
    res.status(500).json({ error: 'Failed to get handoff stats: ' + error.message });
  }
});

// Get all specialist handoff events
app.get('/api/specialist-handoffs', (req, res) => {
  try {
    const limit = req.query.limit ? parseInt(req.query.limit as string) : 50;
    const handoffs = readSpecialistHandoffs(limit);
    res.json({
      handoffs,
      total: handoffs.length,
    });
  } catch (error: any) {
    console.error('Error getting specialist handoffs:', error);
    res.status(500).json({ error: 'Failed to get specialist handoffs: ' + error.message });
  }
});

// Get specialist handoff statistics
app.get('/api/specialist-handoffs/stats', (req, res) => {
  try {
    const stats = getSpecialistHandoffStats();
    res.json(stats);
  } catch (error: any) {
    console.error('Error getting specialist handoff stats:', error);
    res.status(500).json({ error: 'Failed to get specialist handoff stats: ' + error.message });
  }
});

// Get agent cost - parses actual session JSONL files for accurate cost
app.get('/api/agents/:id/cost', (req, res) => {
  try {
    const agentId = req.params.id;
    const agentState = getAgentState(agentId);

    if (!agentState) {
      return res.status(404).json({ error: 'Agent not found' });
    }

    // Calculate cost from session JSONL files
    let cost = 0;
    let inputTokens = 0;
    let outputTokens = 0;
    let cacheReadTokens = 0;
    let cacheWriteTokens = 0;
    let detectedModel = agentState.model || '';

    // Find the Claude project directory for this agent's workspace
    const homeDir = process.env.HOME || homedir();
    const claudeProjectsDir = join(homeDir, '.claude', 'projects');
    const workspacePath = agentState.workspace;

    if (workspacePath) {
      // Claude uses the workspace path as the project directory hash
      const projectDirName = `-${workspacePath.replace(/^\//, '').replace(/\//g, '-')}`;
      const projectDir = join(claudeProjectsDir, projectDirName);
      const sessionsIndexPath = join(projectDir, 'sessions-index.json');

      if (existsSync(sessionsIndexPath)) {
        try {
          const indexContent = JSON.parse(readFileSync(sessionsIndexPath, 'utf-8'));

          // Parse ALL sessions for this workspace (agent may have multiple sessions)
          for (const sessionEntry of (indexContent.entries || [])) {
            if (sessionEntry?.fullPath && existsSync(sessionEntry.fullPath)) {
              const jsonlContent = readFileSync(sessionEntry.fullPath, 'utf-8');
              const lines = jsonlContent.split('\n').filter((l: string) => l.trim());

              for (const line of lines) {
                try {
                  const entry = JSON.parse(line);
                  // Extract usage from message.usage or top-level usage
                  const usage = entry.message?.usage || entry.usage;
                  const model = entry.message?.model || entry.model;

                  if (usage) {
                    inputTokens += usage.input_tokens || 0;
                    outputTokens += usage.output_tokens || 0;
                    cacheReadTokens += usage.cache_read_input_tokens || 0;
                    cacheWriteTokens += usage.cache_creation_input_tokens || 0;
                  }
                  // Track the model being used
                  if (model && !detectedModel) {
                    detectedModel = model;
                  }
                } catch {
                  // Skip malformed lines
                }
              }
            }
          }
        } catch {
          // Failed to parse sessions index
        }
      }
    }

    // Calculate cost from usage using pricing data
    if (inputTokens > 0 || outputTokens > 0) {
      const modelInfo = normalizeModelName(detectedModel || 'claude-sonnet-4');
      const pricing = getPricing(modelInfo.provider, modelInfo.model);
      if (pricing) {
        const usage: TokenUsage = {
          inputTokens,
          outputTokens,
          cacheReadTokens,
          cacheWriteTokens,
        };
        cost = calculateCost(usage, pricing);
      }
    }

    res.json({
      agentId,
      model: detectedModel || agentState.model,
      tokens: {
        input: inputTokens,
        output: outputTokens,
        cacheRead: cacheReadTokens,
        cacheWrite: cacheWriteTokens,
      },
      cost,
    });
  } catch (error: any) {
    console.error('Error getting agent cost:', error);
    res.status(500).json({ error: 'Failed to get agent cost: ' + error.message });
  }
});

// Get cost summary
app.get('/api/costs/summary', (req, res) => {
  try {
    // TODO: Aggregate costs from all agents
    res.json({
      totalCost: 0,
      byModel: {
        opus: 0,
        sonnet: 0,
        haiku: 0,
      },
      byAgent: {},
      today: 0,
      thisWeek: 0,
    });
  } catch (error: any) {
    console.error('Error getting cost summary:', error);
    res.status(500).json({ error: 'Failed to get cost summary: ' + error.message });
  }
});

// Get container status for workspace
// Get container status (ASYNC - non-blocking)
async function getContainerStatusAsync(issueId: string): Promise<Record<string, { running: boolean; uptime: string | null }>> {
  const issueLower = issueId.toLowerCase();
  const containerMap: Record<string, string[]> = {
    'frontend': ['frontend', 'fe'],
    'api': ['api'],
    'postgres': ['postgres'],
    'redis': ['redis'],
    // Note: 'dev' is a script (./dev), not a container - don't check for it
  };

  // Build all possible container patterns
  // Project names are slugified (e.g., "Mind Your Now" -> "mind-your-now")
  const checks: Array<{ displayName: string; containerName: string }> = [];
  for (const [displayName, suffixes] of Object.entries(containerMap)) {
    for (const suffix of suffixes) {
      checks.push(
        // New naming: ${projectName}-feature-${issueLower}-${suffix}-1
        { displayName, containerName: `mind-your-now-feature-${issueLower}-${suffix}-1` },
        // Legacy naming patterns
        { displayName, containerName: `myn-feature-${issueLower}-${suffix}-1` },
        { displayName, containerName: `feature-${issueLower}-${suffix}-1` },
        { displayName, containerName: `${issueLower}-${suffix}-1` },
      );
    }
  }

  // Run all docker checks in parallel
  // Use 'docker ps' (not -a) to only show RUNNING containers
  // This avoids matching stopped containers with old naming patterns
  const results = await Promise.all(
    checks.map(async ({ displayName, containerName }) => {
      try {
        const { stdout } = await execAsync(
          `docker ps --filter "name=${containerName}" --format "{{.Status}}" 2>/dev/null || echo ""`
        );
        return { displayName, containerName, output: stdout.trim() };
      } catch {
        return { displayName, containerName, output: '' };
      }
    })
  );

  // Process results - first match wins for each display name
  const status: Record<string, { running: boolean; uptime: string | null }> = {};
  for (const displayName of Object.keys(containerMap)) {
    const match = results.find(r => r.displayName === displayName && r.output);
    if (match) {
      // Since we use 'docker ps' (running only), any match is running
      const uptime = match.output.replace(/^Up\s+/, '').split(/\s+/)[0] || null;
      status[displayName] = { running: true, uptime };
    } else {
      status[displayName] = { running: false, uptime: null };
    }
  }

  return status;
}

// Get MR URL for an issue from GitLab (ASYNC - non-blocking)
async function getMrUrlAsync(issueId: string, workspacePath: string): Promise<string | null> {
  try {
    const { stdout } = await execAsync(`glab mr list -A -F json 2>/dev/null || echo "[]"`, {
      cwd: workspacePath,
      maxBuffer: 10 * 1024 * 1024,
    });

    const mrs = JSON.parse(stdout);
    for (const mr of mrs) {
      const branchMatch = mr.source_branch?.match(/feature\/(\w+-\d+)/i);
      if (branchMatch && branchMatch[1].toUpperCase() === issueId.toUpperCase()) {
        return mr.web_url;
      }
    }
  } catch {}

  return null;
}

// Synchronous version for backwards compatibility
async function getMrUrl(issueId: string, workspacePath: string): Promise<string | null> {
  try {
    // Try to get MR from glab
    const { stdout: output } = await execAsync(`glab mr list -A -F json 2>/dev/null || echo "[]"`, {
      encoding: 'utf-8',
      cwd: workspacePath,
      maxBuffer: 10 * 1024 * 1024,
    });

    const mrs = JSON.parse(output);
    for (const mr of mrs) {
      // Match by source branch (e.g., feature/min-609 -> MIN-609)
      const branchMatch = mr.source_branch?.match(/feature\/(\w+-\d+)/i);
      if (branchMatch && branchMatch[1].toUpperCase() === issueId.toUpperCase()) {
        return mr.web_url;
      }
    }
  } catch {}

  return null;
}

// Get git status for sub-repos (ASYNC - non-blocking)
async function getRepoGitStatusAsync(workspacePath: string): Promise<{
  frontend: { branch: string; uncommittedFiles: number; latestCommit: string } | null;
  api: { branch: string; uncommittedFiles: number; latestCommit: string } | null;
}> {
  const result: {
    frontend: { branch: string; uncommittedFiles: number; latestCommit: string } | null;
    api: { branch: string; uncommittedFiles: number; latestCommit: string } | null;
  } = { frontend: null, api: null };

  const repoPaths = [
    { key: 'frontend', paths: ['fe', 'frontend'] },
    { key: 'api', paths: ['api', 'backend'] },
  ];

  // Find which paths exist first (sync but fast)
  const existingRepos: Array<{ key: string; repoDir: string }> = [];
  for (const { key, paths } of repoPaths) {
    for (const subdir of paths) {
      const repoDir = join(workspacePath, subdir);
      if (existsSync(repoDir)) {
        existingRepos.push({ key, repoDir });
        break; // First match wins
      }
    }
  }

  // Run all git commands in parallel for all repos
  const gitResults = await Promise.all(
    existingRepos.map(async ({ key, repoDir }) => {
      try {
        const [branchResult, uncommittedResult, commitResult] = await Promise.all([
          execAsync('git rev-parse --abbrev-ref HEAD 2>/dev/null || echo ""', { cwd: repoDir }),
          execAsync('git status --porcelain 2>/dev/null | wc -l', { cwd: repoDir }),
          execAsync('git log -1 --pretty=format:"%s" 2>/dev/null || echo ""', { cwd: repoDir }),
        ]);
        return {
          key,
          branch: branchResult.stdout.trim(),
          uncommitted: uncommittedResult.stdout.trim(),
          latestCommit: commitResult.stdout.trim(),
        };
      } catch {
        return null;
      }
    })
  );

  for (const gitResult of gitResults) {
    if (gitResult && gitResult.branch) {
      result[gitResult.key as 'frontend' | 'api'] = {
        branch: gitResult.branch,
        uncommittedFiles: parseInt(gitResult.uncommitted, 10) || 0,
        latestCommit: gitResult.latestCommit.slice(0, 60) + (gitResult.latestCommit.length > 60 ? '...' : ''),
      };
    }
  }

  return result;
}

// Get workspace info for an issue (ASYNC - non-blocking for terminal performance)
app.get('/api/workspaces/:issueId', async (req, res) => {
  const { issueId } = req.params;
  const issuePrefix = issueId.split('-')[0];
  const projectPath = getProjectPath(undefined, issuePrefix);
  const issueLower = issueId.toLowerCase();

  // Convert issue ID to workspace path (e.g., MIN-645 -> feature-min-645)
  const workspaceName = `feature-${issueLower}`;
  const workspacePath = join(projectPath, 'workspaces', workspaceName);

  if (!existsSync(workspacePath)) {
    return res.json({ exists: false, issueId });
  }

  // Check if workspace is valid (has git, devcontainer, or CLAUDE.md)
  // MYN monorepo style has .git in subdirs (api/.git, fe/.git), not at root
  const gitFile = join(workspacePath, '.git');
  const apiGit = join(workspacePath, 'api', '.git');
  const feGit = join(workspacePath, 'fe', '.git');
  const srcGit = join(workspacePath, 'src', '.git');
  const devcontainer = join(workspacePath, '.devcontainer');
  const claudeMd = join(workspacePath, 'CLAUDE.md');

  const hasValidStructure = existsSync(gitFile) ||       // Standard git worktree
                            existsSync(apiGit) ||         // MYN monorepo (api subdir)
                            existsSync(feGit) ||          // MYN monorepo (fe subdir)
                            existsSync(srcGit) ||         // Other monorepo patterns
                            existsSync(devcontainer) ||   // Containerized workspace
                            existsSync(claudeMd);         // Panopticon workspace

  if (!hasValidStructure) {
    return res.json({
      exists: true,
      corrupted: true,
      issueId,
      path: workspacePath,
      message: 'Workspace exists but is not a valid git worktree or containerized workspace',
    });
  }

  // Construct service URLs based on workspace naming convention
  const frontendUrl = `https://feature-${issueLower}.myn.test`;
  const apiUrl = `https://api-feature-${issueLower}.myn.test`;

  // Check for WORKSPACE.md to get custom service URLs
  let services: { name: string; url?: string }[] = [];
  const workspaceMd = join(workspacePath, 'WORKSPACE.md');
  const dockerCompose = join(workspacePath, 'docker-compose.yml');

  // Try to extract service URLs from WORKSPACE.md if it exists
  if (existsSync(workspaceMd)) {
    try {
      const content = readFileSync(workspaceMd, 'utf-8');
      // Look for URLs in the format: Frontend: http://... or Backend: http://...
      const urlMatches = content.matchAll(/(\w+):\s*(https?:\/\/[^\s\n]+)/gi);
      for (const match of urlMatches) {
        services.push({ name: match[1], url: match[2] });
      }
    } catch {}
  }

  // If no services from WORKSPACE.md, use constructed URLs
  if (services.length === 0) {
    services = [
      { name: 'Frontend', url: frontendUrl },
      { name: 'API', url: apiUrl },
    ];
  }

  // Check if docker-compose exists (indicates containerized workspace)
  // Look in multiple places: root, .devcontainer (with various naming conventions)
  const devcontainerPath = join(workspacePath, '.devcontainer');
  const hasDocker = existsSync(dockerCompose) ||
                    existsSync(join(workspacePath, 'docker-compose.yml')) ||
                    existsSync(join(workspacePath, 'compose.yaml')) ||
                    existsSync(join(devcontainerPath, 'docker-compose.yml')) ||
                    existsSync(join(devcontainerPath, 'docker-compose.devcontainer.yml')) ||
                    existsSync(join(devcontainerPath, 'compose.yaml')) ||
                    existsSync(join(devcontainerPath, 'compose.infra.yml')) ||
                    existsSync(devcontainerPath); // .devcontainer dir exists = containerized

  // Check if project supports containerization (has new-feature script)
  const canContainerize = !hasDocker && existsSync(join(projectPath, 'infra', 'new-feature'));

  // Run all async operations in parallel to minimize blocking
  const agentSession = `agent-${issueLower}`;
  const [git, repoGit, containers, mrUrl, sessionsResult, paneResult] = await Promise.all([
    getGitStatusAsync(workspacePath),
    getRepoGitStatusAsync(workspacePath),
    hasDocker ? getContainerStatusAsync(issueId) : Promise.resolve(null),
    getMrUrlAsync(issueId, workspacePath),
    execAsync('tmux list-sessions 2>/dev/null || echo ""').catch(() => ({ stdout: '' })),
    execAsync(`tmux capture-pane -t "${agentSession}" -p 2>/dev/null | tail -50`).catch(() => ({ stdout: '' })),
  ]);

  // Check for running agent from async results
  let hasAgent = false;
  let agentSessionId: string | null = null;
  let agentModel: string | undefined;
  let agentModelFull: string | undefined;

  const sessions = sessionsResult.stdout;
  if (sessions.includes(agentSession)) {
    hasAgent = true;
    agentSessionId = agentSession;

    const paneOutput = paneResult.stdout;
    const modelMatch = paneOutput.match(/\[(Opus|Sonnet|Haiku)[^\]]*\]/i);
    agentModel = modelMatch ? modelMatch[1] : undefined;

    // Get full model ID from session files
    if (workspacePath) {
      const fullModel = getActiveSessionModel(workspacePath);
      if (fullModel) {
        agentModelFull = fullModel;
      }
    }
  }

  // Get any pending operation for this issue
  const pendingOperation = getPendingOperation(issueId);

  res.json({
    exists: true,
    issueId,
    path: workspacePath,
    frontendUrl,
    apiUrl,
    mrUrl,
    hasAgent,
    agentSessionId,
    agentModel,
    agentModelFull,
    git,
    repoGit,
    services,
    containers,
    hasDocker,
    canContainerize,
    pendingOperation,
  });
});

// Create workspace (without agent)
app.post('/api/workspaces', (req, res) => {
  const { issueId, projectId } = req.body;

  if (!issueId) {
    return res.status(400).json({ error: 'issueId required' });
  }

  try {
    // Extract prefix from issue ID (e.g., "MIN" from "MIN-645")
    const issuePrefix = issueId.split('-')[0];
    const projectPath = getProjectPath(projectId, issuePrefix);
    const activityId = spawnPanCommand(
      ['workspace', 'create', issueId],
      `Create workspace for ${issueId}`,
      projectPath
    );

    res.json({
      success: true,
      message: `Creating workspace for ${issueId}`,
      activityId,
      projectPath,
    });
  } catch (error: any) {
    console.error('Error creating workspace:', error);
    res.status(500).json({ error: 'Failed to create workspace: ' + error.message });
  }
});

// Preview what would be lost when cleaning a corrupted workspace
// Includes diff analysis against main branch to identify actual changes
app.get('/api/workspaces/:issueId/clean/preview', async (req, res) => {
  const { issueId } = req.params;
  const issuePrefix = issueId.split('-')[0];
  const projectPath = getProjectPath(undefined, issuePrefix);
  const issueLower = issueId.toLowerCase();
  const workspaceName = `feature-${issueLower}`;
  const workspacePath = join(projectPath, 'workspaces', workspaceName);

  try {
    if (!existsSync(workspacePath)) {
      return res.status(404).json({ error: 'Workspace does not exist' });
    }

    // Get list of files (excluding common build artifacts)
    const excludeDirs = ['node_modules', 'target', 'dist', 'build', '.git', '__pycache__', '.cache', '.next', 'coverage'];
    const excludePattern = excludeDirs.map(d => `-name "${d}" -prune`).join(' -o ');

    // Find all files, excluding build artifacts
    const findCmd = `find "${workspacePath}" \\( ${excludePattern} \\) -o -type f -print 2>/dev/null | head -500`;
    const { stdout: filesOutput } = await execAsync(findCmd, { encoding: 'utf-8', maxBuffer: 10 * 1024 * 1024 });
    const files = filesOutput.trim() ? filesOutput.trim().split('\n').map(f => f.replace(workspacePath + '/', '')) : [];

    // Get total size (excluding node_modules etc)
    let totalSize = '0';
    try {
      const duCmd = `du -sh "${workspacePath}" --exclude=node_modules --exclude=target --exclude=dist --exclude=.git 2>/dev/null | cut -f1`;
      const { stdout: sizeOutput } = await execAsync(duCmd, { encoding: 'utf-8', maxBuffer: 10 * 1024 * 1024 });
      totalSize = sizeOutput.trim() || '0';
    } catch {
      totalSize = 'unknown';
    }

    // Categorize files by type
    const codeFiles = files.filter(f => /\.(ts|tsx|js|jsx|java|py|rs|go|rb|php|cs|swift|kt)$/.test(f));
    const configFiles = files.filter(f => /\.(json|yaml|yml|toml|xml|env|md)$/.test(f) || f.includes('config'));
    const otherFiles = files.filter(f => !codeFiles.includes(f) && !configFiles.includes(f));

    // Diff analysis: compare workspace files against main branch
    // This helps identify what's actually been changed vs what would be recreated
    let diffAnalysis: {
      modifiedFiles: string[];
      newFiles: string[];
      unchangedFiles: string[];
      comparedAgainst: string;
      error?: string;
    } = {
      modifiedFiles: [],
      newFiles: [],
      unchangedFiles: [],
      comparedAgainst: 'main',
    };

    try {
      // Detect multi-repo structure (e.g., MYN has separate fe/ and api/ repos)
      const subrepos: { prefix: string; gitRoot: string }[] = [];
      const possibleSubrepos = ['fe', 'api', 'frontend', 'backend', 'web', 'server'];

      for (const subdir of possibleSubrepos) {
        const subdirPath = join(workspacePath, subdir);
        if (existsSync(join(subdirPath, '.git'))) {
          subrepos.push({ prefix: subdir + '/', gitRoot: subdirPath });
        }
      }

      // Also check for main repo git
      let mainGitRoot: string | null = null;
      const possibleRoots = [projectPath, join(projectPath, '..'), workspacePath];
      for (const root of possibleRoots) {
        if (existsSync(join(root, '.git'))) {
          mainGitRoot = root;
          break;
        }
      }

      // Sample up to 100 code files for diff analysis
      const filesToCheck = codeFiles.slice(0, 100);
      const reposUsed: string[] = [];

      for (const file of filesToCheck) {
        const workspaceFilePath = join(workspacePath, file);

        // Find which repo this file belongs to
        let gitRoot: string | null = null;
        let relativePath = file;

        // Check subrepos first
        for (const { prefix, gitRoot: subGitRoot } of subrepos) {
          if (file.startsWith(prefix)) {
            gitRoot = subGitRoot;
            relativePath = file.slice(prefix.length);
            if (!reposUsed.includes(prefix)) reposUsed.push(prefix);
            break;
          }
        }

        // Fall back to main repo
        if (!gitRoot && mainGitRoot) {
          gitRoot = mainGitRoot;
          if (!reposUsed.includes('main')) reposUsed.push('main');
        }

        if (!gitRoot) {
          diffAnalysis.newFiles.push(file);
          continue;
        }

        try {
          // Check if feature branch exists in this repo
          const branchName = `feature/${issueLower}`;
          let compareRef = 'main';
          try {
            await execAsync(`git rev-parse --verify ${branchName} 2>/dev/null`, { cwd: gitRoot, encoding: 'utf-8', maxBuffer: 10 * 1024 * 1024 });
            compareRef = branchName;
          } catch {
            // Try master if main doesn't exist
            try {
              await execAsync(`git rev-parse --verify main 2>/dev/null`, { cwd: gitRoot, encoding: 'utf-8', maxBuffer: 10 * 1024 * 1024 });
            } catch {
              compareRef = 'master';
            }
          }

          // Try to get file content from git
          const { stdout: gitContent } = await execAsync(
            `git show ${compareRef}:${relativePath} 2>/dev/null`,
            { cwd: gitRoot, encoding: 'utf-8', maxBuffer: 10 * 1024 * 1024 }
          );

          // Compare with workspace file
          const workspaceContent = readFileSync(workspaceFilePath, 'utf-8');

          if (gitContent === workspaceContent) {
            diffAnalysis.unchangedFiles.push(file);
          } else {
            diffAnalysis.modifiedFiles.push(file);
          }
        } catch {
          // File doesn't exist in git - it's a new file
          diffAnalysis.newFiles.push(file);
        }
      }

      diffAnalysis.comparedAgainst = reposUsed.length > 0
        ? `${reposUsed.join(', ')} repos (main branch)`
        : 'main';

      if (subrepos.length === 0 && !mainGitRoot) {
        diffAnalysis.error = 'Could not find git repository to compare against';
      }
    } catch (diffError: any) {
      diffAnalysis.error = `Diff analysis failed: ${diffError.message}`;
    }

    res.json({
      workspacePath,
      totalSize,
      fileCount: files.length,
      codeFiles: codeFiles.slice(0, 50),
      configFiles: configFiles.slice(0, 30),
      otherFiles: otherFiles.slice(0, 20),
      hasMore: files.length > 100,
      backupPath: join(projectPath, 'workspaces', `.backup-${workspaceName}-${Date.now()}`),
      // Diff analysis results
      diffAnalysis,
    });
  } catch (error: any) {
    console.error('Error previewing workspace:', error);
    res.status(500).json({ error: 'Failed to preview workspace: ' + error.message });
  }
});

// Clean and recreate a corrupted workspace
app.post('/api/workspaces/:issueId/clean', async (req, res) => {
  const { issueId } = req.params;
  const { createBackup } = req.body || {};
  const issuePrefix = issueId.split('-')[0];
  const projectPath = getProjectPath(undefined, issuePrefix);
  const issueLower = issueId.toLowerCase();
  const workspaceName = `feature-${issueLower}`;
  const workspacePath = join(projectPath, 'workspaces', workspaceName);

  try {
    // Check if workspace exists
    if (!existsSync(workspacePath)) {
      return res.status(404).json({ error: 'Workspace does not exist' });
    }

    let backupPath: string | null = null;

    // Create backup if requested
    if (createBackup) {
      backupPath = join(projectPath, 'workspaces', `.backup-${workspaceName}-${Date.now()}`);
      console.log(`Creating backup: ${workspacePath} -> ${backupPath}`);

      // Copy workspace to backup (excluding node_modules, target, etc. to save space)
      await execAsync(
        `rsync -a --quiet --exclude=node_modules --exclude=target --exclude=dist --exclude=.git --exclude=__pycache__ --exclude=.cache --exclude=.next --exclude=coverage "${workspacePath}/" "${backupPath}/"`,
        { encoding: 'utf-8', maxBuffer: 50 * 1024 * 1024 }
      );
    }

    // Remove the corrupted workspace directory
    // If regular rm fails (files owned by root from Docker), use Docker to clean up
    console.log(`Removing corrupted workspace: ${workspacePath}`);
    try {
      await execAsync(`rm -rf "${workspacePath}"`, { encoding: 'utf-8', maxBuffer: 50 * 1024 * 1024 });
    } catch (rmError: any) {
      console.log('Regular rm failed, using Docker to clean up root-owned files...');
      // Use Alpine container to remove contents as root inside Docker (no sudo needed on host)
      // Note: Can't remove /cleanup itself (mount point), so remove contents then rmdir from host
      await execAsync(
        `docker run --rm -v "${workspacePath}:/cleanup" alpine sh -c "rm -rf /cleanup/* /cleanup/.[!.]* /cleanup/..?* 2>/dev/null || true"`,
        { encoding: 'utf-8', maxBuffer: 50 * 1024 * 1024 }
      );
      // Now remove the empty directory from host
      await execAsync(`rmdir "${workspacePath}"`, { encoding: 'utf-8' });
    }

    // Create fresh workspace using pan command
    const activityId = spawnPanCommand(
      ['workspace', 'create', issueId],
      `Recreate workspace for ${issueId}`,
      projectPath
    );

    res.json({
      success: true,
      message: createBackup
        ? `Backed up to ${backupPath} and recreating workspace for ${issueId}`
        : `Cleaned corrupted workspace and recreating for ${issueId}`,
      activityId,
      projectPath,
      backupPath,
    });
  } catch (error: any) {
    console.error('Error cleaning workspace:', error);
    res.status(500).json({ error: 'Failed to clean workspace: ' + error.message });
  }
});

// Containerize an existing workspace (runs project's new-feature script)
app.post('/api/workspaces/:issueId/containerize', async (req, res) => {
  const { issueId } = req.params;
  const issuePrefix = issueId.split('-')[0];
  const projectPath = getProjectPath(undefined, issuePrefix);
  const issueLower = issueId.toLowerCase();

  // Check if new-feature script exists
  const newFeatureScript = join(projectPath, 'infra', 'new-feature');
  if (!existsSync(newFeatureScript)) {
    return res.status(400).json({
      error: 'Project does not support containerization (no infra/new-feature script)',
    });
  }

  // Check if already containerized
  const workspaceName = `feature-${issueLower}`;
  const workspacePath = join(projectPath, 'workspaces', workspaceName);
  if (existsSync(join(workspacePath, '.devcontainer'))) {
    return res.status(400).json({
      error: 'Workspace is already containerized',
    });
  }

  // Check if Docker is running (required for containerization)
  try {
    await execAsync('docker info >/dev/null 2>&1', { encoding: 'utf-8' });
  } catch {
    return res.status(400).json({
      error: 'Docker is not running. Start Docker Desktop first.',
    });
  }

  try {
    // First, remove the git-only workspace if it exists
    // The new-feature script will create a proper containerized one
    if (existsSync(workspacePath)) {
      // Run pan workspace destroy first to clean up the git worktree
      await execAsync(`pan workspace destroy ${issueId} --force 2>/dev/null || true`, {
        cwd: projectPath,
        encoding: 'utf-8',
      });
    }

    // Run the new-feature script from the infra directory
    // Extract just the issue identifier (e.g., "min-645" from "MIN-645")
    const featureName = issueLower;
    const activityId = Date.now().toString();

    // Add to activity log immediately as running
    logActivity({
      id: activityId,
      timestamp: new Date().toISOString(),
      command: `./new-feature ${featureName}`,
      status: 'running',
      output: [],
    });

    // Spawn the new-feature script
    const child = spawn('./new-feature', [featureName], {
      cwd: join(projectPath, 'infra'),
      detached: true,
      stdio: ['ignore', 'pipe', 'pipe'],
    });

    child.stdout?.on('data', (data) => {
      data.toString().split('\n').filter(Boolean).forEach((line: string) => {
        appendActivityOutput(activityId, line);
      });
    });
    child.stderr?.on('data', (data) => {
      data.toString().split('\n').filter(Boolean).forEach((line: string) => {
        appendActivityOutput(activityId, `[stderr] ${line}`);
      });
    });

    child.on('close', (code) => {
      appendActivityOutput(activityId, `[${new Date().toISOString()}] new-feature exited with code ${code}`);

      if (code === 0) {
        // Now start the containers
        appendActivityOutput(activityId, '');
        appendActivityOutput(activityId, '=== Starting containers ===');

        const workspaceDir = join(projectPath, 'workspaces', `feature-${featureName}`);
        // Pass UID/GID for correct file ownership in containers
        const uid = process.getuid?.() ?? 1000;
        const gid = process.getgid?.() ?? 1000;
        const devUp = spawn('./dev', ['all'], {
          cwd: workspaceDir,
          detached: true,
          stdio: ['ignore', 'pipe', 'pipe'],
          env: { ...process.env, UID: String(uid), GID: String(gid), DOCKER_USER: `${uid}:${gid}` },
        });

        devUp.stdout?.on('data', (data) => {
          data.toString().split('\n').filter(Boolean).forEach((line: string) => {
            appendActivityOutput(activityId, line);
          });
        });
        devUp.stderr?.on('data', (data) => {
          data.toString().split('\n').filter(Boolean).forEach((line: string) => {
            appendActivityOutput(activityId, `[stderr] ${line}`);
          });
        });

        devUp.on('close', (devCode) => {
          appendActivityOutput(activityId, `[${new Date().toISOString()}] ./dev all exited with code ${devCode}`);
          updateActivity(activityId, { status: devCode === 0 ? 'completed' : 'failed' });
        });

        devUp.on('error', (err) => {
          appendActivityOutput(activityId, `[error] ${err.message}`);
          updateActivity(activityId, { status: 'failed' });
        });
      } else {
        updateActivity(activityId, { status: 'failed' });
      }
    });

    child.on('error', (err) => {
      appendActivityOutput(activityId, `[error] ${err.message}`);
      updateActivity(activityId, { status: 'failed' });
    });

    res.json({
      success: true,
      message: `Containerizing workspace for ${issueId}`,
      activityId,
      projectPath,
    });
  } catch (error: any) {
    console.error('Error containerizing workspace:', error);
    res.status(500).json({ error: 'Failed to containerize workspace: ' + error.message });
  }
});

// Start containers for an existing workspace
app.post('/api/workspaces/:issueId/start', async (req, res) => {
  const { issueId } = req.params;
  const issuePrefix = issueId.split('-')[0];
  const projectPath = getProjectPath(undefined, issuePrefix);
  const issueLower = issueId.toLowerCase();
  const workspacePath = join(projectPath, 'workspaces', `feature-${issueLower}`);

  // Check workspace exists
  if (!existsSync(workspacePath)) {
    return res.status(400).json({ error: 'Workspace does not exist' });
  }

  // Check for ./dev script - repair if needed (older workspaces may lack symlink)
  const devScript = join(workspacePath, 'dev');
  const devScriptInContainer = join(workspacePath, '.devcontainer', 'dev');

  if (!existsSync(devScript)) {
    // Try to repair: create symlink if .devcontainer/dev exists
    if (existsSync(devScriptInContainer)) {
      try {
        symlinkSync('.devcontainer/dev', devScript);
        chmodSync(devScriptInContainer, 0o755); // Ensure executable
        console.log(`[workspace/start] Repaired: created ./dev symlink for ${issueId}`);
      } catch (repairErr) {
        return res.status(400).json({
          error: `Workspace has no ./dev script and repair failed: ${repairErr}`
        });
      }
    } else {
      return res.status(400).json({ error: 'Workspace has no ./dev script (checked root and .devcontainer/)' });
    }
  }

  // Repair workspace .env file if needed (older workspaces may lack port assignments)
  // This prevents port conflicts between workspaces
  const envFilePath = join(workspacePath, '.env');
  const teamPrefix = extractTeamPrefix(issueId);
  const projectConfig = teamPrefix ? findProjectByTeam(teamPrefix) : null;

  if (projectConfig?.workspace?.ports && projectConfig?.workspace?.env?.template) {
    const featureFolder = `feature-${issueLower}`;
    let needsRepair = !existsSync(envFilePath);

    // Check if env file is missing required port variables
    if (!needsRepair && existsSync(envFilePath)) {
      const existingEnv = readFileSync(envFilePath, 'utf-8');
      for (const portName of Object.keys(projectConfig.workspace.ports)) {
        const portVar = `${portName.toUpperCase()}_PORT`;
        if (!existingEnv.includes(portVar)) {
          needsRepair = true;
          break;
        }
      }
    }

    if (needsRepair) {
      try {
        // Assign ports from configured ranges
        const placeholders: Record<string, string> = {
          FEATURE_FOLDER: featureFolder,
        };

        for (const [portName, portConfig] of Object.entries(projectConfig.workspace.ports)) {
          const portFile = join(projectPath, `.${portName}-ports`);
          const range = portConfig.range as [number, number];

          // Read existing assignments
          let content = '';
          if (existsSync(portFile)) {
            content = readFileSync(portFile, 'utf-8');
          }

          // Check if already assigned
          const lines = content.split('\n').filter(Boolean);
          let port: number | null = null;
          for (const line of lines) {
            const [folder, p] = line.split(':');
            if (folder === featureFolder) {
              port = parseInt(p, 10);
              break;
            }
          }

          // Find next available port if not assigned
          if (!port) {
            const usedPorts = new Set(lines.map(l => parseInt(l.split(':')[1], 10)));
            for (let p = range[0]; p <= range[1]; p++) {
              if (!usedPorts.has(p)) {
                port = p;
                writeFileSync(portFile, content + (content.endsWith('\n') || !content ? '' : '\n') + `${featureFolder}:${port}\n`);
                break;
              }
            }
          }

          if (port) {
            placeholders[`${portName.toUpperCase()}_PORT`] = String(port);
          }
        }

        // Generate .env content from template
        let envContent = projectConfig.workspace.env.template;
        for (const [key, value] of Object.entries(placeholders)) {
          envContent = envContent.replace(new RegExp(`\\{\\{${key}\\}\\}`, 'g'), value);
        }

        writeFileSync(envFilePath, envContent);
        console.log(`[workspace/start] Repaired: created .env with port assignments for ${issueId}`);
      } catch (envErr) {
        console.warn(`[workspace/start] Could not repair .env for ${issueId}: ${envErr}`);
        // Continue anyway - Docker might still work with defaults
      }
    }
  }

  // Check if Docker is running
  try {
    await execAsync('docker info >/dev/null 2>&1', { encoding: 'utf-8' });
  } catch {
    return res.status(400).json({ error: 'Docker is not running. Start Docker Desktop first.' });
  }

  try {
    const activityId = Date.now().toString();

    logActivity({
      id: activityId,
      timestamp: new Date().toISOString(),
      command: `./dev all (${issueId})`,
      status: 'running',
      output: [],
    });

    // Pass UID/GID to ensure Docker containers create files with correct ownership
    // Projects should use: user: "${UID}:${GID}" in docker-compose.yml
    const uid = process.getuid?.() ?? 1000;
    const gid = process.getgid?.() ?? 1000;

    const child = spawn('./dev', ['all'], {
      cwd: workspacePath,
      detached: true,
      stdio: ['ignore', 'pipe', 'pipe'],
      env: {
        ...process.env,
        UID: String(uid),
        GID: String(gid),
        // Also set DOCKER_USER for compatibility with different docker-compose patterns
        DOCKER_USER: `${uid}:${gid}`,
      },
    });

    child.stdout?.on('data', (data) => {
      data.toString().split('\n').filter(Boolean).forEach((line: string) => {
        appendActivityOutput(activityId, line);
      });
    });
    child.stderr?.on('data', (data) => {
      data.toString().split('\n').filter(Boolean).forEach((line: string) => {
        appendActivityOutput(activityId, `[stderr] ${line}`);
      });
    });

    child.on('close', (code) => {
      appendActivityOutput(activityId, `[${new Date().toISOString()}] ./dev all exited with code ${code}`);
      updateActivity(activityId, { status: code === 0 ? 'completed' : 'failed' });
    });

    child.on('error', (err) => {
      appendActivityOutput(activityId, `[error] ${err.message}`);
      updateActivity(activityId, { status: 'failed' });
    });

    res.json({
      success: true,
      message: `Starting containers for ${issueId}`,
      activityId,
    });
  } catch (error: any) {
    console.error('Error starting containers:', error);
    res.status(500).json({ error: 'Failed to start containers: ' + error.message });
  }
});

// Control individual container (start/stop/restart)
app.post('/api/workspaces/:issueId/containers/:containerName/:action', async (req, res) => {
  const { issueId, containerName, action } = req.params;

  // Validate action
  if (!['start', 'stop', 'restart'].includes(action)) {
    return res.status(400).json({ error: 'Invalid action. Must be start, stop, or restart.' });
  }

  // Find workspace and compose file
  const projectPaths = [
    join(homedir(), 'projects/myn/workspaces', `feature-${issueId.toLowerCase()}`),
    join(homedir(), 'projects/panopticon/workspaces', `feature-${issueId.toLowerCase()}`),
  ];

  let workspacePath: string | null = null;
  let composeFile: string | null = null;

  for (const path of projectPaths) {
    if (existsSync(path)) {
      workspacePath = path;
      // Check for compose file in common locations
      const composePaths = [
        join(path, '.devcontainer/docker-compose.devcontainer.yml'),
        join(path, 'docker-compose.yml'),
        join(path, 'docker-compose.yaml'),
      ];
      for (const cp of composePaths) {
        if (existsSync(cp)) {
          composeFile = cp;
          break;
        }
      }
      break;
    }
  }

  if (!workspacePath) {
    return res.status(404).json({ error: `Workspace not found for ${issueId}` });
  }

  if (!composeFile) {
    return res.status(404).json({ error: `No docker-compose file found in workspace` });
  }

  // Check Docker is running
  try {
    await execAsync('docker info >/dev/null 2>&1', { encoding: 'utf-8' });
  } catch {
    return res.status(400).json({ error: 'Docker is not running. Start Docker Desktop first.' });
  }

  // Map display name to service name(s) - some services have aliases
  const serviceMap: Record<string, string[]> = {
    'frontend': ['fe', 'frontend'],
    'api': ['api'],
    'dev': ['dev'],
    'postgres': ['postgres'],
    'redis': ['redis'],
    'fe': ['fe', 'frontend'],
  };

  const serviceNames = serviceMap[containerName.toLowerCase()] || [containerName.toLowerCase()];

  try {
    // Get the project name from compose
    const { stdout: projectNameOut } = await execAsync(
      `docker compose -f "${composeFile}" config --format json 2>/dev/null | jq -r '.name // empty'`,
      { encoding: 'utf-8' }
    );
    const projectName = projectNameOut.trim();

    // Try each possible service name
    let success = false;
    let lastError = '';

    for (const serviceName of serviceNames) {
      try {
        const cmd = `docker compose -f "${composeFile}" ${projectName ? `--project-name "${projectName}"` : ''} ${action} ${serviceName}`;
        console.log(`[container-control] Running: ${cmd}`);
        await execAsync(cmd, { encoding: 'utf-8', timeout: 30000 });
        success = true;
        console.log(`[container-control] Successfully ${action}ed ${serviceName} for ${issueId}`);
        break;
      } catch (err: any) {
        lastError = err.message || String(err);
        // Continue trying other service names
      }
    }

    if (success) {
      res.json({ success: true, message: `Container ${containerName} ${action}ed successfully` });
    } else {
      res.status(500).json({ error: `Failed to ${action} ${containerName}: ${lastError}` });
    }
  } catch (error: any) {
    console.error(`Error ${action}ing container:`, error);
    res.status(500).json({ error: `Failed to ${action} container: ${error.message}` });
  }
});

// Get review status for a workspace
app.get('/api/workspaces/:issueId/review-status', (req, res) => {
  const { issueId } = req.params;
  const status = getReviewStatus(issueId);
  res.json(status || {
    issueId,
    reviewStatus: 'pending',
    testStatus: 'pending',
    readyForMerge: false,
  });
});

// Update review status (called by specialists via CLI)
app.post('/api/workspaces/:issueId/review-status', async (req, res) => {
  const { issueId } = req.params;
  const { reviewStatus, testStatus, reviewNotes, testNotes } = req.body;

  const update: Partial<ReviewStatus> = {};
  if (reviewStatus) update.reviewStatus = reviewStatus;
  if (testStatus) update.testStatus = testStatus;
  if (reviewNotes) update.reviewNotes = reviewNotes;
  if (testNotes) update.testNotes = testNotes;

  const status = setReviewStatus(issueId, update);
  console.log(`[review-status] Updated ${issueId}:`, status);

  // Set specialist state to idle when they report completion
  // Infer which specialist based on which field was updated
  const { getTmuxSessionName, checkSpecialistQueue, completeSpecialistTask } = await import('../../lib/cloister/specialists.js');

  if (reviewStatus && ['passed', 'blocked', 'failed'].includes(reviewStatus)) {
    const tmuxSession = getTmuxSessionName('review-agent');
    saveAgentRuntimeState(tmuxSession, {
      state: 'idle',
      lastActivity: new Date().toISOString(),
    });
    console.log(`[review-status] Set review-agent to idle`);

    // Clear this issue from review-agent queue (prevents orphaned queue items)
    const queue = checkSpecialistQueue('review-agent');
    for (const item of queue.items) {
      if (item.payload?.issueId?.toLowerCase() === issueId.toLowerCase()) {
        completeSpecialistTask('review-agent', item.id);
        console.log(`[review-status] Cleared ${issueId} from review-agent queue`);
      }
    }

    // Auto-send feedback to work agent when blocked/failed (guarantees delivery)
    if (['blocked', 'failed'].includes(reviewStatus) && reviewNotes) {
      const agentId = `agent-${issueId.toLowerCase()}`;
      try {
        const { sessionExists, sendToTmux } = await import('../../lib/tmux.js');
        if (sessionExists(agentId)) {
          const feedback = `CODE REVIEW ${reviewStatus.toUpperCase()} for ${issueId}:\n\n${reviewNotes}\n\nPlease address these issues and re-request review.`;
          sendToTmux(agentId, feedback);
          console.log(`[review-status] Auto-sent feedback to ${agentId}`);
        } else {
          console.log(`[review-status] Work agent ${agentId} not running, feedback saved to review-status only`);
        }
      } catch (err) {
        console.error(`[review-status] Failed to send feedback to ${agentId}:`, err);
      }
    }

    // Immediately process next queued item (don't wait for deacon patrol)
    const remainingQueue = checkSpecialistQueue('review-agent');
    if (remainingQueue.hasWork) {
      const { getNextSpecialistTask, wakeSpecialistWithTask, completeSpecialistTask: completeTask } = await import('../../lib/cloister/specialists.js');
      const nextTask = getNextSpecialistTask('review-agent');
      if (nextTask) {
        console.log(`[review-status] Immediately waking review-agent for next queued task: ${nextTask.payload.issueId}`);
        const taskDetails = {
          issueId: nextTask.payload.issueId || '',
          branch: nextTask.payload.context?.branch,
          workspace: nextTask.payload.context?.workspace,
        };
        const wakeResult = await wakeSpecialistWithTask('review-agent', taskDetails);
        if (wakeResult.success) {
          completeTask('review-agent', nextTask.id);
          console.log(`[review-status] Review-agent woken for ${nextTask.payload.issueId}`);
        } else {
          console.error(`[review-status] Failed to wake review-agent for next task: ${wakeResult.error}`);
        }
      }
    }
  }

  if (testStatus && ['passed', 'failed', 'skipped'].includes(testStatus)) {
    const tmuxSession = getTmuxSessionName('test-agent');
    saveAgentRuntimeState(tmuxSession, {
      state: 'idle',
      lastActivity: new Date().toISOString(),
    });
    console.log(`[review-status] Set test-agent to idle`);

    // Clear this issue from test-agent queue
    const queue = checkSpecialistQueue('test-agent');
    for (const item of queue.items) {
      if (item.payload?.issueId?.toLowerCase() === issueId.toLowerCase()) {
        completeSpecialistTask('test-agent', item.id);
        console.log(`[review-status] Cleared ${issueId} from test-agent queue`);
      }
    }

    // Auto-send test failure feedback to work agent
    if (testStatus === 'failed' && testNotes) {
      const agentId = `agent-${issueId.toLowerCase()}`;
      try {
        const { sessionExists, sendToTmux } = await import('../../lib/tmux.js');
        if (sessionExists(agentId)) {
          const feedback = `TESTS FAILED for ${issueId}:\n\n${testNotes}\n\nPlease fix the failing tests and re-request review.`;
          sendToTmux(agentId, feedback);
          console.log(`[review-status] Auto-sent test failure to ${agentId}`);
        }
      } catch (err) {
        console.error(`[review-status] Failed to send test feedback to ${agentId}:`, err);
      }
    }

    // Immediately process next queued item for test-agent
    const remainingTestQueue = checkSpecialistQueue('test-agent');
    if (remainingTestQueue.hasWork) {
      const { getNextSpecialistTask, wakeSpecialistWithTask, completeSpecialistTask: completeTask } = await import('../../lib/cloister/specialists.js');
      const nextTask = getNextSpecialistTask('test-agent');
      if (nextTask) {
        console.log(`[review-status] Immediately waking test-agent for next queued task: ${nextTask.payload.issueId}`);
        const taskDetails = {
          issueId: nextTask.payload.issueId || '',
          branch: nextTask.payload.context?.branch,
          workspace: nextTask.payload.context?.workspace,
        };
        const wakeResult = await wakeSpecialistWithTask('test-agent', taskDetails);
        if (wakeResult.success) {
          completeTask('test-agent', nextTask.id);
          console.log(`[review-status] Test-agent woken for ${nextTask.payload.issueId}`);
        } else {
          console.error(`[review-status] Failed to wake test-agent for next task: ${wakeResult.error}`);
        }
      }
    }
  }

  res.json(status);
});

// Specialist completion endpoint
// Allows specialists to signal completion via curl without needing `pan` CLI in PATH
// Usage: curl -X POST http://localhost:3011/api/specialists/done \
//   -H "Content-Type: application/json" \
//   -d '{"specialist":"merge","issueId":"PAN-81","status":"passed","notes":"..."}'
app.post('/api/specialists/done', async (req, res) => {
  const { specialist, issueId, status, notes } = req.body;

  // Validate specialist type
  const validSpecialists = ['review', 'test', 'merge'];
  if (!validSpecialists.includes(specialist)) {
    return res.status(400).json({
      error: `Invalid specialist: ${specialist}. Valid: ${validSpecialists.join(', ')}`,
    });
  }

  // Validate status
  if (!status || !['passed', 'failed'].includes(status)) {
    return res.status(400).json({
      error: `Invalid status: ${status}. Must be 'passed' or 'failed'`,
    });
  }

  // Validate issueId
  if (!issueId) {
    return res.status(400).json({ error: 'issueId is required' });
  }

  const normalizedIssueId = issueId.toUpperCase();
  console.log(`[specialists/done] ${specialist} signaling ${status} for ${normalizedIssueId}`);

  // Build the update based on specialist type
  const update: Partial<ReviewStatus> = {};

  switch (specialist) {
    case 'review':
      update.reviewStatus = status === 'passed' ? 'passed' : 'blocked';
      if (notes) update.reviewNotes = notes;
      break;

    case 'test':
      update.testStatus = status;
      if (notes) update.testNotes = notes;
      break;

    case 'merge':
      update.mergeStatus = status === 'passed' ? 'merged' : 'failed';
      break;
  }

  // Apply the update (this triggers all the side effects like idle state, queue processing)
  const updatedStatus = setReviewStatus(normalizedIssueId, update);

  // Set specialist state to idle
  const { getTmuxSessionName, checkSpecialistQueue, completeSpecialistTask } = await import('../../lib/cloister/specialists.js');
  const tmuxSession = getTmuxSessionName(`${specialist}-agent` as any);
  saveAgentRuntimeState(tmuxSession, {
    state: 'idle',
    lastActivity: new Date().toISOString(),
  });
  console.log(`[specialists/done] Set ${specialist}-agent to idle`);

  // Clear this issue from the specialist's queue
  const queue = checkSpecialistQueue(`${specialist}-agent` as any);
  for (const item of queue.items) {
    if (item.payload?.issueId?.toLowerCase() === normalizedIssueId.toLowerCase()) {
      completeSpecialistTask(`${specialist}-agent` as any, item.id);
      console.log(`[specialists/done] Cleared ${normalizedIssueId} from ${specialist}-agent queue`);
    }
  }

  // Note: readyForMerge is automatically set to false when mergeStatus='merged' in setReviewStatus()

  res.json({
    success: true,
    specialist,
    issueId: normalizedIssueId,
    status,
    notes,
    currentStatus: updatedStatus,
  });
});

// Start review pipeline: triggers review-agent â†’ test-agent
// Does NOT merge - just reviews and tests
app.post('/api/workspaces/:issueId/review', async (req, res) => {
  const { issueId } = req.params;
  const issuePrefix = issueId.split('-')[0];
  const projectPath = getProjectPath(undefined, issuePrefix);
  const issueLower = issueId.toLowerCase();
  const workspacePath = join(projectPath, 'workspaces', `feature-${issueLower}`);
  const branchName = `feature/${issueLower}`;

  // Check if issue was already reviewed with feedback that needs addressing
  const existingStatus = getReviewStatus(issueId);
  if (existingStatus?.reviewNotes && ['blocked', 'failed'].includes(existingStatus.reviewStatus)) {
    // Issue has existing review feedback - don't reset to reviewing
    // Return info about existing review so user knows to address feedback first
    return res.json({
      success: false,
      alreadyReviewed: true,
      message: `Review already completed with status: ${existingStatus.reviewStatus}`,
      reviewNotes: existingStatus.reviewNotes,
      hint: 'Address the review feedback before requesting another review',
    });
  }

  // Mark review as starting (human-initiated: reset autoRequeueCount)
  setPendingOperation(issueId, 'review');
  setReviewStatus(issueId, { reviewStatus: 'reviewing', testStatus: 'pending', autoRequeueCount: 0 });

  try {
    // 1. Check workspace exists
    if (!existsSync(workspacePath)) {
      completePendingOperation(issueId, 'Workspace does not exist');
      setReviewStatus(issueId, { reviewStatus: 'failed', reviewNotes: 'Workspace does not exist' });
      return res.status(400).json({ error: 'Workspace does not exist' });
    }

    // 1b. Update Linear issue to "In Review" status
    const linearApiKey = process.env.LINEAR_API_KEY;
    if (linearApiKey && !issueId.toUpperCase().startsWith('PAN-')) {
      try {
        const getIssueQuery = `
          query GetIssue($id: String!) {
            issue(id: $id) {
              id
              state { id name type }
              team { states { nodes { id name type } } }
            }
          }
        `;
        const issueResponse = await fetch('https://api.linear.app/graphql', {
          method: 'POST',
          headers: { 'Content-Type': 'application/json', 'Authorization': linearApiKey },
          body: JSON.stringify({ query: getIssueQuery, variables: { id: issueId } }),
        });
        const issueJson = await issueResponse.json();
        const states = issueJson.data?.issue?.team?.states?.nodes || [];
        const linearId = issueJson.data?.issue?.id;
        const inReviewState = states.find((s: any) => s.name.toLowerCase() === 'in review' || s.name.toLowerCase() === 'review');

        if (linearId && inReviewState) {
          const updateMutation = `
            mutation UpdateIssue($id: String!, $stateId: String!) {
              issueUpdate(id: $id, input: { stateId: $stateId }) { success }
            }
          `;
          await fetch('https://api.linear.app/graphql', {
            method: 'POST',
            headers: { 'Content-Type': 'application/json', 'Authorization': linearApiKey },
            body: JSON.stringify({ query: updateMutation, variables: { id: linearId, stateId: inReviewState.id } }),
          });
          console.log(`[review] Updated ${issueId} to In Review in Linear`);
        }
      } catch (linearError) {
        console.error('[review] Error updating Linear to In Review:', linearError);
        // Non-fatal - continue with review
      }
    }

    // 2. Push the feature branch to remote first
    try {
      await execAsync(`git push origin ${branchName}`, { cwd: workspacePath, encoding: 'utf-8' });
      console.log(`Pushed ${branchName} to remote`);
    } catch (pushErr: any) {
      console.log(`Feature branch push note: ${pushErr.message}`);
    }

    // 3. Start the review pipeline (review-agent â†’ test-agent)
    // PAN-88: Check if review-agent is busy BEFORE waking
    const { wakeSpecialist, isRunning, getTmuxSessionName, submitToSpecialistQueue } = await import('../../lib/cloister/specialists.js');
    const { getAgentRuntimeState, saveAgentRuntimeState } = await import('../../lib/agents.js');

    const reviewSession = getTmuxSessionName('review-agent');
    const reviewRunning = await isRunning('review-agent');
    const reviewState = getAgentRuntimeState(reviewSession);
    const reviewIdle = reviewState?.state === 'idle' || reviewState?.state === 'suspended' || !reviewRunning;

    // If review-agent is busy, queue this task instead
    if (!reviewIdle) {
      console.log(`[review] review-agent busy, queuing ${issueId}`);
      submitToSpecialistQueue('review-agent', {
        priority: 'normal',
        source: 'review-endpoint',
        issueId,
        workspace: workspacePath,
        branch: branchName,
      });
      completePendingOperation(issueId, null);
      return res.json({
        success: true,
        queued: true,
        message: `Review queued for ${issueId} - review-agent is busy`,
      });
    }

    // Set state to active IMMEDIATELY to prevent concurrent wakes (PAN-88)
    saveAgentRuntimeState(reviewSession, {
      state: 'active',
      lastActivity: new Date().toISOString(),
    });
    console.log(`[review] Marked review-agent active, starting pipeline for ${issueId}...`);

    const reviewPrompt = `STRICT REVIEW for ${issueId}

You are a DEMANDING code reviewer. Find EVERY issue before code can proceed to testing.
DO NOT BE NICE. BE THOROUGH.

=== CONTEXT ===
ISSUE: ${issueId}
WORKSPACE: ${workspacePath}
BRANCH: ${branchName}
PROJECT: ${projectPath}

=== MANDATORY REQUIREMENTS (Block if ANY violated) ===
1. **Tests Required** - Every new function MUST have test files. No exceptions.
2. **No In-Memory Only Storage** - Important data MUST persist to files/DB.
3. **No Dead Code** - Remove unused imports, functions, variables.
4. **Error Handling** - All async operations must handle errors.
5. **Type Safety** - No \`any\` without justification.

=== YOUR TASK ===
1. cd ${workspacePath}
2. Review ALL changes: git diff main...${branchName}
3. Check EVERY file for issues
4. List EVERY issue found with file:line references

**IMPORTANT: DO NOT run tests (npm test). You are the REVIEW agent - you only review code.**
**The TEST agent will run tests in the next step. Just verify test FILES exist.**

=== WHEN DONE ===
**IF ANY ISSUES FOUND:**
- Update status: curl -X POST http://localhost:3011/api/workspaces/${issueId}/review-status -H "Content-Type: application/json" -d '{"reviewStatus":"blocked","reviewNotes":"[list issues]"}'
- Use /send-feedback-to-agent to notify agent-${issueLower}
- DO NOT hand off to test-agent

**IF CODE IS PERFECT:**
- Update status: curl -X POST http://localhost:3011/api/workspaces/${issueId}/review-status -H "Content-Type: application/json" -d '{"reviewStatus":"passed"}'
- Queue test-agent (DO NOT use pan specialists wake directly):

curl -X POST http://localhost:3011/api/specialists/test-agent/queue -H "Content-Type: application/json" -d '{"issueId":"${issueId}","workspace":"${workspacePath}","branch":"${branchName}","customPrompt":"TEST for ${issueId}:\\nWORKSPACE: ${workspacePath}\\nBRANCH: ${branchName}\\n\\n1. cd ${workspacePath}\\n2. Run tests: npm test\\n3. Update status:\\n   - PASS: curl -X POST http://localhost:3011/api/workspaces/${issueId}/review-status -H Content-Type:application/json -d {testStatus:passed}\\n   - FAIL: curl -X POST http://localhost:3011/api/workspaces/${issueId}/review-status -d {testStatus:failed,testNotes:[details]}\\n\\nIMPORTANT: Do NOT hand off to merge-agent. Just update status. Human will click Merge."}'`;

    const reviewResult = await wakeSpecialist('review-agent', reviewPrompt, {
      waitForReady: true,
      startIfNotRunning: true,
    });

    if (!reviewResult.success) {
      console.warn(`[review] review-agent failed to wake: ${reviewResult.message}`);
      completePendingOperation(issueId, `Failed to start review: ${reviewResult.message}`);
      setReviewStatus(issueId, { reviewStatus: 'failed', reviewNotes: reviewResult.message });
      return res.status(500).json({ error: `Failed to start review: ${reviewResult.message}` });
    }

    console.log(`[review] Review pipeline started for ${issueId}`);
    completePendingOperation(issueId, null);

    return res.json({
      success: true,
      message: `Review started for ${issueId}`,
      pipeline: 'review â†’ test',
      note: 'Watch the specialists panel for progress. MERGE button will appear when review+test pass.',
    });

  } catch (error: any) {
    console.error(`[review] Error starting review:`, error);
    completePendingOperation(issueId, error.message);
    setReviewStatus(issueId, { reviewStatus: 'failed', reviewNotes: error.message });
    return res.status(500).json({ error: error.message });
  }
});

// Agent-initiated re-review request with circuit breaker (PAN-90)
// Allows agents to request re-review after fixing feedback, max 3 times
const MAX_AUTO_REQUEUE = 3;

app.post('/api/workspaces/:issueId/request-review', async (req, res) => {
  const { issueId } = req.params;
  const { message } = req.body; // Optional message for reviewers

  const existingStatus = getReviewStatus(issueId);
  const currentCount = existingStatus?.autoRequeueCount || 0;

  // Circuit breaker: max 3 auto-requeues
  if (currentCount >= MAX_AUTO_REQUEUE) {
    console.log(`[request-review] Circuit breaker: ${issueId} exceeded max auto-requeues (${currentCount}/${MAX_AUTO_REQUEUE})`);
    return res.status(429).json({
      success: false,
      error: 'Circuit breaker triggered',
      message: `Maximum automatic re-review requests (${MAX_AUTO_REQUEUE}) exceeded. Human intervention required.`,
      autoRequeueCount: currentCount,
      hint: 'A human must click the Review button to continue.',
    });
  }

  // Check if workspace exists
  const issuePrefix = issueId.split('-')[0];
  const projectPath = getProjectPath(undefined, issuePrefix);
  const issueLower = issueId.toLowerCase();
  const workspacePath = join(projectPath, 'workspaces', `feature-${issueLower}`);
  const branchName = `feature/${issueLower}`;

  if (!existsSync(workspacePath)) {
    return res.status(400).json({
      success: false,
      error: 'Workspace does not exist',
    });
  }

  // Increment counter and queue for review
  const newCount = currentCount + 1;
  const reviewNotes = message ? `Agent re-review request (${newCount}/${MAX_AUTO_REQUEUE}): ${message}` : undefined;

  setReviewStatus(issueId, {
    reviewStatus: 'reviewing',
    testStatus: 'pending',
    autoRequeueCount: newCount,
    reviewNotes,
  });

  console.log(`[request-review] Agent requested re-review for ${issueId} (${newCount}/${MAX_AUTO_REQUEUE})`);

  // Queue for review-agent (same logic as human-initiated review)
  try {
    const { wakeSpecialistOrQueue } = await import('../../lib/cloister/specialists.js');

    const result = await wakeSpecialistOrQueue('review-agent', {
      issueId,
      workspace: workspacePath,
      branch: branchName,
    }, {
      priority: 'normal',
      source: 'agent-request',
    });

    if (result.success) {
      console.log(`[request-review] Queued ${issueId} for review-agent`);
      return res.json({
        success: true,
        queued: result.queued,
        message: result.queued
          ? `Review queued (${newCount}/${MAX_AUTO_REQUEUE} auto-requeues used)`
          : `Review started (${newCount}/${MAX_AUTO_REQUEUE} auto-requeues used)`,
        autoRequeueCount: newCount,
        remainingRequeues: MAX_AUTO_REQUEUE - newCount,
      });
    } else {
      return res.status(500).json({
        success: false,
        error: result.error || 'Failed to queue review',
        autoRequeueCount: newCount,
      });
    }
  } catch (error: any) {
    console.error(`[request-review] Error:`, error);
    return res.status(500).json({
      success: false,
      error: error.message,
      autoRequeueCount: newCount,
    });
  }
});

// Merge workspace: ONLY merges (requires review+test to have passed first)
// SAFETY: Never delete remote branches. Always push before cleanup. Abort on any error.
app.post('/api/workspaces/:issueId/merge', async (req, res) => {
  const { issueId } = req.params;

  // Check review status - must be ready for merge
  const reviewStatus = getReviewStatus(issueId);
  if (!reviewStatus?.readyForMerge) {
    return res.status(400).json({
      error: 'Cannot merge: review and tests have not passed yet',
      reviewStatus: reviewStatus?.reviewStatus || 'pending',
      testStatus: reviewStatus?.testStatus || 'pending',
    });
  }

  // Check if already merging
  if (reviewStatus?.mergeStatus === 'merging') {
    return res.status(400).json({
      error: 'Merge already in progress',
      mergeStatus: 'merging',
    });
  }

  // Check if already merged
  if (reviewStatus?.mergeStatus === 'merged') {
    return res.status(400).json({
      error: 'Already merged',
      mergeStatus: 'merged',
    });
  }

  const issuePrefix = issueId.split('-')[0];
  const projectPath = getProjectPath(undefined, issuePrefix);
  const issueLower = issueId.toLowerCase();
  const workspacePath = join(projectPath, 'workspaces', `feature-${issueLower}`);
  const branchName = `feature/${issueLower}`;

  // Mark merge as in progress
  setReviewStatus(issueId, { mergeStatus: 'merging' });

  // Mark operation as pending
  setPendingOperation(issueId, 'merge');

  try {
    // 1. Check workspace exists
    if (!existsSync(workspacePath)) {
      completePendingOperation(issueId, 'Workspace does not exist');
      return res.status(400).json({ error: 'Workspace does not exist' });
    }

    // 2. Push the feature branch to remote BEFORE merging (preserve work)
    try {
      await execAsync(`git push origin ${branchName}`, { cwd: workspacePath, encoding: 'utf-8' });
      console.log(`Pushed ${branchName} to remote`);
    } catch (pushErr: any) {
      console.log(`Feature branch push note: ${pushErr.message}`);
    }

    // 3. Spawn merge-agent to handle the merge
    const { spawnMergeAgentForBranches } = await import('../../lib/cloister/merge-agent.js');

    console.log(`[merge] Starting merge-agent for ${issueId}...`);

    const mergeResult = await spawnMergeAgentForBranches(
      projectPath,
      branchName,
      'main',
      issueId
    );

    if (mergeResult.success && mergeResult.testsStatus === 'PASS') {
      console.log(`[merge] Successfully merged ${issueId}`);
      clearReviewStatus(issueId); // Clear review status after successful merge
      completePendingOperation(issueId, null);

      // Close the issue after successful merge
      await closeIssueAfterMerge(issueId);

      return res.json({
        success: true,
        message: `Successfully merged ${issueId} to main and closed issue`,
        testsStatus: 'PASS',
      });
    } else if (mergeResult.success) {
      console.log(`[merge] Merged ${issueId} (tests: ${mergeResult.testsStatus})`);
      clearReviewStatus(issueId);
      completePendingOperation(issueId, null);

      // Close the issue after successful merge (even if tests skipped)
      await closeIssueAfterMerge(issueId);

      return res.json({
        success: true,
        message: `Merged ${issueId} to main and closed issue`,
        testsStatus: mergeResult.testsStatus,
        note: mergeResult.testsStatus === 'SKIP' ? 'Tests were skipped' : undefined,
      });
    } else {
      const error = mergeResult.notes || 'Merge failed';
      setReviewStatus(issueId, { mergeStatus: 'failed' });
      completePendingOperation(issueId, error);
      return res.status(500).json({ error, mergeResult });
    }

  } catch (error: any) {
    console.error(`[merge] Error:`, error);
    setReviewStatus(issueId, { mergeStatus: 'failed' });
    completePendingOperation(issueId, error.message);
    return res.status(500).json({ error: error.message });
  }
});

// DEPRECATED: Old approve endpoint - redirects to review flow
// TODO: Remove after frontend is updated
app.post('/api/workspaces/:issueId/approve', async (req, res) => {
  const { issueId } = req.params;
  const issuePrefix = issueId.split('-')[0];
  const projectPath = getProjectPath(undefined, issuePrefix);
  const issueLower = issueId.toLowerCase();
  const workspacePath = join(projectPath, 'workspaces', `feature-${issueLower}`);
  const branchName = `feature/${issueLower}`;

  // Track what we've done for rollback info
  let mergeCompleted = false;
  let pushCompleted = false;

  // Mark operation as pending (persists across refreshes)
  setPendingOperation(issueId, 'approve');

  try {
    // 1. Check workspace exists
    if (!existsSync(workspacePath)) {
      completePendingOperation(issueId, 'Workspace does not exist');
      return res.status(400).json({ error: 'Workspace does not exist' });
    }

    // 2. Verify the feature branch exists
    try {
      await execAsync(`git rev-parse --verify ${branchName}`, { cwd: projectPath, encoding: 'utf-8' });
    } catch {
      completePendingOperation(issueId, `Branch ${branchName} does not exist`);
      return res.status(400).json({ error: `Branch ${branchName} does not exist` });
    }

    // 3. Check for uncommitted changes in workspace before proceeding
    // Use -uno to ignore untracked files - they don't block merges and are often
    // Panopticon-managed symlinks that haven't been added to .gitignore yet
    try {
      const { stdout: status } = await execAsync('git status --porcelain -uno', { cwd: workspacePath, encoding: 'utf-8' });
      if (status.trim()) {
        const error = `Workspace has uncommitted changes. Please commit or stash them first:\ncd ${workspacePath}\ngit status`;
        completePendingOperation(issueId, error);
        return res.status(400).json({ error });
      }
    } catch (statusErr) {
      // If we can't check status, continue but log it
      console.warn('Could not check workspace status:', statusErr);
    }

    // 4. Push the feature branch to remote BEFORE merging (preserve work)
    try {
      await execAsync(`git push origin ${branchName}`, { cwd: workspacePath, encoding: 'utf-8' });
      console.log(`Pushed ${branchName} to remote`);
    } catch (pushErr: any) {
      // If push fails, it might already be up to date - that's okay
      console.log(`Feature branch push note: ${pushErr.message}`);
    }

    // 5. Switch to main and pull latest
    try {
      await execAsync('git checkout main', { cwd: projectPath, encoding: 'utf-8' });
      // Use explicit origin main to avoid tracking branch issues in worktrees
      await execAsync('git pull origin main --ff-only', { cwd: projectPath, encoding: 'utf-8' });
    } catch (checkoutErr: any) {
      const error = `Failed to checkout/update main branch: ${checkoutErr.message}`;
      completePendingOperation(issueId, error);
      return res.status(400).json({ error });
    }

    // 6. SPECIALIST WORKFLOW: review-agent â†’ test-agent â†’ merge-agent
    // Kick off review-agent with handoff instructions - it will wake the next specialists
    const { wakeSpecialist } = await import('../../lib/cloister/specialists.js');

    // Build the full pipeline prompt for review-agent
    // It will hand off to test-agent, which hands off to merge-agent
    console.log(`[approve] Starting specialist pipeline for ${issueId}...`);

    const pipelinePrompt = `STRICT REVIEW WORKFLOW for ${issueId}

You are a DEMANDING code reviewer. Your job is to find EVERY issue before code can proceed.
DO NOT BE NICE. BE THOROUGH. The code must be PERFECT before it can proceed to testing.

=== CONTEXT ===
ISSUE: ${issueId}
WORKSPACE: ${workspacePath}
BRANCH: ${branchName}
PROJECT: ${projectPath}

=== MANDATORY REQUIREMENTS (Block if ANY violated) ===
1. **Tests Required** - Every new function MUST have test files. No exceptions.
2. **No In-Memory Only Storage** - Important data MUST persist to files/DB.
3. **No Dead Code** - Remove unused imports, functions, variables.
4. **Error Handling** - All async operations must handle errors.
5. **Type Safety** - No \`any\` without justification.

=== YOUR TASK (EXHAUSTIVE REVIEW) ===
1. cd ${workspacePath}
2. Review ALL changes: git diff main...${branchName}
3. Check EVERY file for:
   - Missing test FILES (AUTOMATIC REJECTION)
   - In-memory storage for persistent data (AUTOMATIC REJECTION)
   - Security vulnerabilities
   - Performance issues
   - Code quality problems
4. List EVERY issue found with file:line references

**IMPORTANT: DO NOT run tests (npm test). You are the REVIEW agent - you only review code.**
**The TEST agent will run tests in the next step. Just verify test FILES exist.**

=== DECISION ===
**IF ANY ISSUES FOUND:**
- DO NOT hand off to test-agent
- Use /send-feedback-to-agent to send detailed feedback to agent-${issueId.toLowerCase()}
- Report: "REVIEW BLOCKED: [list of issues that must be fixed]"

**ONLY IF CODE IS PERFECT (rare):**
- Update status: curl -X POST http://localhost:3011/api/workspaces/${issueId}/review-status -H "Content-Type: application/json" -d '{"reviewStatus":"passed"}'
- Queue test-agent (DO NOT use pan specialists wake directly):

curl -X POST http://localhost:3011/api/specialists/test-agent/queue -H "Content-Type: application/json" -d '{"issueId":"${issueId}","workspace":"${workspacePath}","branch":"${branchName}","customPrompt":"TEST TASK for ${issueId}:\\nWORKSPACE: ${workspacePath}\\nBRANCH: ${branchName}\\n\\n1. cd ${workspacePath}\\n2. Run tests: npm test\\n3. Update status via API:\\n   - PASS: curl -X POST http://localhost:3011/api/workspaces/${issueId}/review-status -H Content-Type:application/json -d {testStatus:passed}\\n   - FAIL: curl -X POST http://localhost:3011/api/workspaces/${issueId}/review-status -d {testStatus:failed,testNotes:[details]}\\n\\nIMPORTANT: Do NOT hand off to merge-agent. Human clicks Merge button when ready."}'

=== REVIEW PHILOSOPHY ===
- Your default answer is BLOCK, not PASS
- Missing tests alone is enough to reject
- In-memory storage for important data is enough to reject
- "It works" is NOT enough - code must be EXCELLENT
- Find EVERYTHING. The agent should learn from your feedback.`;

    const reviewResult = await wakeSpecialist('review-agent', pipelinePrompt, {
      waitForReady: true,
      startIfNotRunning: true,
    });

    if (!reviewResult.success) {
      console.warn(`[approve] review-agent failed to wake: ${reviewResult.message}`);
      // Fall back to direct merge if specialists aren't available
      console.log(`[approve] Falling back to direct merge...`);
    } else {
      console.log(`[approve] Pipeline started - review-agent will queue test-agent when done`);
      // Don't wait - the specialists will handle the rest
      // Human clicks Merge button when review+test pass

      // Return early with pipeline status
      completePendingOperation(issueId, null);
      return res.json({
        success: true,
        message: `Approval pipeline started for ${issueId}. Specialists: review â†’ test`,
        pipeline: 'running',
        note: 'Watch the specialists panel for progress. Click Merge when review+test pass.',
      });
    }

    // 6c. MERGE-AGENT: Direct merge (fallback if review-agent failed)
    console.log(`[approve] Step 3/3: Waking merge-agent for ${issueId}...`);

    try {
      const mergeResult = await spawnMergeAgentForBranches(
        projectPath,
        branchName,
        'main',
        issueId
      );

      if (mergeResult.success && mergeResult.testsStatus === 'PASS') {
        // merge-agent successfully completed merge and tests passed
        mergeCompleted = true;
        console.log(`merge-agent successfully merged ${issueId}`);
        if (mergeResult.resolvedFiles?.length) {
          console.log(`Resolved conflicts in: ${mergeResult.resolvedFiles.join(', ')}`);
        }
      } else if (mergeResult.success && mergeResult.testsStatus === 'SKIP') {
        // merge-agent completed merge but tests were skipped
        mergeCompleted = true;
        console.log(`merge-agent merged ${issueId} (tests skipped)`);
        if (mergeResult.resolvedFiles?.length) {
          console.log(`Resolved conflicts in: ${mergeResult.resolvedFiles.join(', ')}`);
        }
      } else if (mergeResult.success && mergeResult.testsStatus === 'FAIL') {
        // merge-agent completed merge but tests failed
        try {
          await execAsync('git reset --hard HEAD~1', { cwd: projectPath, encoding: 'utf-8' });
        } catch {}
        const error = `merge-agent completed merge but tests failed.\nReason: ${mergeResult.reason || 'Tests did not pass'}\n\nPlease fix tests and try again.`;
        completePendingOperation(issueId, error);
        return res.status(400).json({ error });
      } else {
        // merge-agent failed (conflicts it couldn't resolve, or other issue)
        try {
          await execAsync('git merge --abort', { cwd: projectPath, encoding: 'utf-8' });
        } catch {}
        try {
          await execAsync('git reset --hard HEAD', { cwd: projectPath, encoding: 'utf-8' });
        } catch {}
        const error = `merge-agent could not complete merge.\nReason: ${mergeResult.reason || 'Unknown'}\nFailed files: ${mergeResult.failedFiles?.join(', ') || 'N/A'}\n\nPlease resolve manually:\ncd ${projectPath}\ngit merge ${branchName}`;
        completePendingOperation(issueId, error);
        return res.status(400).json({ error });
      }
    } catch (agentError: any) {
      // merge-agent itself failed (timeout, crash, etc.)
      try {
        await execAsync('git merge --abort', { cwd: projectPath, encoding: 'utf-8' });
      } catch {}
      try {
        await execAsync('git reset --hard HEAD', { cwd: projectPath, encoding: 'utf-8' });
      } catch {}
      const error = `merge-agent failed to run: ${agentError.message}\n\nPlease resolve manually:\ncd ${projectPath}\ngit merge ${branchName}`;
      completePendingOperation(issueId, error);
      return res.status(400).json({ error });
    }

    // 7. CRITICAL: Push merged main to remote BEFORE any cleanup
    try {
      await execAsync('git push origin main', { cwd: projectPath, encoding: 'utf-8' });
      pushCompleted = true;
      console.log('Pushed merged main to remote');
    } catch (pushErr: any) {
      // CRITICAL: If push fails, DO NOT proceed with cleanup
      const error = `Merge succeeded but push failed! Your work is safe locally.\nPlease push manually: cd ${projectPath} && git push origin main\nError: ${pushErr.message}`;
      completePendingOperation(issueId, error);
      return res.status(400).json({ error });
    }

    // 8. Stop any running agent
    const agentId = `agent-${issueLower}`;
    try {
      await execAsync(`tmux has-session -t ${agentId} 2>/dev/null && tmux kill-session -t ${agentId}`, {
        encoding: 'utf-8',
        shell: '/bin/bash'
      });
      console.log(`Stopped agent ${agentId}`);
    } catch {
      // Agent not running, that's fine
    }

    // 8.5. Move PRD from active to completed (preserve documentation)
    try {
      const activePrdPath = join(projectPath, 'docs', 'prds', 'active', `${issueLower}-plan.md`);
      const completedDir = join(projectPath, 'docs', 'prds', 'completed');
      const completedPrdPath = join(completedDir, `${issueLower}-plan.md`);

      if (existsSync(activePrdPath)) {
        // Ensure completed directory exists
        if (!existsSync(completedDir)) {
          mkdirSync(completedDir, { recursive: true });
        }
        // Move the PRD
        renameSync(activePrdPath, completedPrdPath);
        console.log(`Moved PRD from active to completed: ${issueLower}-plan.md`);

        // Commit the PRD move
        try {
          await execAsync(`git add docs/prds && git commit -m "docs: move ${issueId} PRD to completed"`, {
            cwd: projectPath,
            encoding: 'utf-8'
          });
          await execAsync('git push origin main', { cwd: projectPath, encoding: 'utf-8' });
          console.log('Committed and pushed PRD move');
        } catch (commitErr: any) {
          // Non-fatal - PRD move is nice to have
          console.log('Could not commit PRD move (non-fatal):', commitErr.message);
        }
      }
    } catch (prdErr: any) {
      // Non-fatal - PRD handling shouldn't block approval
      console.log('PRD move failed (non-fatal):', prdErr.message);
    }

    // 9. Remove the workspace (git worktree) - ONLY after successful push
    try {
      await execAsync(`git worktree remove workspaces/feature-${issueLower} --force`, {
        cwd: projectPath,
        encoding: 'utf-8'
      });
      console.log(`Removed workspace for ${issueId}`);
    } catch (wtError: any) {
      // Log but don't fail - workspace cleanup is non-critical after push
      console.error('Error removing worktree (non-fatal):', wtError.message);
    }

    // 10. DISABLED: Keep feature branches for safety during early development
    // TODO: Re-enable branch cleanup once workflow is battle-tested
    // try {
    //   execSync(`git branch -d ${branchName}`, { cwd: projectPath, encoding: 'utf-8', stdio: 'pipe' });
    //   console.log(`Deleted local branch ${branchName} (remote preserved)`);
    // } catch (branchError: any) {
    //   console.log(`Could not delete local branch ${branchName} (may have unmerged commits): ${branchError.message}`);
    // }
    console.log(`Keeping local branch ${branchName} for safety (early development mode)`);

    // 6. Update Linear issue to Done (or GitHub label)
    const apiKey = getLinearApiKey();
    const isGitHubIssue = issueId.startsWith('PAN-');

    if (isGitHubIssue) {
      // GitHub issue - add "done" label, remove "in-progress"
      const ghConfig = getGitHubConfig();
      if (ghConfig) {
        const number = parseInt(issueId.split('-')[1], 10);
        const repoConfig = ghConfig.repos.find(r => r.prefix === 'PAN') || ghConfig.repos[0];
        const { owner, repo } = repoConfig;
        const token = ghConfig.token;

        await fetch(`https://api.github.com/repos/${owner}/${repo}/issues/${number}/labels/in-progress`, {
          method: 'DELETE',
          headers: { 'Authorization': `token ${token}`, 'Accept': 'application/vnd.github.v3+json' },
        }).catch(() => {});

        await fetch(`https://api.github.com/repos/${owner}/${repo}/issues/${number}/labels`, {
          method: 'POST',
          headers: { 'Authorization': `token ${token}`, 'Accept': 'application/vnd.github.v3+json', 'Content-Type': 'application/json' },
          body: JSON.stringify({ labels: ['done'] }),
        });

        // Close the issue
        await fetch(`https://api.github.com/repos/${owner}/${repo}/issues/${number}`, {
          method: 'PATCH',
          headers: { 'Authorization': `token ${token}`, 'Accept': 'application/vnd.github.v3+json', 'Content-Type': 'application/json' },
          body: JSON.stringify({ state: 'closed' }),
        });
      }
    } else if (apiKey) {
      // Linear issue - transition through proper states: In Progress â†’ In Review â†’ Done
      try {
        const getIssueQuery = `
          query GetIssue($id: String!) {
            issue(id: $id) {
              id
              state { id name type }
              team { states { nodes { id name type } } }
            }
          }
        `;
        const issueResponse = await fetch('https://api.linear.app/graphql', {
          method: 'POST',
          headers: { 'Content-Type': 'application/json', 'Authorization': apiKey },
          body: JSON.stringify({ query: getIssueQuery, variables: { id: issueId } }),
        });
        const issueJson = await issueResponse.json();
        const states = issueJson.data?.issue?.team?.states?.nodes || [];
        const currentState = issueJson.data?.issue?.state;
        const linearId = issueJson.data?.issue?.id;

        // Find the states we need
        const inProgressState = states.find((s: any) => s.type === 'started' || s.name.toLowerCase() === 'in progress');
        const inReviewState = states.find((s: any) => s.name.toLowerCase() === 'in review' || s.name.toLowerCase() === 'review');
        const doneState = states.find((s: any) => s.type === 'completed' || s.name.toLowerCase() === 'done');

        const updateMutation = `
          mutation UpdateIssue($id: String!, $stateId: String!) {
            issueUpdate(id: $id, input: { stateId: $stateId }) { success }
          }
        `;

        if (linearId) {
          // Transition through states properly
          // If still in Planning/Backlog, move to In Progress first
          if (currentState?.type === 'backlog' || currentState?.type === 'unstarted') {
            if (inProgressState) {
              await fetch('https://api.linear.app/graphql', {
                method: 'POST',
                headers: { 'Content-Type': 'application/json', 'Authorization': apiKey },
                body: JSON.stringify({ query: updateMutation, variables: { id: linearId, stateId: inProgressState.id } }),
              });
              console.log(`Updated ${issueId} to In Progress`);
              await new Promise(resolve => setTimeout(resolve, 500)); // Brief delay between transitions
            }
          }

          // Move to In Review
          if (inReviewState) {
            await fetch('https://api.linear.app/graphql', {
              method: 'POST',
              headers: { 'Content-Type': 'application/json', 'Authorization': apiKey },
              body: JSON.stringify({ query: updateMutation, variables: { id: linearId, stateId: inReviewState.id } }),
            });
            console.log(`Updated ${issueId} to In Review`);
            await new Promise(resolve => setTimeout(resolve, 500)); // Brief delay between transitions
          }

          // Finally move to Done
          if (doneState) {
            await fetch('https://api.linear.app/graphql', {
              method: 'POST',
              headers: { 'Content-Type': 'application/json', 'Authorization': apiKey },
              body: JSON.stringify({ query: updateMutation, variables: { id: linearId, stateId: doneState.id } }),
            });
            console.log(`Updated ${issueId} to Done`);
          }
        }
      } catch (linearError) {
        console.error('Error updating Linear:', linearError);
      }
    }

    // For Panopticon issues, run pan sync to distribute new skills/commands/agents
    if (isGitHubIssue || issueId.toUpperCase().startsWith('PAN-')) {
      try {
        console.log('Running pan sync for Panopticon issue...');
        await execAsync('pan sync', { encoding: 'utf-8', timeout: 30000 });
        console.log('pan sync completed');
      } catch (syncError: any) {
        console.error('pan sync failed (non-fatal):', syncError.message);
        // Don't fail the approve - sync failure is non-fatal
      }
    }

    // Record task metrics for the completed work (async to avoid blocking)
    await recordApprovedTask(issueId, workspacePath, 'success');

    // Clear pending operation on success
    completePendingOperation(issueId);

    res.json({
      success: true,
      message: `Approved ${issueId}: merged, workspace removed, issue closed${isGitHubIssue || issueId.toUpperCase().startsWith('PAN-') ? ', skills synced' : ''}, metrics recorded`,
    });
  } catch (error: any) {
    console.error('Error approving workspace:', error);
    completePendingOperation(issueId, error.message);
    res.status(500).json({ error: 'Failed to approve: ' + error.message });
  }
});

// Clear pending operation (dismiss error state)
app.delete('/api/workspaces/:issueId/pending', (req, res) => {
  const { issueId } = req.params;
  clearPendingOperation(issueId);
  res.json({ success: true });
});

// Close/resolve an issue manually (without merge)
app.post('/api/issues/:issueId/close', async (req, res) => {
  const { issueId } = req.params;
  const { reason } = req.body;
  const issuePrefix = issueId.split('-')[0];
  const projectPath = getProjectPath(undefined, issuePrefix);
  const issueLower = issueId.toLowerCase();
  const workspacePath = join(projectPath, 'workspaces', `feature-${issueLower}`);
  const branchName = `feature/${issueLower}`;

  try {
    const isGitHubIssue = issueId.toUpperCase().startsWith('PAN-');
    const apiKey = getLinearApiKey();

    // 1. Close the issue (GitHub via gh CLI, Linear via API)
    if (isGitHubIssue) {
      const ghConfig = getGitHubConfig();
      const number = parseInt(issueId.split('-')[1], 10);
      const repoConfig = ghConfig?.repos.find(r => r.prefix === 'PAN') || ghConfig?.repos[0];
      const repoPath = repoConfig ? `${repoConfig.owner}/${repoConfig.repo}` : 'eltmon/panopticon-cli';

      try {
        // Use gh CLI for better auth handling
        await execAsync(`gh issue close ${number} --repo ${repoPath} --reason completed`, {
          encoding: 'utf-8',
          timeout: 30000,
        });
        console.log(`Closed GitHub issue ${issueId} via gh CLI`);
      } catch (ghError: any) {
        console.error('gh CLI failed, trying API:', ghError.message);
        // Fallback to API if gh fails
        if (ghConfig && repoConfig) {
          await fetch(`https://api.github.com/repos/${repoConfig.owner}/${repoConfig.repo}/issues/${number}`, {
            method: 'PATCH',
            headers: { 'Authorization': `token ${ghConfig.token}`, 'Accept': 'application/vnd.github.v3+json', 'Content-Type': 'application/json' },
            body: JSON.stringify({ state: 'closed' }),
          });
        }
      }
    } else if (apiKey) {
      // Linear issue - update to Done
      const getIssueQuery = `
        query GetIssue($id: String!) {
          issue(id: $id) {
            id
            team { states { nodes { id name type } } }
          }
        }
      `;
      const issueResponse = await fetch('https://api.linear.app/graphql', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json', 'Authorization': apiKey },
        body: JSON.stringify({ query: getIssueQuery, variables: { id: issueId } }),
      });
      const issueJson = await issueResponse.json();
      const states = issueJson.data?.issue?.team?.states?.nodes || [];
      const doneState = states.find((s: any) => s.type === 'completed' || s.name.toLowerCase() === 'done');
      const linearId = issueJson.data?.issue?.id;

      if (doneState && linearId) {
        const updateMutation = `
          mutation UpdateIssue($id: String!, $stateId: String!) {
            issueUpdate(id: $id, input: { stateId: $stateId }) { success }
          }
        `;
        await fetch('https://api.linear.app/graphql', {
          method: 'POST',
          headers: { 'Content-Type': 'application/json', 'Authorization': apiKey },
          body: JSON.stringify({ query: updateMutation, variables: { id: linearId, stateId: doneState.id } }),
        });
        console.log(`Updated Linear issue ${issueId} to Done`);
      }
    }

    // 2. Stop any running agent
    const agentId = `agent-${issueLower}`;
    try {
      await execAsync(`tmux has-session -t ${agentId} 2>/dev/null && tmux kill-session -t ${agentId}`, {
        encoding: 'utf-8',
        shell: '/bin/bash'
      });
      console.log(`Stopped agent ${agentId}`);
    } catch {
      // Agent not running, that's fine
    }

    // 3. Clean up workspace if it exists
    if (existsSync(workspacePath)) {
      try {
        await execAsync(`git worktree remove workspaces/feature-${issueLower} --force`, {
          cwd: projectPath,
          encoding: 'utf-8'
        });
        console.log(`Removed workspace for ${issueId}`);
      } catch (wtError: any) {
        console.error('Error removing worktree:', wtError.message);
      }
    }

    // 4. Feature branches are preserved for history - do NOT delete them
    // Users can manually delete branches if needed via: git branch -d <branch>

    // 5. Run pan sync for Panopticon issues
    if (isGitHubIssue) {
      try {
        await execAsync('pan sync', { encoding: 'utf-8', timeout: 30000 });
        console.log('pan sync completed');
      } catch {}
    }

    res.json({
      success: true,
      message: `Closed ${issueId}${reason ? ': ' + reason : ''}`,
    });
  } catch (error: any) {
    console.error('Error closing issue:', error);
    res.status(500).json({ error: 'Failed to close: ' + error.message });
  }
});

// Start agent for issue
app.post('/api/agents', async (req, res) => {
  const { issueId, projectId } = req.body;

  if (!issueId) {
    return res.status(400).json({ error: 'issueId required' });
  }

  const issueLower = issueId.toLowerCase();

  // SAFEGUARD: Check if planning agent is still running
  // Never start work agent while planning agent is active - they'll conflict
  const planningSession = `planning-${issueLower}`;
  try {
    const { stdout: sessions } = await execAsync('tmux list-sessions -F "#{session_name}" 2>/dev/null || true');
    if (sessions.split('\n').includes(planningSession)) {
      console.warn(`[start-agent] BLOCKED: Planning agent still running for ${issueId}`);
      return res.status(409).json({
        error: `Planning agent is still running for ${issueId}. Kill the planning session first or wait for it to complete.`,
        planningSession,
        hint: 'Use "Complete Planning" or "Abort Planning" to end the planning session before starting work.',
      });
    }
  } catch (tmuxErr) {
    // If tmux check fails, log but continue (fail-open)
    console.warn(`[start-agent] Could not check for planning session: ${tmuxErr}`);
  }

  try {
    // Extract prefix from issue ID (e.g., "MIN" from "MIN-645")
    const issuePrefix = issueId.split('-')[0];
    const projectPath = getProjectPath(projectId, issuePrefix);

    // Before starting agent, commit and push any planning artifacts
    const workspacePath = join(projectPath, 'workspaces', `feature-${issueLower}`);
    const workspacePlanningDir = join(workspacePath, '.planning');
    const legacyPlanningDir = join(projectPath, '.planning', issueLower);

    let planningDir: string | null = null;
    if (existsSync(workspacePlanningDir)) {
      planningDir = workspacePlanningDir;
    } else if (existsSync(legacyPlanningDir)) {
      planningDir = legacyPlanningDir;
    }

    if (planningDir) {
      try {
        // Get the git root (workspace or project root)
        const gitRoot = planningDir.includes('/workspaces/')
          ? workspacePath
          : projectPath;

        // Git add planning and beads directories
        await execAsync(`git add .planning/`, { cwd: gitRoot, encoding: 'utf-8' });
        // Also add .beads/ if it exists
        if (existsSync(join(gitRoot, '.beads'))) {
          await execAsync(`git add .beads/`, { cwd: gitRoot, encoding: 'utf-8' });
        }
        // Also add STATE.md and WORKSPACE.md if they exist
        if (existsSync(join(gitRoot, 'STATE.md'))) {
          await execAsync(`git add STATE.md`, { cwd: gitRoot, encoding: 'utf-8' });
        }
        if (existsSync(join(gitRoot, 'WORKSPACE.md'))) {
          await execAsync(`git add WORKSPACE.md`, { cwd: gitRoot, encoding: 'utf-8' });
        }

        // Check if there are changes to commit
        try {
          await execAsync(`git diff --cached --quiet`, { cwd: gitRoot, encoding: 'utf-8' });
          // No changes to commit
          console.log(`No planning changes to commit for ${issueId}`);
        } catch (diffErr) {
          // There are changes, commit and push them
          await execAsync(`git commit -m "Planning artifacts for ${issueId} before agent start"`, { cwd: gitRoot, encoding: 'utf-8' });
          // Push in background (non-blocking to avoid freezing dashboard)
          const pushChild = spawn('git', ['push'], { cwd: gitRoot, detached: true, stdio: 'ignore' });
          pushChild.unref();
          console.log(`[start-agent] Committed and pushed planning artifacts for ${issueId} (push in background)`);
        }
      } catch (gitErr) {
        console.error('Git commit/push of planning artifacts failed:', gitErr);
        // Continue even if git fails - don't block agent start
      }
    }

    // First, start containers if workspace has ./dev script
    // We must wait for containers to be ready BEFORE starting the agent
    const devScript = join(workspacePath, 'dev');
    let containerActivityId: string | null = null;
    let containersReady = false;

    if (existsSync(workspacePath) && existsSync(devScript)) {
      // Check if Docker is running
      let dockerRunning = false;
      try {
        await execAsync('docker info >/dev/null 2>&1', { encoding: 'utf-8' });
        dockerRunning = true;
      } catch {
        console.log('[start-agent] Docker not running, skipping container start');
      }

      if (dockerRunning) {
        containerActivityId = `containers-${Date.now()}`;
        const featureName = `myn-feature-${issueLower}`;

        logActivity({
          id: containerActivityId,
          timestamp: new Date().toISOString(),
          command: `./dev all (${issueId}) - waiting for containers`,
          status: 'running',
          output: [],
        });

        // Pass UID/GID for correct file ownership in containers
        const containerUid = process.getuid?.() ?? 1000;
        const containerGid = process.getgid?.() ?? 1000;

        // Start containers (don't detach - we need to track completion)
        const containerPromise = new Promise<boolean>((resolve) => {
          const containerChild = spawn('./dev', ['all'], {
            cwd: workspacePath,
            stdio: ['ignore', 'pipe', 'pipe'],
            env: { ...process.env, UID: String(containerUid), GID: String(containerGid), DOCKER_USER: `${containerUid}:${containerGid}` },
          });

          containerChild.stdout?.on('data', (data) => {
            data.toString().split('\n').filter(Boolean).forEach((line: string) => {
              appendActivityOutput(containerActivityId!, line);
            });
          });
          containerChild.stderr?.on('data', (data) => {
            data.toString().split('\n').filter(Boolean).forEach((line: string) => {
              appendActivityOutput(containerActivityId!, `[stderr] ${line}`);
            });
          });

          containerChild.on('close', (code) => {
            appendActivityOutput(containerActivityId!, `[${new Date().toISOString()}] ./dev all exited with code ${code}`);
            updateActivity(containerActivityId!, { status: code === 0 ? 'completed' : 'failed' });
            resolve(code === 0);
          });

          containerChild.on('error', (err) => {
            appendActivityOutput(containerActivityId!, `[error] ${err.message}`);
            updateActivity(containerActivityId!, { status: 'failed' });
            resolve(false);
          });

          // Timeout after 5 minutes
          setTimeout(() => {
            appendActivityOutput(containerActivityId!, '[timeout] Container startup exceeded 5 minutes');
            containerChild.kill('SIGTERM');
            resolve(false);
          }, 5 * 60 * 1000);
        });

        console.log(`[start-agent] Starting containers for ${issueId}, waiting for ready...`);
        appendActivityOutput(containerActivityId, `[${new Date().toISOString()}] Starting containers...`);

        // Wait for ./dev all to complete
        const devCompleted = await containerPromise;

        if (devCompleted) {
          // Now poll for container health (some containers have healthchecks)
          const maxWaitMs = 60000; // 60 seconds
          const pollIntervalMs = 2000;
          const startTime = Date.now();

          appendActivityOutput(containerActivityId, `[${new Date().toISOString()}] Checking container health...`);

          while (Date.now() - startTime < maxWaitMs) {
            try {
              const { stdout } = await execAsync(
                `docker ps --filter "name=${featureName}" --format "{{.Names}}|{{.Status}}"`,
                { encoding: 'utf-8' }
              );

              const containers = stdout.trim().split('\n').filter(Boolean);
              const allHealthy = containers.length > 0 && containers.every(line => {
                const status = line.split('|')[1] || '';
                // Container is ready if it's "Up" and either has no healthcheck or is "(healthy)"
                return status.includes('Up') && (!status.includes('(') || status.includes('(healthy)'));
              });

              if (allHealthy) {
                containersReady = true;
                appendActivityOutput(containerActivityId, `[${new Date().toISOString()}] All ${containers.length} containers ready`);
                console.log(`[start-agent] All ${containers.length} containers ready for ${issueId}`);
                break;
              }

              await new Promise(r => setTimeout(r, pollIntervalMs));
            } catch (healthErr) {
              console.error('[start-agent] Error checking container health:', healthErr);
              await new Promise(r => setTimeout(r, pollIntervalMs));
            }
          }

          if (!containersReady) {
            appendActivityOutput(containerActivityId, `[${new Date().toISOString()}] Warning: Container health check timed out, proceeding anyway`);
            console.warn(`[start-agent] Container health check timed out for ${issueId}`);
            containersReady = true; // Proceed anyway, agent can handle it
          }
        } else {
          appendActivityOutput(containerActivityId, `[${new Date().toISOString()}] Container startup failed`);
          console.error(`[start-agent] Container startup failed for ${issueId}`);
          return res.status(500).json({
            error: `Container startup failed for ${issueId}`,
            hint: 'Check activity log for details',
            activityId: containerActivityId,
          });
        }
      }
    }

    // NOW spawn the agent (after containers are ready)
    const activityId = spawnPanCommand(
      ['work', 'issue', issueId],
      `Start agent for ${issueId}`,
      projectPath
    );

    console.log(`[start-agent] Agent spawned for ${issueId} (containers ready: ${containersReady})`);

    // Update issue status to "In Progress"
    const apiKey = getLinearApiKey();
    const isGitHubIssue = issueId.startsWith('PAN-');

    if (isGitHubIssue) {
      // GitHub issue - add "in-progress" label, remove "planned" label
      try {
        const ghConfig = getGitHubConfig();
        if (ghConfig) {
          const number = parseInt(issueId.split('-')[1], 10);
          // Find the repo config that matches this issue prefix
          const repoConfig = ghConfig.repos.find(r => r.prefix === 'PAN') || ghConfig.repos[0];
          const { owner, repo } = repoConfig;
          const token = ghConfig.token;

          // Remove "planned" label if present
          await fetch(`https://api.github.com/repos/${owner}/${repo}/issues/${number}/labels/planned`, {
            method: 'DELETE',
            headers: {
              'Authorization': `token ${token}`,
              'Accept': 'application/vnd.github.v3+json',
            },
          }).catch(() => {}); // Ignore if label doesn't exist

          // Add "in-progress" label
          await fetch(`https://api.github.com/repos/${owner}/${repo}/issues/${number}/labels`, {
            method: 'POST',
            headers: {
              'Authorization': `token ${token}`,
              'Accept': 'application/vnd.github.v3+json',
              'Content-Type': 'application/json',
            },
            body: JSON.stringify({ labels: ['in-progress'] }),
          });

          console.log(`Updated ${issueId} GitHub labels to in-progress`);
        }
      } catch (ghError) {
        console.error('Failed to update GitHub labels:', ghError);
      }
    } else if (apiKey) {
      // It's a Linear issue, update status
      try {
        // First get the issue to find the team's "In Progress" state
        const getIssueQuery = `
          query GetIssue($id: String!) {
            issue(id: $id) {
              id
              team {
                states {
                  nodes {
                    id
                    name
                    type
                  }
                }
              }
            }
          }
        `;

        const issueResponse = await fetch('https://api.linear.app/graphql', {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
            'Authorization': apiKey,
          },
          body: JSON.stringify({ query: getIssueQuery, variables: { id: issueId } }),
        });

        const issueJson = await issueResponse.json();
        const states = issueJson.data?.issue?.team?.states?.nodes || [];
        const inProgressState = states.find((s: any) => s.type === 'started' || s.name.toLowerCase() === 'in progress');

        if (inProgressState && issueJson.data?.issue?.id) {
          // Update the issue state
          const updateMutation = `
            mutation UpdateIssue($id: String!, $stateId: String!) {
              issueUpdate(id: $id, input: { stateId: $stateId }) {
                success
              }
            }
          `;

          await fetch('https://api.linear.app/graphql', {
            method: 'POST',
            headers: {
              'Content-Type': 'application/json',
              'Authorization': apiKey,
            },
            body: JSON.stringify({
              query: updateMutation,
              variables: { id: issueJson.data.issue.id, stateId: inProgressState.id },
            }),
          });

          console.log(`Updated ${issueId} status to In Progress`);
        }
      } catch (linearError) {
        console.error('Failed to update Linear status:', linearError);
        // Don't fail the request, agent was still started
      }
    }

    res.json({
      success: true,
      message: `Starting agent for ${issueId}`,
      activityId,
      containerActivityId,
      projectPath,
    });
  } catch (error: any) {
    console.error('Error starting agent:', error);
    res.status(500).json({ error: 'Failed to start agent: ' + error.message });
  }
});

// POST /api/agents/cleanup - Clean up old agent directories (PAN-85)
app.post('/api/agents/cleanup', async (req, res) => {
  try {
    const { dryRun = false, ageThresholdDays } = req.body;

    // Call cleanup function from cleanup.ts
    const result = await cleanupOldAgents(ageThresholdDays, dryRun);

    res.json(result);
  } catch (error: any) {
    console.error('Error cleaning up agents:', error);
    res.status(500).json({ error: 'Failed to clean up agents: ' + error.message });
  }
});

// Get skills
app.get('/api/skills', (_req, res) => {
  try {
    const skills: Array<{
      name: string;
      path: string;
      source: string;
      hasSkillMd: boolean;
      description?: string;
    }> = [];

    // Check both skill locations
    const skillLocations = [
      { path: join(homedir(), '.panopticon', 'skills'), source: 'panopticon' },
      { path: join(homedir(), '.claude', 'skills'), source: 'claude' },
    ];

    for (const { path: skillsDir, source } of skillLocations) {
      if (!existsSync(skillsDir)) continue;

      const entries = readdirSync(skillsDir, { withFileTypes: true });
      for (const entry of entries) {
        if (!entry.isDirectory()) continue;

        const skillPath = join(skillsDir, entry.name);
        const skillMdPath = join(skillPath, 'SKILL.md');
        const hasSkillMd = existsSync(skillMdPath);

        let description: string | undefined;
        if (hasSkillMd) {
          try {
            const content = readFileSync(skillMdPath, 'utf-8');
            // Extract first line or sentence as description
            const firstLine = content.split('\n').find(line =>
              line.trim() && !line.startsWith('#') && !line.startsWith('---')
            );
            description = firstLine?.trim().slice(0, 100);
          } catch {}
        }

        skills.push({
          name: entry.name,
          path: skillPath,
          source,
          hasSkillMd,
          description,
        });
      }
    }

    res.json(skills);
  } catch (error) {
    console.error('Error listing skills:', error);
    res.json([]);
  }
});

// Helper to detect if an issue ID is from GitHub
function isGitHubIssue(issueId: string): { isGitHub: boolean; owner?: string; repo?: string; number?: number } {
  const config = getGitHubConfig();
  if (!config) return { isGitHub: false };

  // Check if the prefix matches any configured GitHub repo
  const prefix = issueId.split('-')[0].toUpperCase();
  for (const { owner, repo, prefix: repoPrefix } of config.repos) {
    const configPrefix = (repoPrefix || repo).toUpperCase();
    if (prefix === configPrefix) {
      const number = parseInt(issueId.split('-')[1], 10);
      if (!isNaN(number)) {
        return { isGitHub: true, owner, repo, number };
      }
    }
  }

  return { isGitHub: false };
}

// Fetch GitHub issue details
async function fetchGitHubIssue(owner: string, repo: string, number: number): Promise<any> {
  const config = getGitHubConfig();
  if (!config) throw new Error('GitHub not configured');

  const response = await fetch(
    `https://api.github.com/repos/${owner}/${repo}/issues/${number}`,
    {
      headers: {
        'Authorization': `token ${config.token}`,
        'Accept': 'application/vnd.github.v3+json',
        'User-Agent': 'Panopticon-Dashboard',
      },
    }
  );

  if (!response.ok) {
    throw new Error(`GitHub API error: ${response.status}`);
  }

  return response.json();
}

// Add "planning" label to GitHub issue
async function addGitHubPlanningLabel(owner: string, repo: string, number: number): Promise<void> {
  const config = getGitHubConfig();
  if (!config) throw new Error('GitHub not configured');

  // First, try to create the label if it doesn't exist
  try {
    await fetch(`https://api.github.com/repos/${owner}/${repo}/labels`, {
      method: 'POST',
      headers: {
        'Authorization': `token ${config.token}`,
        'Accept': 'application/vnd.github.v3+json',
        'User-Agent': 'Panopticon-Dashboard',
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        name: 'planning',
        color: 'a855f7', // Purple
        description: 'Issue is in planning/discovery phase',
      }),
    });
  } catch {
    // Label might already exist, that's fine
  }

  // Add the label to the issue
  await fetch(`https://api.github.com/repos/${owner}/${repo}/issues/${number}/labels`, {
    method: 'POST',
    headers: {
      'Authorization': `token ${config.token}`,
      'Accept': 'application/vnd.github.v3+json',
      'User-Agent': 'Panopticon-Dashboard',
      'Content-Type': 'application/json',
    },
    body: JSON.stringify({ labels: ['planning'] }),
  });
}

// Start planning for an issue - moves to "In Planning", creates workspace, spawns planning agent
app.post('/api/issues/:id/start-planning', async (req, res) => {
  const { id } = req.params;
  const { skipWorkspace = false, startDocker = false } = req.body;

  try {
    // Check if a work agent is already running for this issue
    // Don't allow planning when execution is in progress
    const issueLowerForCheck = id.toLowerCase();
    try {
      const { stdout: sessions } = await execAsync('tmux list-sessions -F "#{session_name}" 2>/dev/null || true');
      const workAgentSession = sessions
        .trim()
        .split('\n')
        .find(s => s === `agent-${issueLowerForCheck}`);

      if (workAgentSession) {
        return res.status(409).json({
          error: `Cannot start planning: work agent already running for ${id.toUpperCase()}`,
          hint: 'Stop the agent first or use the terminal view to interact with it',
          existingSession: workAgentSession,
        });
      }
    } catch (tmuxError) {
      // tmux not running or error checking - continue with planning
      console.log('[start-planning] Could not check existing agents:', tmuxError);
    }

    // Check if this is a GitHub issue
    const githubCheck = isGitHubIssue(id);

    let issue: {
      id: string;
      identifier: string;
      title: string;
      description: string;
      url: string;
      source: 'linear' | 'github';
    };
    let newStateName = 'In Planning';

    if (githubCheck.isGitHub && githubCheck.owner && githubCheck.repo && githubCheck.number) {
      // Handle GitHub issue
      const ghIssue = await fetchGitHubIssue(githubCheck.owner, githubCheck.repo, githubCheck.number);

      // Find the prefix for this repo
      const config = getGitHubConfig()!;
      const repoConfig = config.repos.find(r => r.owner === githubCheck.owner && r.repo === githubCheck.repo);
      const prefix = repoConfig?.prefix || githubCheck.repo.toUpperCase();

      issue = {
        id: `github-${githubCheck.owner}-${githubCheck.repo}-${githubCheck.number}`,
        identifier: `${prefix}-${githubCheck.number}`,
        title: ghIssue.title,
        description: ghIssue.body || '',
        url: ghIssue.html_url,
        source: 'github',
      };

      // Add "planning" label to GitHub issue
      await addGitHubPlanningLabel(githubCheck.owner, githubCheck.repo, githubCheck.number);
      newStateName = 'Planning (label added)';

    } else {
      // Handle Linear issue
      const apiKey = getLinearApiKey();
      if (!apiKey) {
        return res.status(500).json({ error: 'LINEAR_API_KEY not configured' });
      }

      // 1. Fetch issue details
      const issueQuery = `
        query GetIssue($id: String!) {
          issue(id: $id) {
            id
            identifier
            title
            description
            url
            state { id name }
            team { id key }
          }
        }
      `;

      const issueResponse = await fetch('https://api.linear.app/graphql', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': apiKey,
        },
        body: JSON.stringify({ query: issueQuery, variables: { id } }),
      });
      const issueJson = await issueResponse.json();
      if (issueJson.errors) throw new Error(issueJson.errors[0]?.message || 'GraphQL error');
      const linearIssue = issueJson.data?.issue;

      if (!linearIssue) {
        return res.status(404).json({ error: 'Issue not found' });
      }

      // 2. Find "In Planning" state for this team
      const statesQuery = `
        query GetTeamStates($teamId: String!) {
          team(id: $teamId) {
            states {
              nodes {
                id
                name
                type
              }
            }
          }
        }
      `;

      const statesResponse = await fetch('https://api.linear.app/graphql', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': apiKey,
        },
        body: JSON.stringify({ query: statesQuery, variables: { teamId: linearIssue.team.id } }),
      });
      const statesJson = await statesResponse.json();
      if (statesJson.errors) throw new Error(statesJson.errors[0]?.message || 'GraphQL error');

      const states = statesJson.data?.team?.states?.nodes || [];
      const planningState = states.find((s: any) =>
        s.name.toLowerCase().includes('planning') ||
        s.name.toLowerCase() === 'planned'
      );

      if (!planningState) {
        return res.status(400).json({
          error: 'No "In Planning" state found in Linear. Please add it to your team workflow.',
          hint: 'Go to Linear â†’ Settings â†’ Teams â†’ Workflow â†’ Add "In Planning" under Started',
        });
      }

      // 3. Move issue to "In Planning" state
      const updateMutation = `
        mutation UpdateIssue($id: String!, $stateId: String!) {
          issueUpdate(id: $id, input: { stateId: $stateId }) {
            success
            issue {
              id
              identifier
              state { name }
            }
          }
        }
      `;

      const updateResponse = await fetch('https://api.linear.app/graphql', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': apiKey,
        },
        body: JSON.stringify({
          query: updateMutation,
          variables: { id: linearIssue.id, stateId: planningState.id },
        }),
      });
      const updateJson = await updateResponse.json();
      if (updateJson.errors) throw new Error(updateJson.errors[0]?.message || 'Failed to update issue');

      issue = {
        id: linearIssue.id,
        identifier: linearIssue.identifier,
        title: linearIssue.title,
        description: linearIssue.description || '',
        url: linearIssue.url,
        source: 'linear',
      };
      newStateName = planningState.name;
    }

    // 4. Create workspace (git worktree) if not skipped
    const mappings = getProjectMappings();
    const prefix = issue.identifier.split('-')[0];
    const mapping = mappings.find(m => m.linearPrefix.toUpperCase() === prefix.toUpperCase());

    // For GitHub issues, check if there's a mapping, otherwise use the GitHub config's local path
    let projectPath: string;
    if (mapping?.localPath) {
      projectPath = mapping.localPath;
    } else if (issue.source === 'github' && githubCheck.owner && githubCheck.repo) {
      // Try to find local path from GitHub config
      const localPaths = getGitHubLocalPaths();
      projectPath = localPaths[`${githubCheck.owner}/${githubCheck.repo}`] || getDefaultProjectPath();
    } else {
      projectPath = getDefaultProjectPath();
    }
    const issueLower = issue.identifier.toLowerCase();
    const workspacePath = join(projectPath, 'workspaces', `feature-${issueLower}`);

    let workspaceCreated = false;
    let workspaceError: string | undefined;

    if (!skipWorkspace) {
      try {
        // Check if workspace needs to be created
        // A workspace with only .planning is incomplete (from a failed previous attempt)
        const workspaceNeedsCreation = !existsSync(workspacePath) ||
          (existsSync(workspacePath) && readdirSync(workspacePath).every(f => f === '.planning'));

        if (workspaceNeedsCreation) {
          // Create workspace using pan workspace create
          const dockerFlag = startDocker ? ' --docker' : '';
          const createCmd = `pan workspace create ${issue.identifier}${dockerFlag}`;
          const activityId = Date.now().toString();
          logActivity({
            id: activityId,
            timestamp: new Date().toISOString(),
            command: createCmd,
            status: 'running',
            output: [],
          });

          // Run pan workspace create (may call custom workspace_command for complex projects)
          // With --docker, containers start in background (up to 5 min timeout for builds)
          await execAsync(createCmd, {
            cwd: projectPath,
            encoding: 'utf-8',
            timeout: startDocker ? 300000 : 120000, // 5 min with docker, 2 min without
          });
          workspaceCreated = true;
          const successMsg = startDocker
            ? 'Workspace created, Docker containers starting in background'
            : 'Workspace created successfully';
          appendActivityOutput(activityId, successMsg);
        } else {
          workspaceCreated = true; // Already exists
        }
      } catch (err: any) {
        workspaceError = err.message;
        console.error('Workspace creation error:', err);
      }
    }

    // 5. Spawn planning agent in tmux
    const sessionName = `planning-${issueLower}`;
    let planningAgentStarted = false;
    let planningAgentError: string | undefined;

    try {
      // Kill existing planning session if any
      await execAsync(`tmux kill-session -t ${sessionName} 2>/dev/null || true`, { encoding: 'utf-8' });

      // Create planning prompt file - store IN workspace if exists (for git-backed planning)
      const planningDir = workspaceCreated
        ? join(workspacePath, '.planning')
        : join(projectPath, '.planning', issueLower);
      if (!existsSync(planningDir)) {
        await execAsync(`mkdir -p "${planningDir}"`, { encoding: 'utf-8' });
      }

      // Clear stale STATE.md from previous planning session (start fresh)
      // This prevents new planning agents from seeing old state and thinking work is done
      const staleStatePath = join(planningDir, 'STATE.md');
      if (existsSync(staleStatePath)) {
        console.log(`[start-planning] Clearing stale STATE.md from previous session`);
        await execAsync(`rm -f "${staleStatePath}"`, { encoding: 'utf-8' });
      }

      const planningPromptPath = join(planningDir, 'PLANNING_PROMPT.md');

      // Get project config for structure context
      const teamPrefix = extractTeamPrefix(issue.identifier);
      const projectConfig = teamPrefix ? findProjectByTeam(teamPrefix) : null;

      // Generate project structure context for polyrepos
      let projectStructureSection = '';
      if (projectConfig?.workspace?.type === 'polyrepo' && projectConfig.workspace.repos) {
        const repos = projectConfig.workspace.repos;
        projectStructureSection = `
## Project Structure (Polyrepo)

**IMPORTANT:** This project uses a **polyrepo** structure. The workspace root is NOT a git repository.
Each subdirectory is a separate git worktree:

| Directory | Purpose |
|-----------|---------|
${repos.map(r => `| \`${r.name}/\` | Git worktree for ${r.path} |`).join('\n')}

**Git operations:**
- Run \`git status\`, \`git log\`, etc. INSIDE the subdirectories (e.g., \`cd fe && git status\`)
- The workspace root (\`${workspacePath}\`) has no \`.git\` directory
- Each subdirectory has its own branch: \`${repos[0]?.branch_prefix || 'feature/'}${issue.identifier.toLowerCase()}\`

`;
      }

      const planningPrompt = `# Planning Session: ${issue.identifier}

## CRITICAL: PLANNING ONLY - NO IMPLEMENTATION

**YOU ARE IN PLANNING MODE. DO NOT:**
- Write or modify any code files (except STATE.md)
- Run implementation commands (npm install, docker compose, make, etc.)
- Create actual features or functionality
- Start implementing the solution

**YOU SHOULD ONLY:**
- Ask clarifying questions (use AskUserQuestion tool)
- Explore the codebase to understand context (read files, grep)
- Generate planning artifacts:
  - STATE.md (decisions, approach, architecture)
  - Beads tasks (via \`bd create\`)
  - PRD file at \`docs/prds/active/{issue-id}-plan.md\` (copy of STATE.md, required for dashboard)
- Present options and tradeoffs for the user to decide

When planning is complete, STOP and tell the user: "Planning complete - click Done when ready to hand off to an agent for implementation."

---

## Issue Details
- **ID:** ${issue.identifier}
- **Title:** ${issue.title}
- **URL:** ${issue.url}

## Description
${issue.description || 'No description provided'}
${projectStructureSection}
---

## Your Mission

You are a planning agent conducting a **discovery session** for this issue.

### Phase 1: Understand Context
1. Read the codebase to understand relevant files and patterns
2. Identify what subsystems/files this issue affects
3. Note any existing patterns we should follow

### Phase 2: Discovery Conversation
Use AskUserQuestion tool to ask contextual questions:
- What's the scope? What's explicitly OUT of scope?
- Any technical constraints or preferences?
- What does "done" look like?
- Are there edge cases we need to handle?

### Difficulty Estimation

For each sub-task, estimate difficulty using this rubric:

| Level | When to Use | Model |
|-------|-------------|-------|
| \`trivial\` | Typo, comment, formatting only | haiku |
| \`simple\` | Bug fix, single file, obvious change | haiku |
| \`medium\` | New feature, 3-5 files, standard patterns | sonnet |
| \`complex\` | Refactor, migration, 6+ files, some risk | sonnet |
| \`expert\` | Architecture, security, performance, high risk | opus |

Consider these factors:
- **Files to modify**: 1-2 (simple), 3-5 (medium), 6+ (complex/expert)
- **Cross-cutting**: None (simple), Some (medium), Many (complex/expert)
- **Risk level**: Low (simple), Medium (medium), High (expert)
- **Domain knowledge**: Standard (simple), Research needed (medium), Deep expertise (expert)

When creating beads tasks, include difficulty labels:
\`\`\`bash
bd create "PAN-XX: Task name" --type task -l "PAN-XX,linear,difficulty:medium" -d "Description"
\`\`\`

### Phase 3: Generate Artifacts (NO CODE!)
When discovery is complete:
1. Create STATE.md with decisions made
2. Create beads tasks with dependencies using \`bd create\` (include difficulty:LEVEL labels)
3. Summarize the plan and STOP

**Remember:** Be a thinking partner, not an interviewer. Ask questions that help clarify.

Start by exploring the codebase to understand the context, then begin the discovery conversation.
`;

      writeFileSync(planningPromptPath, planningPrompt);

      // Determine working directory - use workspace if created, otherwise project root
      const agentCwd = workspaceCreated ? workspacePath : projectPath;

      // Start tmux session with Claude Code for planning (interactive TUI mode)
      // Use a launcher script to safely pass the prompt (avoids shell escaping issues)
      const initMessage = `Please read the planning prompt file at ${planningPromptPath} and begin the planning session for ${issue.identifier}: ${issue.title}`;
      const agentStateDir = join(homedir(), '.panopticon', 'agents', sessionName);
      await execAsync(`mkdir -p "${agentStateDir}"`, { encoding: 'utf-8' });

      // Write a launcher script that safely passes the prompt
      const launcherScript = join(agentStateDir, 'launcher.sh');
      const promptFile = join(agentStateDir, 'init-prompt.txt');
      writeFileSync(promptFile, initMessage);
      writeFileSync(launcherScript, `#!/bin/bash
cd "${agentCwd}"
prompt=$(cat "${promptFile}")
exec claude --dangerously-skip-permissions "$prompt"
`, { mode: 0o755 });

      // Ensure tmux is running before starting session
      await ensureTmuxRunning();
      await execAsync(`tmux new-session -d -s ${sessionName} "bash '${launcherScript}'"`, { encoding: 'utf-8' });

      // Write agent state file so QuestionDialog can find the JSONL path
      writeFileSync(join(agentStateDir, 'state.json'), JSON.stringify({
        id: sessionName,
        issueId: issue.identifier,
        workspace: agentCwd,
        runtime: 'claude',
        model: 'opus', // Planning uses Opus
        status: 'running',
        startedAt: new Date().toISOString(),
        type: 'planning'
      }, null, 2));

      // Resize the tmux window to be wide enough for Claude's TUI
      try {
        await execAsync(`tmux resize-window -t ${sessionName} -x 200 -y 50 2>/dev/null`, { encoding: 'utf-8' });
      } catch {
        // Ignore resize errors
      }

      console.log(`Started planning agent ${sessionName} with initial prompt`);

      planningAgentStarted = true;
    } catch (err: any) {
      planningAgentError = err.message;
      console.error('Planning agent error:', err);
    }

    res.json({
      success: true,
      issue: {
        id: issue.id,
        identifier: issue.identifier,
        title: issue.title,
        newState: newStateName,
        source: issue.source,
      },
      workspace: {
        created: workspaceCreated,
        path: workspacePath,
        error: workspaceError,
      },
      planningAgent: {
        started: planningAgentStarted,
        sessionName: planningAgentStarted ? sessionName : undefined,
        error: planningAgentError,
      },
    });
  } catch (error: any) {
    console.error('Error starting planning:', error);
    res.status(500).json({ error: 'Failed to start planning: ' + error.message });
  }
});

// Get planning session status
app.get('/api/planning/:issueId/status', async (req, res) => {
  const { issueId } = req.params;
  const sessionName = `planning-${issueId.toLowerCase()}`;
  const issueLower = issueId.toLowerCase();
  const issuePrefix = issueId.split('-')[0];
  const projectPath = getProjectPath(undefined, issuePrefix);
  const workspacePath = join(projectPath, 'workspaces', `feature-${issueLower}`);

  try {
    // Check if tmux session exists
    const { stdout: sessionsOutput } = await execAsync('tmux list-sessions -F "#{session_name}" 2>/dev/null || echo ""', {
      encoding: 'utf-8',
    });
    const sessions = sessionsOutput.trim().split('\n').filter(Boolean);

    const sessionExists = sessions.includes(sessionName);

    // Check if planning artifacts exist (indicates planning was done but not marked complete)
    const planningDirInWorkspace = join(workspacePath, '.planning');
    const legacyPlanningDir = join(projectPath, '.planning', issueLower);
    const planningDir = existsSync(planningDirInWorkspace) ? planningDirInWorkspace :
                        existsSync(legacyPlanningDir) ? legacyPlanningDir : null;

    const hasStateFile = planningDir ? existsSync(join(planningDir, 'STATE.md')) : false;
    const hasPromptFile = planningDir ? existsSync(join(planningDir, 'PLANNING_PROMPT.md')) : false;

    res.json({
      active: sessionExists,
      sessionName,
      workspacePath: existsSync(workspacePath) ? workspacePath : undefined,
      // If session is NOT active but STATE.md exists, planning was completed but not marked done
      planningCompleted: !sessionExists && hasStateFile,
      hasStateFile,
      hasPromptFile,
    });
  } catch (error: any) {
    res.json({
      active: false,
      sessionName,
      workspacePath: existsSync(workspacePath) ? workspacePath : undefined,
      planningCompleted: false,
      error: error.message,
    });
  }
});

// Send message to planning session - starts a new Claude run with context
app.post('/api/planning/:issueId/message', async (req, res) => {
  const { issueId } = req.params;
  const { message } = req.body;
  const sessionName = `planning-${issueId.toLowerCase()}`;
  const issueLower = issueId.toLowerCase();

  if (!message) {
    return res.status(400).json({ error: 'Message required' });
  }

  try {
    // Kill any existing session first (Claude with --print will have exited anyway)
    try {
      await execAsync(`tmux kill-session -t ${sessionName} 2>/dev/null`, { encoding: 'utf-8' });
    } catch (e) {
      // Session might not exist
    }

    // Find planning directory - check workspace first, then legacy
    const githubCheck = isGitHubIssue(issueId);
    let projectPath = '';
    let planningDir = '';
    let workspacePath = '';

    // Determine project path
    if (githubCheck.isGitHub && githubCheck.owner && githubCheck.repo) {
      const localPaths = getGitHubLocalPaths();
      projectPath = localPaths[`${githubCheck.owner}/${githubCheck.repo}`] || '';
    } else {
      // Linear issue - check common paths
      const possiblePaths = [
        join(homedir(), 'projects', 'panopticon'),
        join(homedir(), 'projects', 'myn'),
      ];
      for (const p of possiblePaths) {
        // Check workspace first
        if (existsSync(join(p, 'workspaces', `feature-${issueLower}`, '.planning'))) {
          projectPath = p;
          break;
        }
        // Then legacy
        if (existsSync(join(p, '.planning', issueLower))) {
          projectPath = p;
          break;
        }
      }
    }

    if (!projectPath) {
      return res.status(404).json({ error: 'Could not find project path' });
    }

    // Check workspace planning first (git-backed)
    workspacePath = join(projectPath, 'workspaces', `feature-${issueLower}`);
    const workspacePlanningDir = join(workspacePath, '.planning');
    const legacyPlanningDir = join(projectPath, '.planning', issueLower);

    if (existsSync(workspacePlanningDir)) {
      planningDir = workspacePlanningDir;
    } else if (existsSync(legacyPlanningDir)) {
      planningDir = legacyPlanningDir;
    } else {
      return res.status(404).json({ error: 'Planning directory not found', sessionEnded: true });
    }

    const outputFile = join(planningDir, 'output.jsonl');

    // Read previous output to get FULL context
    let conversationLog = '';
    if (existsSync(outputFile)) {
      const content = readFileSync(outputFile, 'utf-8');
      const lines = content.split('\n').filter(line => line.trim());
      const logParts: string[] = [];

      for (const line of lines) {
        try {
          const json = JSON.parse(line);

          // Assistant messages (text and tool uses)
          if (json.type === 'assistant' && json.message?.content) {
            for (const block of json.message.content) {
              if (block.type === 'text') {
                logParts.push(`**Assistant:**\n${block.text}`);
              } else if (block.type === 'tool_use') {
                const input = block.input || {};
                // Skip reads of CONTINUATION_PROMPT.md
                if (block.name === 'Read' && input.file_path?.includes('CONTINUATION_PROMPT.md')) {
                  continue;
                }
                let toolInfo = `**Tool: ${block.name}**`;
                if (block.name === 'Read' && input.file_path) {
                  toolInfo += `\nFile: ${input.file_path}`;
                } else if (block.name === 'Bash' && input.command) {
                  toolInfo += `\nCommand: ${input.command.slice(0, 200)}${input.command.length > 200 ? '...' : ''}`;
                } else if (block.name === 'Grep' && input.pattern) {
                  toolInfo += `\nPattern: ${input.pattern}`;
                } else if (block.name === 'Task' && input.description) {
                  toolInfo += `\nTask: ${input.description}`;
                }
                logParts.push(toolInfo);
              }
            }
          }

          // Tool results
          if (json.type === 'user' && json.message?.content) {
            for (const block of json.message.content) {
              if (block.type === 'tool_result' && block.content) {
                const resultText = typeof block.content === 'string'
                  ? block.content
                  : JSON.stringify(block.content);
                if (resultText.includes('# Continuation of Planning Session:')) {
                  continue;
                }
                if (resultText.trim()) {
                  logParts.push(`**Tool Result:**\n\`\`\`\n${resultText}\n\`\`\``);
                }
              }
            }
          }
        } catch (e) {}
      }
      conversationLog = logParts.join('\n\n');
    }

    // Create continuation prompt
    const continuationPromptPath = join(planningDir, 'CONTINUATION_PROMPT.md');
    const continuationPrompt = `# Continuation of Planning Session: ${issueId.toUpperCase()}

## CRITICAL: PLANNING ONLY - NO IMPLEMENTATION

**YOU ARE IN PLANNING MODE. DO NOT:**
- Write or modify any code files
- Run implementation commands (npm install, docker, etc.)
- Create actual features or functionality

**YOU SHOULD ONLY:**
- Ask clarifying questions
- Explore the codebase to understand context
- Generate planning artifacts (STATE.md, Beads tasks via \`bd create\`, PRD at \`docs/prds/active/{issue-id}-plan.md\`)
- Present options and tradeoffs

---

## Previous Conversation

${conversationLog}

---

## User's Response

${message}

---

## Your Task

Continue the PLANNING session. Do NOT implement anything.
`;

    writeFileSync(continuationPromptPath, continuationPrompt);

    // Determine working directory
    const agentCwd = existsSync(workspacePath) ? workspacePath : projectPath;

    // Backup old output and start new session
    if (existsSync(outputFile)) {
      const backupPath = join(planningDir, `output-${Date.now()}.jsonl`);
      renameSync(outputFile, backupPath);
    }

    const claudeCommand = `cd "${agentCwd}" && claude --dangerously-skip-permissions --print --verbose --output-format stream-json -p "${continuationPromptPath}" 2>&1 | tee "${outputFile}"`;

    await ensureTmuxRunning();
    await execAsync(`tmux new-session -d -s ${sessionName} "${claudeCommand}"`, { encoding: 'utf-8' });

    res.json({ success: true, sessionName, message: 'Planning session continued' });
  } catch (error: any) {
    console.error('Error sending message:', error);
    res.status(500).json({ error: 'Failed to send message: ' + error.message });
  }
});

// Stop planning session (kills tmux session)
app.delete('/api/planning/:issueId', async (req, res) => {
  const { issueId } = req.params;
  const sessionName = `planning-${issueId.toLowerCase()}`;

  try {
    // Kill tmux session
    await execAsync(`tmux kill-session -t ${sessionName} 2>/dev/null || true`, { encoding: 'utf-8' });

    res.json({ success: true });
  } catch (error: any) {
    res.status(500).json({ error: 'Failed to stop planning: ' + error.message });
  }
});

// Remove "planning" label from GitHub issue
async function removeGitHubPlanningLabel(owner: string, repo: string, number: number): Promise<void> {
  const config = getGitHubConfig();
  if (!config) throw new Error('GitHub not configured');

  await fetch(`https://api.github.com/repos/${owner}/${repo}/issues/${number}/labels/planning`, {
    method: 'DELETE',
    headers: {
      'Authorization': `token ${config.token}`,
      'Accept': 'application/vnd.github.v3+json',
      'User-Agent': 'Panopticon-Dashboard',
    },
  });
}


// Abort planning - reverts state to Todo and kills session
app.post('/api/issues/:id/abort-planning', async (req, res) => {
  const { id } = req.params;
  const { deleteWorkspace } = req.body || {};

  try {
    // Check if this is a GitHub issue
    const githubCheck = isGitHubIssue(id);

    let revertedState = 'Todo';
    let issueIdentifier: string | undefined; // e.g., "MIN-665"
    let sessionName: string; // Will be set based on identifier

    if (githubCheck.isGitHub && githubCheck.owner && githubCheck.repo && githubCheck.number) {
      // GitHub: set identifier from the ID (which is like "PAN-123")
      issueIdentifier = id;
      sessionName = `planning-${id.toLowerCase()}`;

      // GitHub: remove "planning" label
      try {
        await removeGitHubPlanningLabel(githubCheck.owner, githubCheck.repo, githubCheck.number);
        revertedState = 'Todo (label removed)';
      } catch (err) {
        // Label might not exist, that's fine
        console.log('Could not remove planning label:', err);
      }
    } else {
      // Linear: move back to Todo state
      const apiKey = getLinearApiKey();
      if (apiKey) {
        // Fetch issue to get team and identifier
        const issueQuery = `
          query GetIssue($id: String!) {
            issue(id: $id) {
              id
              identifier
              team { id }
            }
          }
        `;

        const issueResponse = await fetch('https://api.linear.app/graphql', {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
            'Authorization': apiKey,
          },
          body: JSON.stringify({ query: issueQuery, variables: { id } }),
        });
        const issueJson = await issueResponse.json();
        const issue = issueJson.data?.issue;

        if (issue) {
          // Store the issue identifier for workspace deletion and session name
          issueIdentifier = issue.identifier;
          sessionName = `planning-${issue.identifier.toLowerCase()}`;

          // Find "Todo" state for this team
          const statesQuery = `
            query GetTeamStates($teamId: String!) {
              team(id: $teamId) {
                states {
                  nodes {
                    id
                    name
                    type
                  }
                }
              }
            }
          `;

          const statesResponse = await fetch('https://api.linear.app/graphql', {
            method: 'POST',
            headers: {
              'Content-Type': 'application/json',
              'Authorization': apiKey,
            },
            body: JSON.stringify({ query: statesQuery, variables: { teamId: issue.team.id } }),
          });
          const statesJson = await statesResponse.json();
          const states = statesJson.data?.team?.states?.nodes || [];

          // Find Todo/Unstarted state
          const todoState = states.find((s: any) =>
            s.name.toLowerCase() === 'todo' ||
            s.name.toLowerCase() === 'to do' ||
            s.type === 'unstarted'
          );

          if (todoState) {
            // Move issue to Todo
            const updateMutation = `
              mutation UpdateIssue($id: String!, $stateId: String!) {
                issueUpdate(id: $id, input: { stateId: $stateId }) {
                  success
                  issue { state { name } }
                }
              }
            `;

            await fetch('https://api.linear.app/graphql', {
              method: 'POST',
              headers: {
                'Content-Type': 'application/json',
                'Authorization': apiKey,
              },
              body: JSON.stringify({
                query: updateMutation,
                variables: { id: issue.id, stateId: todoState.id },
              }),
            });
            revertedState = todoState.name;
          }
        }
      }
    }

    // Kill the tmux session (try both possible session names if needed)
    if (sessionName) {
      await execAsync(`tmux kill-session -t ${sessionName} 2>/dev/null || true`, { encoding: 'utf-8' });
    }
    // Also try with UUID-based session name (fallback)
    await execAsync(`tmux kill-session -t planning-${id.toLowerCase()} 2>/dev/null || true`, { encoding: 'utf-8' });

    // Clean up agent state files to prevent stale "running" status
    // Note: issueIdentifier is the human-readable ID (e.g., "MIN-665"), not the Linear UUID
    const agentStateDir = sessionName ? join(homedir(), '.panopticon', 'agents', sessionName) : null;
    const workAgentStateDir = issueIdentifier
      ? join(homedir(), '.panopticon', 'agents', `agent-${issueIdentifier.toLowerCase()}`)
      : join(homedir(), '.panopticon', 'agents', `agent-${id.toLowerCase()}`);

    console.log(`[abort-planning] Cleanup paths: sessionName=${sessionName}, issueIdentifier=${issueIdentifier}`);
    console.log(`[abort-planning] agentStateDir=${agentStateDir}, exists=${agentStateDir ? existsSync(agentStateDir) : 'null'}`);
    console.log(`[abort-planning] workAgentStateDir=${workAgentStateDir}, exists=${existsSync(workAgentStateDir)}`);

    try {
      if (agentStateDir && existsSync(agentStateDir)) {
        rmSync(agentStateDir, { recursive: true, force: true });
        console.log(`[abort-planning] âœ“ Cleaned up planning agent state: ${agentStateDir}`);
      }
      if (existsSync(workAgentStateDir)) {
        rmSync(workAgentStateDir, { recursive: true, force: true });
        console.log(`[abort-planning] âœ“ Cleaned up work agent state: ${workAgentStateDir}`);
      }
    } catch (cleanupErr) {
      console.log('[abort-planning] Warning: Could not clean up agent state:', cleanupErr);
    }

    // Clean up legacy planning directory (outside workspace, in project root)
    // This exists when planning started before workspace creation or workspace was skipped
    if (issueIdentifier) {
      try {
        // Find project path to locate legacy planning dir
        let projectPath: string | undefined;
        const prefix = issueIdentifier.split('-')[0].toUpperCase();

        const projectsYamlPath = join(homedir(), '.panopticon', 'projects.yaml');
        if (existsSync(projectsYamlPath)) {
          const yaml = await import('js-yaml');
          const projectsConfig = yaml.load(readFileSync(projectsYamlPath, 'utf-8')) as any;
          for (const [, config] of Object.entries(projectsConfig.projects || {})) {
            const projConfig = config as any;
            if (projConfig.linear_team?.toUpperCase() === prefix) {
              projectPath = projConfig.path;
              break;
            }
          }
        }

        if (projectPath) {
          const legacyPlanningDir = join(projectPath, '.planning', issueIdentifier.toLowerCase());
          if (existsSync(legacyPlanningDir)) {
            rmSync(legacyPlanningDir, { recursive: true, force: true });
            console.log(`Cleaned up legacy planning dir: ${legacyPlanningDir}`);
          }
        }
      } catch (planningCleanupErr) {
        console.log('Warning: Could not clean up legacy planning dir:', planningCleanupErr);
      }
    }

    // Optionally delete the workspace
    let workspaceDeleted = false;
    let workspaceError: string | undefined;

    if (deleteWorkspace) {
      try {
        // Find the workspace path - check GitHub or Linear project mapping
        let projectPath: string | undefined;

        if (githubCheck.isGitHub && githubCheck.owner && githubCheck.repo) {
          const localPaths = getGitHubLocalPaths();
          projectPath = localPaths[`${githubCheck.owner}/${githubCheck.repo}`];
        } else if (issueIdentifier) {
          // For Linear issues, use the identifier to find the project path
          // Check project mappings
          const mappingsPath = join(homedir(), '.panopticon', 'project-mappings.json');
          if (existsSync(mappingsPath)) {
            const mappings = JSON.parse(readFileSync(mappingsPath, 'utf-8'));
            // Try to match by issue prefix (e.g., MIN-123 -> MIN)
            const prefix = issueIdentifier.split('-')[0];
            const mapping = mappings.find((m: any) => m.linearPrefix?.toUpperCase() === prefix.toUpperCase());
            if (mapping) {
              projectPath = mapping.localPath;
            }
          }

          // Also check projects.yaml
          if (!projectPath) {
            const projectsYamlPath = join(homedir(), '.panopticon', 'projects.yaml');
            if (existsSync(projectsYamlPath)) {
              try {
                const yaml = await import('js-yaml');
                const projectsConfig = yaml.load(readFileSync(projectsYamlPath, 'utf-8')) as any;
                const prefix = issueIdentifier.split('-')[0].toUpperCase();

                for (const [, config] of Object.entries(projectsConfig.projects || {})) {
                  const projConfig = config as any;
                  if (projConfig.linear_team?.toUpperCase() === prefix) {
                    projectPath = projConfig.path;
                    break;
                  }
                }
              } catch {
                // Ignore YAML errors
              }
            }
          }
        }

        if (projectPath && issueIdentifier) {
          // Try both naming conventions: feature-{identifier} and just {identifier}
          const featureWorkspacePath = join(projectPath, 'workspaces', `feature-${issueIdentifier.toLowerCase()}`);
          const plainWorkspacePath = join(projectPath, 'workspaces', issueIdentifier.toLowerCase());
          const workspacePath = existsSync(featureWorkspacePath) ? featureWorkspacePath : plainWorkspacePath;

          if (existsSync(workspacePath)) {
            // Check for custom workspace_remove_command in projects.yaml
            const projectsYamlPath = join(homedir(), '.panopticon', 'projects.yaml');
            let customRemoveCmd: string | undefined;

            if (existsSync(projectsYamlPath)) {
              try {
                const yaml = await import('js-yaml');
                const projectsConfig = yaml.load(readFileSync(projectsYamlPath, 'utf-8')) as any;
                const prefix = issueIdentifier.split('-')[0].toLowerCase();

                // Find project by linear_team prefix
                for (const [, config] of Object.entries(projectsConfig.projects || {})) {
                  const projConfig = config as any;
                  if (projConfig.linear_team?.toLowerCase() === prefix && projConfig.workspace_remove_command) {
                    customRemoveCmd = projConfig.workspace_remove_command;
                    break;
                  }
                }
              } catch (yamlErr) {
                console.log('Could not parse projects.yaml:', yamlErr);
              }
            }

            if (customRemoveCmd) {
              // Use custom remove command (legacy)
              const featureName = issueIdentifier.toLowerCase();
              await execAsync(`${customRemoveCmd} ${featureName}`, {
                cwd: projectPath,
                encoding: 'utf-8',
                timeout: 60000, // 1 minute timeout
              });
              workspaceDeleted = true;
            } else {
              // Use pan workspace destroy command (handles polyrepo, Docker cleanup, etc.)
              const featureName = issueIdentifier.toLowerCase();
              await execAsync(`pan workspace destroy ${featureName} --force`, {
                cwd: projectPath,
                encoding: 'utf-8',
                timeout: 120000, // 2 minute timeout for Docker cleanup
                maxBuffer: 10 * 1024 * 1024, // 10MB buffer for verbose Docker output
              });
              workspaceDeleted = true;
            }
          } else {
            workspaceError = 'Workspace not found';
          }
        } else {
          workspaceError = 'Could not determine project path';
        }
      } catch (err: any) {
        workspaceError = err.message;
        console.error('Error deleting workspace:', err);
      }
    }

    res.json({
      success: true,
      issueId: id,
      revertedState,
      sessionKilled: true,
      workspaceDeleted,
      workspacePreserved: !deleteWorkspace && !workspaceDeleted,
      workspaceError,
    });
  } catch (error: any) {
    console.error('Error aborting planning:', error);
    res.status(500).json({ error: 'Failed to abort planning: ' + error.message });
  }
});

// Complete planning - move issue to "Planned" state
app.post('/api/issues/:id/complete-planning', async (req, res) => {
  const { id } = req.params;
  const sessionName = `planning-${id.toLowerCase()}`;
  const issueLower = id.toLowerCase();

  try {
    // Kill any running planning session
    try {
      await execAsync(`tmux kill-session -t ${sessionName} 2>/dev/null`, { encoding: 'utf-8' });
    } catch (e) {
      // Session might not exist
    }

    // Find planning directory and commit/push
    const githubCheck = isGitHubIssue(id);
    let projectPath = '';
    let planningDir = '';

    // Determine project path
    if (githubCheck.isGitHub && githubCheck.owner && githubCheck.repo) {
      const localPaths = getGitHubLocalPaths();
      projectPath = localPaths[`${githubCheck.owner}/${githubCheck.repo}`] || '';
    } else {
      // Linear issue - check common paths
      const possiblePaths = [
        join(homedir(), 'projects', 'panopticon'),
        join(homedir(), 'projects', 'myn'),
      ];
      for (const p of possiblePaths) {
        // Check workspace first
        if (existsSync(join(p, 'workspaces', `feature-${issueLower}`, '.planning'))) {
          projectPath = p;
          break;
        }
        // Then legacy
        if (existsSync(join(p, '.planning', issueLower))) {
          projectPath = p;
          break;
        }
      }
    }

    // Git commit and push if planning dir exists
    let gitPushed = false;
    if (projectPath) {
      const workspacePlanningDir = join(projectPath, 'workspaces', `feature-${issueLower}`, '.planning');
      const legacyPlanningDir = join(projectPath, '.planning', issueLower);

      if (existsSync(workspacePlanningDir)) {
        planningDir = workspacePlanningDir;
      } else if (existsSync(legacyPlanningDir)) {
        planningDir = legacyPlanningDir;
      }

      if (planningDir) {
        try {
          // Get the git root (workspace or project root)
          const gitRoot = planningDir.includes('/workspaces/')
            ? join(projectPath, 'workspaces', `feature-${issueLower}`)
            : projectPath;

          // Git add planning and beads directories
          await execAsync(`git add .planning/`, { cwd: gitRoot, encoding: 'utf-8' });
          // Also add .beads/ if it exists (planning may create beads tasks)
          if (existsSync(join(gitRoot, '.beads'))) {
            await execAsync(`git add .beads/`, { cwd: gitRoot, encoding: 'utf-8' });
          }

          // Check if there are changes to commit
          try {
            await execAsync(`git diff --cached --quiet`, { cwd: gitRoot, encoding: 'utf-8' });
            // No changes to commit
          } catch (diffErr) {
            // There are changes, commit them
            await execAsync(`git commit -m "Complete planning for ${id}"`, { cwd: gitRoot, encoding: 'utf-8' });
          }

          // Push to remote (non-blocking to avoid freezing dashboard)
          // Spawn in background - don't await
          const pushChild = spawn('git', ['push'], { cwd: gitRoot, detached: true, stdio: 'ignore' });
          pushChild.unref();
          gitPushed = true;
          console.log(`[complete-planning] Git push started in background for ${id}`);
        } catch (gitErr) {
          console.error('Git commit/push failed:', gitErr);
          // Continue even if git fails
        }
      }
    }

    // Update issue state (Linear or GitHub)
    let newState = 'Planned';

    if (githubCheck.isGitHub && githubCheck.owner && githubCheck.repo && githubCheck.number) {
      // GitHub: Remove "planning" label, add "planned" label
      const config = getGitHubConfig();
      if (config) {
        try {
          // Remove planning label
          await fetch(`https://api.github.com/repos/${githubCheck.owner}/${githubCheck.repo}/issues/${githubCheck.number}/labels/planning`, {
            method: 'DELETE',
            headers: {
              'Authorization': `token ${config.token}`,
              'Accept': 'application/vnd.github.v3+json',
              'User-Agent': 'Panopticon-Dashboard',
            },
          });
        } catch (e) {}

        try {
          // Add planned label
          await fetch(`https://api.github.com/repos/${githubCheck.owner}/${githubCheck.repo}/issues/${githubCheck.number}/labels`, {
            method: 'POST',
            headers: {
              'Authorization': `token ${config.token}`,
              'Accept': 'application/vnd.github.v3+json',
              'User-Agent': 'Panopticon-Dashboard',
              'Content-Type': 'application/json',
            },
            body: JSON.stringify({ labels: ['planned'] }),
          });
        } catch (e) {}
      }
    } else {
      // Linear: Update to "Planned" state
      const apiKey = getLinearApiKey();
      if (apiKey) {
        // First, get the issue to find its team
        const issueQuery = `query { issue(id: "${id}") { id team { id states { nodes { id name } } } } }`;
        const issueRes = await fetch('https://api.linear.app/graphql', {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
            'Authorization': apiKey,
          },
          body: JSON.stringify({ query: issueQuery }),
        });
        const issueData = await issueRes.json();
        const issue = issueData.data?.issue;

        if (issue) {
          // Find "Planned" state or fall back to first available state after "In Planning"
          const states = issue.team?.states?.nodes || [];
          let plannedState = states.find((s: any) => s.name === 'Planned');
          if (!plannedState) {
            plannedState = states.find((s: any) => s.name === 'Ready');
          }
          if (!plannedState) {
            plannedState = states.find((s: any) => s.name === 'Todo');
          }

          if (plannedState) {
            const updateMutation = `mutation { issueUpdate(id: "${issue.id}", input: { stateId: "${plannedState.id}" }) { success issue { state { name } } } }`;
            const updateRes = await fetch('https://api.linear.app/graphql', {
              method: 'POST',
              headers: {
                'Content-Type': 'application/json',
                'Authorization': apiKey,
              },
              body: JSON.stringify({ query: updateMutation }),
            });
            const updateData = await updateRes.json();
            newState = updateData.data?.issueUpdate?.issue?.state?.name || 'Planned';
          }
        }
      }
    }

    res.json({
      success: true,
      issueId: id,
      newState,
      gitPushed,
      message: gitPushed
        ? 'Planning complete and pushed to git - ready for execution'
        : 'Planning complete - ready for execution',
    });
  } catch (error: any) {
    console.error('Error completing planning:', error);
    res.status(500).json({ error: 'Failed to complete planning: ' + error.message });
  }
});

// Reopen a done/closed issue - moves back to Backlog and optionally starts planning
app.post('/api/issues/:id/reopen', async (req, res) => {
  const { id } = req.params;
  const { skipPlan = false } = req.body || {};

  try {
    // Check if it's a Linear issue
    const linearKey = process.env.LINEAR_API_KEY || '';
    if (!linearKey) {
      return res.status(400).json({ error: 'LINEAR_API_KEY not configured' });
    }

    // Import Linear SDK
    const { LinearClient } = await import('@linear/sdk');
    const client = new LinearClient({ apiKey: linearKey });

    // Find the issue by identifier (e.g., "MIN-665")
    // Linear SDK accepts both UUIDs and identifiers
    const issue = await client.issue(id);

    if (!issue) {
      return res.status(404).json({ error: `Issue ${id} not found` });
    }

    // Get backlog state
    const team = await issue.team;
    if (!team) {
      return res.status(400).json({ error: 'Could not determine team for issue' });
    }

    const states = await team.states();
    const backlogState = states.nodes.find(s => s.type === 'backlog');

    if (!backlogState) {
      return res.status(400).json({ error: 'Could not find Backlog state for team' });
    }

    // Move issue to Backlog
    await issue.update({ stateId: backlogState.id });

    console.log(`Reopened issue ${id} - moved to Backlog`);

    // Optionally start planning
    if (!skipPlan) {
      // We could trigger planning here, but for now just return success
      // The user can click Plan from the dashboard
    }

    res.json({
      success: true,
      message: `Issue ${id} reopened and moved to Backlog`,
      issueId: issue.identifier,
      newState: 'Backlog',
    });
  } catch (error: any) {
    console.error('Error reopening issue:', error);
    res.status(500).json({ error: 'Failed to reopen issue: ' + error.message });
  }
});

// Deep wipe - completely clean up all state for an issue
app.post('/api/issues/:id/deep-wipe', async (req, res) => {
  const { id } = req.params;
  const { deleteWorkspace = false } = req.body || {};
  const cleanupLog: string[] = [];

  try {
    const issueLower = id.toLowerCase();
    const githubCheck = isGitHubIssue(id);

    // 1. Kill all tmux sessions for this issue
    const sessionPatterns = [
      `planning-${issueLower}`,
      `agent-${issueLower}`,
    ];
    for (const session of sessionPatterns) {
      try {
        await execAsync(`tmux kill-session -t ${session} 2>/dev/null || true`, { encoding: 'utf-8' });
        cleanupLog.push(`Killed tmux session: ${session}`);
      } catch (e) {
        // Session might not exist
      }
    }

    // 2. Clean up agent state directories
    const agentDirs = [
      join(homedir(), '.panopticon', 'agents', `planning-${issueLower}`),
      join(homedir(), '.panopticon', 'agents', `agent-${issueLower}`),
    ];
    for (const dir of agentDirs) {
      if (existsSync(dir)) {
        rmSync(dir, { recursive: true, force: true });
        cleanupLog.push(`Deleted agent state: ${dir}`);
      }
    }

    // 3. Find project path for workspace and planning dir cleanup
    let projectPath: string | undefined;
    if (!githubCheck.isGitHub) {
      const prefix = id.split('-')[0].toUpperCase();
      const projectsYamlPath = join(homedir(), '.panopticon', 'projects.yaml');
      if (existsSync(projectsYamlPath)) {
        const yaml = await import('js-yaml');
        const projectsConfig = yaml.load(readFileSync(projectsYamlPath, 'utf-8')) as any;
        for (const [, config] of Object.entries(projectsConfig.projects || {})) {
          const projConfig = config as any;
          if (projConfig.linear_team?.toUpperCase() === prefix) {
            projectPath = projConfig.path;
            break;
          }
        }
      }
    } else {
      const localPaths = getGitHubLocalPaths();
      projectPath = localPaths[`${githubCheck.owner}/${githubCheck.repo}`];
    }

    // 4. Clean up legacy planning directory
    if (projectPath) {
      const legacyPlanningDir = join(projectPath, '.planning', issueLower);
      if (existsSync(legacyPlanningDir)) {
        rmSync(legacyPlanningDir, { recursive: true, force: true });
        cleanupLog.push(`Deleted legacy planning dir: ${legacyPlanningDir}`);
      }
    }

    // 5. Optionally delete workspace
    if (deleteWorkspace && projectPath) {
      const workspacePath = join(projectPath, 'workspaces', `feature-${issueLower}`);
      const branchName = `feature/${issueLower}`;
      const gitDirs = ['api', 'frontend', 'fe', '.'];

      // Helper to run git commands with timeout (5 seconds for local, 10 for remote)
      const gitExec = async (cmd: string, timeoutMs = 5000) => {
        try {
          await execAsync(cmd, { encoding: 'utf-8', timeout: timeoutMs });
        } catch (e) {
          // Command failed or timed out - continue anyway
        }
      };

      // Remove git worktrees first
      for (const gitDir of gitDirs) {
        const gitPath = join(projectPath, gitDir);
        if (existsSync(join(gitPath, '.git'))) {
          // Remove worktree - use prune instead of remove to avoid hangs
          await gitExec(`cd "${gitPath}" && git worktree prune 2>/dev/null || true`);

          // Also try explicit remove for subdirs
          const subDirs = ['fe', 'api', 'frontend'];
          for (const subDir of subDirs) {
            const subPath = join(workspacePath, subDir);
            await gitExec(`cd "${gitPath}" && git worktree remove "${subPath}" --force 2>/dev/null || true`);
          }

          // Delete local branch
          await gitExec(`cd "${gitPath}" && git branch -D "${branchName}" 2>/dev/null || true`);

          // Delete remote branch (longer timeout for network)
          await gitExec(`cd "${gitPath}" && git push origin --delete "${branchName}" 2>/dev/null || true`, 10000);
        }
      }

      // Delete workspace directory if it still exists
      if (existsSync(workspacePath)) {
        rmSync(workspacePath, { recursive: true, force: true });
      }
      cleanupLog.push(`Deleted workspace and branches: ${branchName}`);
    }

    // 6. Reset Linear issue state and remove labels
    if (!githubCheck.isGitHub) {
      const linearKey = process.env.LINEAR_API_KEY || '';
      if (linearKey) {
        try {
          const { LinearClient } = await import('@linear/sdk');
          const client = new LinearClient({ apiKey: linearKey });
          const issue = await client.issue(id);

          if (issue) {
            // Get team and backlog state
            const team = await issue.team;
            if (team) {
              const states = await team.states();
              const backlogState = states.nodes.find(s => s.type === 'backlog');

              if (backlogState) {
                await issue.update({ stateId: backlogState.id });
                cleanupLog.push(`Reset Linear status to Backlog`);
              }

              // Remove labels
              const labels = await issue.labels();
              const labelsToRemove = labels.nodes.filter(l =>
                l.name.toLowerCase() === 'review ready' ||
                l.name.toLowerCase() === 'planning'
              );
              if (labelsToRemove.length > 0) {
                const currentLabelIds = labels.nodes.map(l => l.id);
                const newLabelIds = currentLabelIds.filter(
                  lid => !labelsToRemove.some(lr => lr.id === lid)
                );
                await issue.update({ labelIds: newLabelIds });
                cleanupLog.push(`Removed labels: ${labelsToRemove.map(l => l.name).join(', ')}`);
              }
            }
          }
        } catch (linearErr) {
          cleanupLog.push(`Linear cleanup warning: ${(linearErr as Error).message}`);
        }
      }
    }

    console.log(`[deep-wipe] Completed for ${id}:`, cleanupLog);
    res.json({
      success: true,
      message: `Deep wipe completed for ${id}`,
      cleanupLog,
    });
  } catch (error: any) {
    console.error('Error in deep wipe:', error);
    res.status(500).json({ error: 'Deep wipe failed: ' + error.message, partialLog: cleanupLog });
  }
});

// Get beads tasks for an issue
app.get('/api/issues/:id/beads', (req, res) => {
  const { id } = req.params;
  const issueLower = id.toLowerCase();

  try {
    // Find project path
    const githubCheck = isGitHubIssue(id);
    let projectPath = '';

    if (githubCheck.isGitHub && githubCheck.owner && githubCheck.repo) {
      const localPaths = getGitHubLocalPaths();
      projectPath = localPaths[`${githubCheck.owner}/${githubCheck.repo}`] || '';
    } else {
      const possiblePaths = [
        join(homedir(), 'projects', 'panopticon'),
        join(homedir(), 'projects', 'myn'),
      ];
      for (const p of possiblePaths) {
        if (existsSync(join(p, 'workspaces', `feature-${issueLower}`)) || existsSync(join(p, '.beads'))) {
          projectPath = p;
          break;
        }
      }
    }

    if (!projectPath) {
      return res.json({ tasks: [], message: 'No project found' });
    }

    // Read STATE.md to get beads IDs created during planning
    const workspacePath = join(projectPath, 'workspaces', `feature-${issueLower}`);
    const statePath = join(workspacePath, '.planning', 'STATE.md');
    const beadsIds: string[] = [];

    if (existsSync(statePath)) {
      const stateContent = readFileSync(statePath, 'utf-8');
      // Extract beads IDs from STATE.md (format: `panopticon-xxx` or similar)
      const idMatches = stateContent.match(/`([a-z]+-[a-z0-9]+)`/g) || [];
      for (const match of idMatches) {
        const beadsId = match.replace(/`/g, '');
        if (beadsId.includes('-') && !beadsId.includes('/')) {
          beadsIds.push(beadsId);
        }
      }
    }

    // Check both workspace beads and main project beads
    const beadsPaths = [
      join(workspacePath, '.beads', 'issues.jsonl'),
      join(projectPath, '.beads', 'issues.jsonl'),
    ];

    const tasks: any[] = [];
    const seenIds = new Set<string>();

    for (const issuesFile of beadsPaths) {
      if (!existsSync(issuesFile)) continue;

      const content = readFileSync(issuesFile, 'utf-8');
      const lines = content.split('\n').filter(line => line.trim());

      for (const line of lines) {
        try {
          const issue = JSON.parse(line);
          // Skip if already seen
          if (seenIds.has(issue.id)) continue;

          // Include if: ID is in our beadsIds list, OR tagged with issue identifier
          const tags = issue.tags || [];
          const matchesTag = tags.some((t: string) =>
            t.toLowerCase() === issueLower || t.toLowerCase() === id.toLowerCase()
          );
          const matchesBeadsId = beadsIds.includes(issue.id);

          if (matchesTag || matchesBeadsId) {
            seenIds.add(issue.id);
            tasks.push({
              id: issue.id,
              title: issue.title,
              status: issue.status,
              type: issue.issue_type || issue.type,
              blockedBy: issue.blocked_by || [],
              createdAt: issue.created_at,
            });
          }
        } catch (e) {
          // Skip malformed lines
        }
      }
    }

    // Sort by creation date
    tasks.sort((a, b) => new Date(a.createdAt).getTime() - new Date(b.createdAt).getTime());

    res.json({
      tasks,
      workspacePath,
      count: tasks.length,
    });
  } catch (error: any) {
    console.error('Error fetching beads:', error);
    res.status(500).json({ error: 'Failed to fetch beads: ' + error.message });
  }
});

// ============== Cost & Metrics API ==============

// Cost tracking imports (inline to avoid external module issues)
const COSTS_DIR = join(homedir(), '.panopticon', 'costs');
const SESSION_MAP_FILE = join(homedir(), '.panopticon', 'session-map.json');
const METRICS_FILE = join(homedir(), '.panopticon', 'runtime-metrics.json');

// Model pricing data
const MODEL_PRICING: Record<string, { inputPer1k: number; outputPer1k: number; cacheReadPer1k?: number; cacheWrite5mPer1k?: number; cacheWrite1hPer1k?: number }> = {
  // 4.5 series
  'claude-opus-4.5': { inputPer1k: 0.005, outputPer1k: 0.025, cacheReadPer1k: 0.0005, cacheWrite5mPer1k: 0.00625, cacheWrite1hPer1k: 0.01 },
  'claude-sonnet-4.5': { inputPer1k: 0.003, outputPer1k: 0.015, cacheReadPer1k: 0.0003, cacheWrite5mPer1k: 0.00375, cacheWrite1hPer1k: 0.006 },
  'claude-haiku-4.5': { inputPer1k: 0.001, outputPer1k: 0.005, cacheReadPer1k: 0.0001, cacheWrite5mPer1k: 0.00125, cacheWrite1hPer1k: 0.002 },
  // 4.x series
  'claude-opus-4-1': { inputPer1k: 0.015, outputPer1k: 0.075, cacheReadPer1k: 0.0015, cacheWrite5mPer1k: 0.01875, cacheWrite1hPer1k: 0.03 },
  'claude-opus-4': { inputPer1k: 0.015, outputPer1k: 0.075, cacheReadPer1k: 0.0015, cacheWrite5mPer1k: 0.01875, cacheWrite1hPer1k: 0.03 },
  'claude-sonnet-4': { inputPer1k: 0.003, outputPer1k: 0.015, cacheReadPer1k: 0.0003, cacheWrite5mPer1k: 0.00375, cacheWrite1hPer1k: 0.006 },
  // Legacy
  'claude-haiku-3': { inputPer1k: 0.00025, outputPer1k: 0.00125, cacheReadPer1k: 0.00003, cacheWrite5mPer1k: 0.0003, cacheWrite1hPer1k: 0.0005 },
};

function readCostFiles(startDate: string, endDate: string): any[] {
  const entries: any[] = [];
  const start = new Date(startDate);
  const end = new Date(endDate);

  for (let date = new Date(start); date <= end; date.setDate(date.getDate() + 1)) {
    const dateStr = date.toISOString().split('T')[0];
    const costFile = join(COSTS_DIR, `costs-${dateStr}.jsonl`);

    if (existsSync(costFile)) {
      const content = readFileSync(costFile, 'utf-8');
      const lines = content.split('\n').filter(line => line.trim());

      for (const line of lines) {
        try {
          entries.push(JSON.parse(line));
        } catch {
          // Skip invalid entries
        }
      }
    }
  }

  return entries;
}

function loadSessionMap(): any {
  try {
    if (existsSync(SESSION_MAP_FILE)) {
      return JSON.parse(readFileSync(SESSION_MAP_FILE, 'utf-8'));
    }
  } catch {}
  return { version: 1, issues: {}, lastUpdated: new Date().toISOString() };
}

function loadRuntimeMetrics(): any {
  try {
    if (existsSync(METRICS_FILE)) {
      return JSON.parse(readFileSync(METRICS_FILE, 'utf-8'));
    }
  } catch {}
  return { version: 1, tasks: [], runtimes: {}, lastUpdated: new Date().toISOString() };
}

function saveRuntimeMetrics(data: any): void {
  const { mkdirSync } = require('fs');
  mkdirSync(dirname(METRICS_FILE), { recursive: true });
  data.lastUpdated = new Date().toISOString();
  writeFileSync(METRICS_FILE, JSON.stringify(data, null, 2));
}

// Parse Claude Code session files for a workspace and return aggregated usage (ASYNC to avoid blocking)
async function parseWorkspaceSessionUsageAsync(workspacePath: string): Promise<{
  tokenCount: number;
  cost: number;
  model: string;
  startTime: string | null;
  endTime: string | null;
}> {
  // Claude Code session directory name format: path with leading / removed and / replaced by -
  // e.g., /home/eltmon/projects/foo -> -home-eltmon-projects-foo
  const sessionDirName = `-${workspacePath.replace(/^\//, '').replace(/\//g, '-')}`;
  const sessionDir = join(homedir(), '.claude', 'projects', sessionDirName);

  let totalInputTokens = 0;
  let totalOutputTokens = 0;
  let totalCacheReadTokens = 0;
  let totalCacheWriteTokens = 0;
  let model = 'claude-sonnet-4';
  let startTime: string | null = null;
  let endTime: string | null = null;

  if (!existsSync(sessionDir)) {
    console.log(`No session directory found: ${sessionDir}`);
    return { tokenCount: 0, cost: 0, model, startTime: null, endTime: null };
  }

  try {
    const allFiles = await readdir(sessionDir);
    const files = allFiles.filter(f => f.endsWith('.jsonl'));

    // Read files in parallel but with concurrency limit to avoid memory issues
    const BATCH_SIZE = 5;
    for (let i = 0; i < files.length; i += BATCH_SIZE) {
      const batch = files.slice(i, i + BATCH_SIZE);
      const contents = await Promise.all(
        batch.map(async (file) => {
          const filePath = join(sessionDir, file);
          try {
            return await readFile(filePath, 'utf-8');
          } catch {
            return '';
          }
        })
      );

      for (const content of contents) {
        const lines = content.split('\n').filter(l => l.trim());

        for (const line of lines) {
          try {
            const entry = JSON.parse(line);

            // Track timestamps
            if (entry.timestamp) {
              if (!startTime || entry.timestamp < startTime) {
                startTime = entry.timestamp;
              }
              if (!endTime || entry.timestamp > endTime) {
                endTime = entry.timestamp;
              }
            }

            // Extract model
            if (entry.message?.model || entry.model) {
              model = entry.message?.model || entry.model;
            }

            // Extract usage - can be at top level or in message
            const usage = entry.usage || entry.message?.usage;
            if (usage) {
              totalInputTokens += usage.input_tokens || 0;
              totalOutputTokens += usage.output_tokens || 0;
              totalCacheReadTokens += usage.cache_read_input_tokens || 0;
              totalCacheWriteTokens += usage.cache_creation_input_tokens || 0;
            }
          } catch {
            // Skip malformed lines
          }
        }
      }
    }

    // Calculate cost based on model pricing
    let pricing = MODEL_PRICING['claude-sonnet-4']; // default
    if (model.includes('opus')) {
      pricing = MODEL_PRICING['claude-opus-4'];
    } else if (model.includes('haiku')) {
      pricing = MODEL_PRICING['claude-haiku-4.5'];
    }

    const cost =
      (totalInputTokens / 1000) * pricing.inputPer1k +
      (totalOutputTokens / 1000) * pricing.outputPer1k +
      (totalCacheReadTokens / 1000) * (pricing.cacheReadPer1k || 0) +
      (totalCacheWriteTokens / 1000) * (pricing.cacheWrite5mPer1k || 0);  // Default to 5-minute TTL

    const tokenCount = totalInputTokens + totalOutputTokens + totalCacheReadTokens + totalCacheWriteTokens;

    console.log(`Parsed session usage for ${workspacePath}: ${tokenCount} tokens, $${cost.toFixed(4)}`);

    return { tokenCount, cost, model, startTime, endTime };
  } catch (err) {
    console.error('Error parsing session files:', err);
    return { tokenCount: 0, cost: 0, model, startTime: null, endTime: null };
  }
}

// Record a completed task in runtime metrics (async to avoid blocking)
async function recordApprovedTask(issueId: string, workspacePath: string, outcome: 'success' | 'failure' | 'partial'): Promise<void> {
  try {
    const usage = await parseWorkspaceSessionUsageAsync(workspacePath);
    const data = loadRuntimeMetrics();

    const startedAt = usage.startTime || new Date().toISOString();
    const completedAt = usage.endTime || new Date().toISOString();
    const durationMinutes = (new Date(completedAt).getTime() - new Date(startedAt).getTime()) / 60000;

    // Determine capability from issue prefix or description
    let capability: string = 'feature';
    const issueLower = issueId.toLowerCase();
    if (issueLower.includes('bug') || issueLower.includes('fix')) {
      capability = 'bugfix';
    } else if (issueLower.includes('refactor')) {
      capability = 'refactor';
    } else if (issueLower.includes('doc')) {
      capability = 'documentation';
    } else if (issueLower.includes('test')) {
      capability = 'testing';
    } else if (issueLower.includes('review')) {
      capability = 'review';
    } else if (issueLower.includes('plan')) {
      capability = 'planning';
    }

    const task = {
      id: `task-${Date.now()}-${Math.random().toString(36).slice(2, 8)}`,
      runtime: 'claude',
      issueId,
      capability,
      model: usage.model,
      outcome,
      startedAt,
      completedAt,
      durationMinutes: Math.max(durationMinutes, 0),
      cost: usage.cost,
      tokenCount: usage.tokenCount,
    };

    data.tasks.push(task);

    // Rebuild runtime aggregates
    const runtimeTasks = data.tasks.filter((t: any) => t.runtime === 'claude');
    const successful = runtimeTasks.filter((t: any) => t.outcome === 'success').length;
    const failed = runtimeTasks.filter((t: any) => t.outcome === 'failure').length;
    const partial = runtimeTasks.filter((t: any) => t.outcome === 'partial').length;
    const totalCost = runtimeTasks.reduce((sum: number, t: any) => sum + (t.cost || 0), 0);
    const totalTokens = runtimeTasks.reduce((sum: number, t: any) => sum + (t.tokenCount || 0), 0);
    const totalDuration = runtimeTasks.reduce((sum: number, t: any) => sum + (t.durationMinutes || 0), 0);

    // By capability aggregation
    const byCapability: any = {};
    const capabilities = ['feature', 'bugfix', 'refactor', 'review', 'planning', 'documentation', 'testing', 'other'];
    for (const cap of capabilities) {
      const capTasks = runtimeTasks.filter((t: any) => t.capability === cap);
      if (capTasks.length > 0) {
        const capSuccessful = capTasks.filter((t: any) => t.outcome === 'success').length;
        const capTotalCost = capTasks.reduce((sum: number, t: any) => sum + (t.cost || 0), 0);
        const capTotalDuration = capTasks.reduce((sum: number, t: any) => sum + (t.durationMinutes || 0), 0);
        byCapability[cap] = {
          tasks: capTasks.length,
          successfulTasks: capSuccessful,
          successRate: capTasks.length > 0 ? capSuccessful / capTasks.length : 0,
          avgDurationMinutes: capTasks.length > 0 ? capTotalDuration / capTasks.length : 0,
          totalCost: capTotalCost,
          avgCost: capTasks.length > 0 ? capTotalCost / capTasks.length : 0,
        };
      }
    }

    // By model aggregation
    const byModel: any = {};
    const models: string[] = [...new Set(runtimeTasks.map((t: any) => t.model || 'unknown'))] as string[];
    for (const m of models) {
      const modelTasks = runtimeTasks.filter((t: any) => (t.model || 'unknown') === m);
      const modelSuccessful = modelTasks.filter((t: any) => t.outcome === 'success').length;
      const modelTotalCost = modelTasks.reduce((sum: number, t: any) => sum + (t.cost || 0), 0);
      byModel[m] = {
        tasks: modelTasks.length,
        successRate: modelTasks.length > 0 ? modelSuccessful / modelTasks.length : 0,
        avgCost: modelTasks.length > 0 ? modelTotalCost / modelTasks.length : 0,
        totalCost: modelTotalCost,
      };
    }

    // Daily stats
    const dailyStats: any[] = [];
    const thirtyDaysAgo = new Date();
    thirtyDaysAgo.setDate(thirtyDaysAgo.getDate() - 30);
    for (let d = new Date(thirtyDaysAgo); d <= new Date(); d.setDate(d.getDate() + 1)) {
      const dateStr = d.toISOString().split('T')[0];
      const dayTasks = runtimeTasks.filter((t: any) => t.completedAt?.startsWith(dateStr));
      if (dayTasks.length > 0) {
        const daySuccessful = dayTasks.filter((t: any) => t.outcome === 'success').length;
        const dayCost = dayTasks.reduce((sum: number, t: any) => sum + (t.cost || 0), 0);
        const dayTokens = dayTasks.reduce((sum: number, t: any) => sum + (t.tokenCount || 0), 0);
        dailyStats.push({
          date: dateStr,
          tasks: dayTasks.length,
          successfulTasks: daySuccessful,
          cost: dayCost,
          successRate: dayTasks.length > 0 ? daySuccessful / dayTasks.length : 0,
          tokenCount: dayTokens,
        });
      }
    }

    data.runtimes['claude'] = {
      runtime: 'claude',
      totalTasks: runtimeTasks.length,
      successfulTasks: successful,
      failedTasks: failed,
      partialTasks: partial,
      successRate: runtimeTasks.length > 0 ? successful / runtimeTasks.length : 0,
      avgDurationMinutes: runtimeTasks.length > 0 ? totalDuration / runtimeTasks.length : 0,
      avgCost: runtimeTasks.length > 0 ? totalCost / runtimeTasks.length : 0,
      totalCost,
      totalTokens,
      byCapability,
      byModel,
      dailyStats,
      lastUpdated: new Date().toISOString(),
    };

    saveRuntimeMetrics(data);
    console.log(`Recorded task for ${issueId}: ${outcome}, $${usage.cost.toFixed(4)}, ${usage.tokenCount} tokens`);
  } catch (err) {
    console.error('Error recording task metrics:', err);
  }
}

// GET /api/costs/summary - Overall cost summary
app.get('/api/costs/summary', (_req, res) => {
  try {
    const today = new Date().toISOString().split('T')[0];
    const weekAgo = new Date(Date.now() - 7 * 24 * 60 * 60 * 1000).toISOString().split('T')[0];
    const monthAgo = new Date(Date.now() - 30 * 24 * 60 * 60 * 1000).toISOString().split('T')[0];

    const todayEntries = readCostFiles(today, today);
    const weekEntries = readCostFiles(weekAgo, today);
    const monthEntries = readCostFiles(monthAgo, today);

    const summarize = (entries: any[]) => ({
      totalCost: entries.reduce((sum, e) => sum + (e.cost || 0), 0),
      totalTokens: entries.reduce((sum, e) => sum + ((e.usage?.inputTokens || 0) + (e.usage?.outputTokens || 0)), 0),
      entryCount: entries.length,
      byModel: entries.reduce((acc, e) => {
        acc[e.model] = (acc[e.model] || 0) + (e.cost || 0);
        return acc;
      }, {} as Record<string, number>),
    });

    res.json({
      today: summarize(todayEntries),
      week: summarize(weekEntries),
      month: summarize(monthEntries),
    });
  } catch (error: any) {
    console.error('Error getting cost summary:', error);
    res.status(500).json({ error: 'Failed to get cost summary: ' + error.message });
  }
});

// GET /api/costs/by-issue - Costs grouped by issue (PAN-85: migrated to cache)
app.get('/api/costs/by-issue', async (_req, res) => {
  try {
    const issueMap: Record<string, { totalCost: number; tokenCount: number; sessionCount: number; model?: string; durationMinutes?: number }> = {};

    // PRIMARY: Read from pre-computed cache (PAN-81 event-sourced tracking)
    const cacheFile = join(homedir(), '.panopticon', 'costs', 'by-issue.json');
    if (existsSync(cacheFile)) {
      try {
        const cacheContent = readFileSync(cacheFile, 'utf-8');
        const cache = JSON.parse(cacheContent);

        // Map cache format to expected format
        for (const [issueId, issueData] of Object.entries(cache.issues || {})) {
          const data = issueData as any;
          const key = issueId.toLowerCase();

          // Calculate total token count (input + output + cache tokens)
          const totalTokens =
            (data.inputTokens || 0) +
            (data.outputTokens || 0) +
            (data.cacheReadTokens || 0) +
            (data.cacheWriteTokens || 0);

          // Get primary model (model with highest cost)
          let primaryModel: string | undefined;
          if (data.models) {
            const modelEntries = Object.entries(data.models) as [string, number][];
            if (modelEntries.length > 0) {
              modelEntries.sort((a, b) => b[1] - a[1]);
              primaryModel = modelEntries[0][0];
            }
          }

          issueMap[key] = {
            totalCost: data.totalCost || 0,
            tokenCount: totalTokens,
            sessionCount: data.eventCount || 0, // Use eventCount as proxy for sessionCount
            model: primaryModel,
            // durationMinutes not available in cache yet - could be added in future
          };
        }
      } catch (error) {
        console.error('Warning: Failed to read cost cache, falling back to legacy', error);
      }
    }

    // FALLBACK: Check legacy tracking files for any historical data not in cache
    const sessionMap = loadSessionMap();
    const runtimeMetrics = loadRuntimeMetrics();

    // Add from session-map (legacy format) if not already present
    for (const [issueId, issueData] of Object.entries(sessionMap.issues || {})) {
      const data = issueData as any;
      const key = issueId.toLowerCase();
      if (!issueMap[key] && (data.totalCost || 0) > 0) {
        issueMap[key] = {
          totalCost: data.totalCost || 0,
          tokenCount: data.totalTokens || 0,
          sessionCount: data.sessions?.length || 0,
        };
      }
    }

    // Add from runtime-metrics if it has higher values (legacy)
    for (const task of runtimeMetrics.tasks || []) {
      if (task.issueId) {
        const key = task.issueId.toLowerCase();
        if (!issueMap[key]) {
          issueMap[key] = { totalCost: 0, tokenCount: 0, sessionCount: 0 };
        }
        // Only use if higher than what we calculated from sessions
        if (task.cost > issueMap[key].totalCost) {
          issueMap[key].totalCost = task.cost;
          issueMap[key].tokenCount = task.tokenCount;
          issueMap[key].model = task.model;
          issueMap[key].durationMinutes = task.durationMinutes;
        }
      }
    }

    // Convert to array
    const issues = Object.entries(issueMap).map(([issueId, data]) => ({
      issueId: issueId.toUpperCase(),
      totalCost: data.totalCost,
      tokenCount: data.tokenCount,
      sessionCount: data.sessionCount,
      model: data.model,
      durationMinutes: data.durationMinutes,
    }));

    // Sort by cost descending
    issues.sort((a, b) => b.totalCost - a.totalCost);

    res.json({ issues });
  } catch (error: any) {
    console.error('Error getting costs by issue:', error);
    res.status(500).json({ error: 'Failed to get costs by issue: ' + error.message });
  }
});

// GET /api/issues/:id/costs - Cost summary for a specific issue
app.get('/api/issues/:id/costs', (req, res) => {
  try {
    const { id } = req.params;
    const sessionMap = loadSessionMap();
    const issueData = sessionMap.issues?.[id] || sessionMap.issues?.[id.toUpperCase()];

    if (!issueData) {
      // Try to find by searching (case-insensitive)
      const issueKey = Object.keys(sessionMap.issues || {}).find(
        k => k.toLowerCase() === id.toLowerCase()
      );
      if (!issueKey) {
        return res.json({
          issueId: id,
          totalCost: 0,
          totalTokens: 0,
          sessions: [],
          byModel: {},
        });
      }
    }

    const data = issueData || { sessions: [], totalCost: 0, totalTokens: 0 };

    // Calculate by-model breakdown
    const byModel: Record<string, number> = {};
    for (const session of data.sessions || []) {
      const model = session.model || 'unknown';
      byModel[model] = (byModel[model] || 0) + (session.cost || 0);
    }

    res.json({
      issueId: id,
      totalCost: data.totalCost || 0,
      totalTokens: data.totalTokens || 0,
      sessions: data.sessions || [],
      byModel,
    });
  } catch (error: any) {
    console.error('Error getting issue costs:', error);
    res.status(500).json({ error: 'Failed to get issue costs: ' + error.message });
  }
});

// GET /api/metrics/runtimes - Runtime metrics comparison
app.get('/api/metrics/runtimes', (_req, res) => {
  try {
    const metrics = loadRuntimeMetrics();
    const runtimes = metrics.runtimes || {};

    // Format for frontend
    const comparison = Object.entries(runtimes).map(([runtime, data]: [string, any]) => ({
      runtime,
      totalTasks: data.totalTasks || 0,
      successfulTasks: data.successfulTasks || 0,
      failedTasks: data.failedTasks || 0,
      successRate: data.successRate || 0,
      avgDurationMinutes: data.avgDurationMinutes || 0,
      avgCost: data.avgCost || 0,
      totalCost: data.totalCost || 0,
      totalTokens: data.totalTokens || 0,
      byCapability: data.byCapability || {},
      byModel: data.byModel || {},
      dailyStats: data.dailyStats || [],
    }));

    // Calculate aggregates
    const totalTasks = comparison.reduce((sum, r) => sum + r.totalTasks, 0);
    const totalCost = comparison.reduce((sum, r) => sum + r.totalCost, 0);
    const totalTokens = comparison.reduce((sum, r) => sum + r.totalTokens, 0);
    const totalSuccessful = comparison.reduce((sum, r) => sum + r.successfulTasks, 0);

    res.json({
      runtimes: comparison,
      aggregated: {
        totalTasks,
        totalCost,
        totalTokens,
        avgSuccessRate: totalTasks > 0 ? totalSuccessful / totalTasks : 0,
      },
      lastUpdated: metrics.lastUpdated,
    });
  } catch (error: any) {
    console.error('Error getting runtime metrics:', error);
    res.status(500).json({ error: 'Failed to get runtime metrics: ' + error.message });
  }
});

// GET /api/metrics/tasks - Recent tasks
app.get('/api/metrics/tasks', (req, res) => {
  try {
    const limit = parseInt(req.query.limit as string) || 50;
    const metrics = loadRuntimeMetrics();
    const tasks = (metrics.tasks || [])
      .sort((a: any, b: any) => new Date(b.completedAt).getTime() - new Date(a.completedAt).getTime())
      .slice(0, limit);

    res.json({ tasks });
  } catch (error: any) {
    console.error('Error getting tasks:', error);
    res.status(500).json({ error: 'Failed to get tasks: ' + error.message });
  }
});

// Ensure tmux is running at startup
ensureTmuxRunning().catch((err) => {
  console.error('Failed to ensure tmux is running:', err);
});

// Auto-start Cloister if configured
if (shouldAutoStart()) {
  console.log('ðŸ”” Auto-starting Cloister...');
  getCloisterService().start();
}

// In production, serve the frontend static files
if (process.env.NODE_ENV === 'production') {
  const frontendPath = join(__dirname, '..', '..', 'frontend', 'dist');
  if (existsSync(frontendPath)) {
    app.use(express.static(frontendPath));
    // SPA fallback - serve index.html for all non-API routes
    app.get('*', (req, res) => {
      if (!req.path.startsWith('/api')) {
        res.sendFile(join(frontendPath, 'index.html'));
      }
    });
    console.log(`Serving frontend from ${frontendPath}`);
  }
}

// Create HTTP server and attach WebSocket server for terminal
const server = http.createServer(app);
const wss = new WebSocketServer({ server, path: '/ws/terminal' });

// Track active PTY sessions
const activePtys = new Map<string, pty.IPty>();

// Health check endpoint (must be after wss and activePtys are defined)
app.get('/api/health', (_req, res) => {
  res.json({
    status: 'ok',
    timestamp: new Date().toISOString(),
    connections: {
      websockets: wss.clients.size,
      activePtys: activePtys.size
    }
  });
});

wss.on('connection', (ws: WebSocket, req) => {
  // Parse session name from URL query param: /ws/terminal?session=planning-min-123
  const url = new URL(req.url || '', `http://${req.headers.host}`);
  const sessionName = url.searchParams.get('session');

  if (!sessionName) {
    ws.close(1008, 'Session name required');
    return;
  }

  console.log(`WebSocket connected for session: ${sessionName}`);

  // Check if tmux session exists (async to avoid blocking event loop)
  (async () => {
    try {
      const { stdout } = await execAsync('tmux list-sessions -F "#{session_name}" 2>/dev/null || echo ""');
      const sessions = stdout.trim().split('\n').filter(Boolean);

      if (!sessions.includes(sessionName)) {
        ws.close(1008, `Session ${sessionName} not found`);
        return;
      }
    } catch {
      ws.close(1008, 'Failed to list tmux sessions');
      return;
    }

    // Spawn a PTY that attaches to the tmux session
    // The PTY will receive the full screen content including alternate buffer
    // Initial dimensions match frontend xterm.js (120x30) to avoid resize flicker
    const ptyProcess = pty.spawn('tmux', ['attach-session', '-t', sessionName], {
      name: 'xterm-256color',
      cols: 120,
      rows: 30,
      cwd: homedir(),
      env: { ...process.env, TERM: 'xterm-256color', COLORTERM: 'truecolor', LANG: 'en_US.UTF-8' } as { [key: string]: string },
    });

    // Pre-resize tmux window to match initial PTY dimensions
    execAsync(`tmux resize-window -t ${sessionName} -x 120 -y 30 2>/dev/null || true`)
      .catch(() => { /* ignore initial resize errors */ });

    activePtys.set(sessionName, ptyProcess);

    // Capture and send the current visible screen state with ANSI escape codes
    // This ensures the client sees the actual current terminal state immediately
    // The PTY will then handle live updates going forward
    setTimeout(async () => {
      if (ws.readyState === WebSocket.OPEN) {
        try {
          // Capture with -e to include escape sequences (colors, formatting)
          // -p prints to stdout, -S - -E - captures only the visible viewport (not scrollback)
          const { stdout } = await execAsync(`tmux capture-pane -t "${sessionName}" -e -p -S - -E - 2>/dev/null || echo ""`);
          if (stdout.trim()) {
            // Send a clear screen sequence first, then the captured content
            ws.send('\x1b[2J\x1b[H' + stdout);
          }
        } catch {
          // Ignore capture errors
        }
      }
    }, 200);

    // Forward PTY output to WebSocket
    ptyProcess.onData((data) => {
      if (ws.readyState === WebSocket.OPEN) {
        ws.send(data);
      }
    });

    // Handle PTY exit
    ptyProcess.onExit(({ exitCode }) => {
      console.log(`PTY for ${sessionName} exited with code ${exitCode}`);
      activePtys.delete(sessionName);
      if (ws.readyState === WebSocket.OPEN) {
        ws.close(1000, 'Session ended');
      }
    });

    // Forward WebSocket input to PTY
    ws.on('message', (data) => {
      const message = data.toString();

      // Handle resize messages (JSON format: {"type":"resize","cols":80,"rows":24})
      // Only attempt JSON parse if message looks like JSON (starts with '{')
      if (message.startsWith('{')) {
        try {
          const parsed = JSON.parse(message);
          if (parsed.type === 'resize' && parsed.cols && parsed.rows) {
            // Resize tmux window FIRST, then PTY (order matters for proper sync)
            // tmux resize triggers SIGWINCH which the application uses to redraw
            execAsync(`tmux resize-window -t ${sessionName} -x ${parsed.cols} -y ${parsed.rows} 2>/dev/null || true`)
              .then(() => {
                ptyProcess.resize(parsed.cols, parsed.rows);
              })
              .catch(() => {
                // Still resize PTY even if tmux resize fails
                ptyProcess.resize(parsed.cols, parsed.rows);
              });
            return;
          }
        } catch {
          // Invalid JSON, treat as terminal input
        }
      }

      ptyProcess.write(message);
    });

    // Clean up on WebSocket close
    ws.on('close', () => {
      console.log(`WebSocket closed for session: ${sessionName}`);
      // Detach from tmux (Ctrl-b d) before killing PTY to leave tmux session running
      ptyProcess.write('\x02d'); // Ctrl-b d
      setTimeout(() => {
        ptyProcess.kill();
        activePtys.delete(sessionName);
      }, 100);
    });

    ws.on('error', (err) => {
      console.error(`WebSocket error for ${sessionName}:`, err);
      ptyProcess.kill();
      activePtys.delete(sessionName);
    });
  })();
});

// Serve static files in production mode
const __dirname = dirname(fileURLToPath(import.meta.url));
const publicDir = join(__dirname, 'public');

if (existsSync(publicDir)) {
  console.log(`Serving static files from ${publicDir}`);
  app.use(express.static(publicDir));

  // SPA fallback - serve index.html for all non-API routes
  app.get('*', (req, res) => {
    res.sendFile(join(publicDir, 'index.html'));
  });
}

server.listen(PORT, '0.0.0.0', async () => {
  console.log(`Panopticon API server running on http://0.0.0.0:${PORT}`);
  console.log(`WebSocket terminal available at ws://0.0.0.0:${PORT}/ws/terminal`);

  // Auto-start Cloister if configured
  try {
    const config = loadCloisterConfig();
    if (config.startup?.auto_start) {
      console.log('Cloister auto-start enabled, starting...');
      const service = getCloisterService();
      await service.start();
      console.log('Cloister auto-started successfully');
    }
  } catch (error: any) {
    console.error('Failed to auto-start Cloister:', error.message);
  }
});
